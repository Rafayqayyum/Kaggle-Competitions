{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading playground-series-s3e18.zip to f:\\kaggle_competitions\\Multi-label classification of enzyme\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/2.41M [00:00<?, ?B/s]\n",
      " 41%|████▏     | 1.00M/2.41M [00:03<00:05, 267kB/s]\n",
      " 83%|████████▎ | 2.00M/2.41M [00:06<00:01, 361kB/s]\n",
      "100%|██████████| 2.41M/2.41M [00:07<00:00, 375kB/s]\n",
      "100%|██████████| 2.41M/2.41M [00:07<00:00, 354kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c playground-series-s3e18"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original=pd.read_csv('mixed_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1_1_1_1_0_1\n",
       "1       1_1_1_1_0_1\n",
       "2       1_1_1_1_0_1\n",
       "3       0_1_1_0_0_0\n",
       "4       1_1_1_1_0_1\n",
       "           ...     \n",
       "1034    0_1_0_0_0_1\n",
       "1035    1_1_0_0_0_0\n",
       "1036    0_1_1_0_0_0\n",
       "1037    0_1_1_0_0_0\n",
       "1038    0_1_0_1_0_0\n",
       "Name: EC1_EC2_EC3_EC4_EC5_EC6, Length: 1039, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original['EC1_EC2_EC3_EC4_EC5_EC6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='EC1_EC2_EC3_EC4_EC5_EC6'\n",
    "\n",
    "for x in col.split('_'):\n",
    "    original[x]=original[col].apply(lambda x: int(x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v',\n",
       "       'Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n",
       "       'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n",
       "       'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n",
       "       'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n",
       "       'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n",
       "       'fr_COO', 'fr_COO2', 'EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original=original[train.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1039, 14838)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original),len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged=pd.concat([train,original],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14838"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at it later some of the columns are highly skewed\n",
    "# from ydata_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(train, title=\"Pandas Profiling Report\")\n",
    "\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.duplicated().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['EC3','EC4','EC5','EC6'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.drop(['EC3','EC4','EC5','EC6'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop(['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v', 'Chi4n'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=train.drop(['EC1','EC2'],axis=1)\n",
    "X=train_merged.drop(['EC1','EC2'],axis=1)\n",
    "y1=train_merged[['EC1']]\n",
    "y2=train[['EC2']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew,yeojohnson\n",
    "from scipy import stats\n",
    "def preprocess(data,labels):\n",
    "    ## remove the outliers with IQR and remove the labels of the outliers\n",
    "    # Q1 = data.quantile(0.10)\n",
    "    # Q3 = data.quantile(0.90)\n",
    "    # IQR = Q3 - Q1\n",
    "    # condition=~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    # processed_data=data[condition].reset_index(drop=True)\n",
    "    # processed_labels=labels[condition].reset_index(drop=True)\n",
    "    ## remove the skewness of the data\n",
    "    # skewness = data.apply(lambda x: skew(x))\n",
    "    # skewness = skewness[abs(skewness) > 0.5]\n",
    "    # skewed_features = skewness.index\n",
    "    # # yeo \n",
    "    # for feat in skewed_features:\n",
    "    #     data[feat]=yeojohnson(data[feat])[0]\n",
    "    \n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15797, 15797, 14838)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(y1),len(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v', 'Chi4n',\n",
       "       'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n",
       "       'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n",
       "       'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n",
       "       'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n",
       "       'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n",
       "       'fr_COO', 'fr_COO2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>FpDensityMorgan1</th>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <th>FpDensityMorgan3</th>\n",
       "      <th>HallKierAlpha</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>Kappa3</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>NumHeteroatoms</th>\n",
       "      <th>PEOE_VSA10</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222.068080</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>212.163</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>11.922504</td>\n",
       "      <td>0.171585</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.536492</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>260.029719</td>\n",
       "      <td>1.346154</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>2.769231</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>247.031</td>\n",
       "      <td>3.201491</td>\n",
       "      <td>10.932338</td>\n",
       "      <td>-4.830450</td>\n",
       "      <td>10</td>\n",
       "      <td>24.415866</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382.131027</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>1.742857</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>354.106</td>\n",
       "      <td>15.033890</td>\n",
       "      <td>11.238048</td>\n",
       "      <td>-5.066255</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>530.070277</td>\n",
       "      <td>1.162791</td>\n",
       "      <td>1.573770</td>\n",
       "      <td>2.270270</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>506.124</td>\n",
       "      <td>6.724301</td>\n",
       "      <td>11.171170</td>\n",
       "      <td>-5.276575</td>\n",
       "      <td>19</td>\n",
       "      <td>42.727765</td>\n",
       "      <td>21.335138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118.062994</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>108.056</td>\n",
       "      <td>3.931272</td>\n",
       "      <td>9.855741</td>\n",
       "      <td>-1.676296</td>\n",
       "      <td>4</td>\n",
       "      <td>6.041841</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>6.923737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExactMolWt  FpDensityMorgan1  FpDensityMorgan2  FpDensityMorgan3  \\\n",
       "0  222.068080          1.181818          1.727273          2.363636   \n",
       "1  260.029719          1.346154          2.076923          2.769231   \n",
       "2  382.131027          1.085714          1.742857          2.400000   \n",
       "3  530.070277          1.162791          1.573770          2.270270   \n",
       "4  118.062994          1.444444          2.111111          2.555556   \n",
       "\n",
       "   HallKierAlpha  HeavyAtomMolWt     Kappa3  MaxAbsEStateIndex  \\\n",
       "0          -0.24         212.163   8.170000          11.922504   \n",
       "1          -0.09         247.031   3.201491          10.932338   \n",
       "2          -0.78         354.106  15.033890          11.238048   \n",
       "3          -1.30         506.124   6.724301          11.171170   \n",
       "4          -1.10         108.056   3.931272           9.855741   \n",
       "\n",
       "   MinEStateIndex  NumHeteroatoms  PEOE_VSA10  PEOE_VSA14  PEOE_VSA6  \n",
       "0        0.171585               4    0.000000   91.536492   0.000000  \n",
       "1       -4.830450              10   24.415866    7.822697   0.000000  \n",
       "2       -5.066255               9    0.000000   15.645394   0.000000  \n",
       "3       -5.276575              19   42.727765   21.335138   0.000000  \n",
       "4       -1.676296               4    6.041841   11.938611   6.923737  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['ExactMolWt', 'FpDensityMorgan1',\n",
    "       'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n",
    "       'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n",
    "       'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>EState_VSA2</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323.390782</td>\n",
       "      <td>9.879918</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>2.754513</td>\n",
       "      <td>1.749203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938294</td>\n",
       "      <td>...</td>\n",
       "      <td>91.536492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.744066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>35.527357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.723798</td>\n",
       "      <td>7.259037</td>\n",
       "      <td>4.441467</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.285046</td>\n",
       "      <td>4.485235</td>\n",
       "      <td>2.201375</td>\n",
       "      <td>1.289775</td>\n",
       "      <td>45.135471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>30.705892</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>44.707310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>521.643822</td>\n",
       "      <td>10.911303</td>\n",
       "      <td>8.527859</td>\n",
       "      <td>11.050864</td>\n",
       "      <td>6.665291</td>\n",
       "      <td>9.519706</td>\n",
       "      <td>5.824822</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>6.606882</td>\n",
       "      <td>...</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.378235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>73.143616</td>\n",
       "      <td>17.964475</td>\n",
       "      <td>45.660120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>567.431166</td>\n",
       "      <td>12.453343</td>\n",
       "      <td>7.089119</td>\n",
       "      <td>12.833709</td>\n",
       "      <td>6.478023</td>\n",
       "      <td>10.978151</td>\n",
       "      <td>7.914542</td>\n",
       "      <td>3.067181</td>\n",
       "      <td>95.639554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.335138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>62.107304</td>\n",
       "      <td>31.961948</td>\n",
       "      <td>87.509997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.770735</td>\n",
       "      <td>4.414719</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.036450</td>\n",
       "      <td>0.727664</td>\n",
       "      <td>17.980451</td>\n",
       "      <td>12.841643</td>\n",
       "      <td>...</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>6.923737</td>\n",
       "      <td>19.386400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>18.883484</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BertzCT       Chi1     Chi1n      Chi1v     Chi2n      Chi2v     Chi3v  \\\n",
       "0  323.390782   9.879918  5.875576   5.875576  4.304757   4.304757  2.754513   \n",
       "1  273.723798   7.259037  4.441467   5.834958  3.285046   4.485235  2.201375   \n",
       "2  521.643822  10.911303  8.527859  11.050864  6.665291   9.519706  5.824822   \n",
       "3  567.431166  12.453343  7.089119  12.833709  6.478023  10.978151  7.914542   \n",
       "4  112.770735   4.414719  2.866236   2.866236  1.875634   1.875634  1.036450   \n",
       "\n",
       "      Chi4n  EState_VSA1  EState_VSA2  ...  PEOE_VSA14  PEOE_VSA6  PEOE_VSA7  \\\n",
       "0  1.749203     0.000000    11.938294  ...   91.536492   0.000000   0.000000   \n",
       "1  1.289775    45.135471     0.000000  ...    7.822697   0.000000   0.000000   \n",
       "2  1.770579    15.645394     6.606882  ...   15.645394   0.000000  53.378235   \n",
       "3  3.067181    95.639554     0.000000  ...   21.335138   0.000000   0.000000   \n",
       "4  0.727664    17.980451    12.841643  ...   11.938611   6.923737  19.386400   \n",
       "\n",
       "   PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  fr_COO2  \n",
       "0   0.000000  17.744066   0.000000    4.794537    35.527357       0        0  \n",
       "1   0.000000   7.822697  30.705892   13.825658    44.707310       0        0  \n",
       "2   0.000000  15.645394  73.143616   17.964475    45.660120       0        0  \n",
       "3   6.420822  15.645394  62.107304   31.961948    87.509997       0        0  \n",
       "4   0.000000  11.938611  18.883484    9.589074    33.333333       2        2  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns \n",
    "\n",
    "cat_cols=['NumHeteroatoms', 'fr_COO', 'fr_COO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols_X=X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "numerical_cols_X2=X2.select_dtypes(include=['int64','float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BertzCT',\n",
       " 'Chi1',\n",
       " 'Chi1n',\n",
       " 'Chi1v',\n",
       " 'Chi2n',\n",
       " 'Chi2v',\n",
       " 'Chi3v',\n",
       " 'Chi4n',\n",
       " 'EState_VSA1',\n",
       " 'EState_VSA2',\n",
       " 'ExactMolWt',\n",
       " 'FpDensityMorgan1',\n",
       " 'FpDensityMorgan2',\n",
       " 'FpDensityMorgan3',\n",
       " 'HallKierAlpha',\n",
       " 'HeavyAtomMolWt',\n",
       " 'Kappa3',\n",
       " 'MaxAbsEStateIndex',\n",
       " 'MinEStateIndex',\n",
       " 'NumHeteroatoms',\n",
       " 'PEOE_VSA10',\n",
       " 'PEOE_VSA14',\n",
       " 'PEOE_VSA6',\n",
       " 'PEOE_VSA7',\n",
       " 'PEOE_VSA8',\n",
       " 'SMR_VSA10',\n",
       " 'SMR_VSA5',\n",
       " 'SlogP_VSA3',\n",
       " 'VSA_EState9',\n",
       " 'fr_COO',\n",
       " 'fr_COO2']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_cols_X),len(numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    numerical_cols_X.remove(col)\n",
    "    numerical_cols_X2.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 3, 28)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_cols_X),len(cat_cols),len(numerical_cols_X2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Importances\n",
    "from sklearn.feature_selection import mutual_info_classif,chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def feature_importances(Xdata,ydata):\n",
    "    mi=mutual_info_classif(Xdata,ydata)\n",
    "    rfc=RandomForestClassifier()\n",
    "    rfc.fit(Xdata,ydata)\n",
    "    return pd.DataFrame({'features':Xdata.columns,'mi':mi,'rfc':rfc.feature_importances_}).sort_values(by=['mi','rfc'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>mi</th>\n",
       "      <th>rfc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NumHeteroatoms</td>\n",
       "      <td>0.058280</td>\n",
       "      <td>0.039064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MinEStateIndex</td>\n",
       "      <td>0.056605</td>\n",
       "      <td>0.052705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EState_VSA1</td>\n",
       "      <td>0.052662</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SlogP_VSA3</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>0.031848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PEOE_VSA14</td>\n",
       "      <td>0.046395</td>\n",
       "      <td>0.023424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HeavyAtomMolWt</td>\n",
       "      <td>0.044479</td>\n",
       "      <td>0.036525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SMR_VSA10</td>\n",
       "      <td>0.044010</td>\n",
       "      <td>0.026908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>VSA_EState9</td>\n",
       "      <td>0.043804</td>\n",
       "      <td>0.041079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExactMolWt</td>\n",
       "      <td>0.043124</td>\n",
       "      <td>0.036290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMR_VSA5</td>\n",
       "      <td>0.038005</td>\n",
       "      <td>0.029832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MaxAbsEStateIndex</td>\n",
       "      <td>0.037436</td>\n",
       "      <td>0.043032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BertzCT</td>\n",
       "      <td>0.035297</td>\n",
       "      <td>0.039535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HallKierAlpha</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.033696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.032370</td>\n",
       "      <td>0.039749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chi1v</td>\n",
       "      <td>0.032325</td>\n",
       "      <td>0.038288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chi1</td>\n",
       "      <td>0.030871</td>\n",
       "      <td>0.035283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chi3v</td>\n",
       "      <td>0.028152</td>\n",
       "      <td>0.036678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chi2v</td>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PEOE_VSA7</td>\n",
       "      <td>0.024253</td>\n",
       "      <td>0.020154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chi1n</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.036317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chi2n</td>\n",
       "      <td>0.023996</td>\n",
       "      <td>0.036939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chi4n</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.035434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PEOE_VSA10</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>0.023879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EState_VSA2</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.026829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PEOE_VSA6</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.015304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FpDensityMorgan1</td>\n",
       "      <td>0.013253</td>\n",
       "      <td>0.035288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FpDensityMorgan2</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.035425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PEOE_VSA8</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>0.020911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FpDensityMorgan3</td>\n",
       "      <td>0.008780</td>\n",
       "      <td>0.036582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fr_COO2</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fr_COO</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.004851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             features        mi       rfc\n",
       "19     NumHeteroatoms  0.058280  0.039064\n",
       "18     MinEStateIndex  0.056605  0.052705\n",
       "8         EState_VSA1  0.052662  0.041800\n",
       "27         SlogP_VSA3  0.047201  0.031848\n",
       "21         PEOE_VSA14  0.046395  0.023424\n",
       "15     HeavyAtomMolWt  0.044479  0.036525\n",
       "25          SMR_VSA10  0.044010  0.026908\n",
       "28        VSA_EState9  0.043804  0.041079\n",
       "10         ExactMolWt  0.043124  0.036290\n",
       "26           SMR_VSA5  0.038005  0.029832\n",
       "17  MaxAbsEStateIndex  0.037436  0.043032\n",
       "0             BertzCT  0.035297  0.039535\n",
       "14      HallKierAlpha  0.034046  0.033696\n",
       "16             Kappa3  0.032370  0.039749\n",
       "3               Chi1v  0.032325  0.038288\n",
       "1                Chi1  0.030871  0.035283\n",
       "6               Chi3v  0.028152  0.036678\n",
       "5               Chi2v  0.027127  0.041200\n",
       "23          PEOE_VSA7  0.024253  0.020154\n",
       "2               Chi1n  0.024070  0.036317\n",
       "4               Chi2n  0.023996  0.036939\n",
       "7               Chi4n  0.022183  0.035434\n",
       "20         PEOE_VSA10  0.019912  0.023879\n",
       "9         EState_VSA2  0.019779  0.026829\n",
       "22          PEOE_VSA6  0.014661  0.015304\n",
       "11   FpDensityMorgan1  0.013253  0.035288\n",
       "12   FpDensityMorgan2  0.012849  0.035425\n",
       "24          PEOE_VSA8  0.012581  0.020911\n",
       "13   FpDensityMorgan3  0.008780  0.036582\n",
       "30            fr_COO2  0.007797  0.005151\n",
       "29             fr_COO  0.005863  0.004851"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances(X,y1.values.ravel())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler,MaxAbsScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "def get_column_transformer(num_cols):\n",
    "    return ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(model,num_cols):\n",
    "    return Pipeline(steps=[('preprocessor', get_column_transformer(num_cols)),\n",
    "                      ('classifier', model)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def skf_model(model_obj,X,y,num_cols):\n",
    "    skf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    scores=[]\n",
    "    i=0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y.iloc[train_index,:], y.iloc[test_index,:]\n",
    "        # preprocess\n",
    "        X_train,y_train=preprocess(X_train,y_train)\n",
    "        y_train=y_train.values.ravel()\n",
    "        y_test=y_test.values.ravel()\n",
    "        # get pipeline\n",
    "        model=get_pipeline(model_obj,num_cols)\n",
    "        # fit model\n",
    "        model.fit(X_train,y_train)\n",
    "        # predict\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        val_preds = np.array(y_pred)[:,1]\n",
    "        score=roc_auc_score(y_test,val_preds)\n",
    "        scores.append(score)\n",
    "        print(f'Fold {i+1} : {score}')\n",
    "        i+=1\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5698826291079813\n",
      "Fold 2 : 0.5466386554621849\n",
      "Fold 3 : 0.5626685309098172\n",
      "Fold 4 : 0.5583614516802793\n",
      "Fold 5 : 0.5609541357557266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5597010805831978"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "skf_model(GaussianNB(),X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params_l1={'n_estimators': 1173,\n",
    "              'max_depth': 91,\n",
    "              'criterion': 'entropy',\n",
    "              'max_features': 'sqrt',\n",
    "              'min_samples_split': 10,\n",
    "              'min_samples_leaf': 18}\n",
    "rf_params_l2={'n_estimators': 1371,\n",
    "              'max_depth': 7,\n",
    "              'criterion': 'gini',\n",
    "              'max_features': 'log2',\n",
    "              'min_samples_split': 2,\n",
    "              'min_samples_leaf': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7204854141387502\n",
      "Fold 2 : 0.7164103026065116\n",
      "Fold 3 : 0.709592223889241\n",
      "Fold 4 : 0.7093813717003118\n",
      "Fold 5 : 0.7198656551288131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scores1=skf_model(RandomForestClassifier(random_state=42,**rf_params_l1,n_jobs=-1),X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5955061619718309\n",
      "Fold 2 : 0.5760847196021265\n",
      "Fold 3 : 0.5981363116837001\n",
      "Fold 4 : 0.5887067623276507\n",
      "Fold 5 : 0.5733632717813976\n"
     ]
    }
   ],
   "source": [
    "scores2=skf_model(RandomForestClassifier(random_state=42,**rf_params_l2,n_jobs=-1),X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7151469934927255, 0.5863594454733412, 0.6507532194830333)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.6213000594420688 before removing the outliers\n",
    "scores1,scores2, np.mean([scores1,scores2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_params_l1 = {\n",
    "    'iterations': 150,\n",
    "    'depth': 8,\n",
    "    'learning_rate': 0.0583328291135858,\n",
    "    'l2_leaf_reg': 1.718355353927,\n",
    "    'random_strength': 0.0364936343793558,\n",
    "    'od_type': \"Iter\", \n",
    "    'od_wait': 38,\n",
    "    'bootstrap_type': \"Bayesian\",\n",
    "    'grow_policy': 'Lossguide',\n",
    "    'bagging_temperature': 4.81608188901775,\n",
    "    'eval_metric': 'AUC', # AUC\n",
    "    'loss_function': 'Logloss',\n",
    "    #'random_seed': 42,\n",
    "    #'auto_class_weights': 'Balanced',\n",
    "    'verbose': False\n",
    "}\n",
    "# tuned somewhat\n",
    "cat_params_l2 = {'iterations': 2052,\n",
    "                 'depth': 3,\n",
    "                 'learning_rate': 0.005860280381371149,\n",
    "                 'l2_leaf_reg': 3.915641769216947,\n",
    "                 'random_strength': 4.589849045106614,\n",
    "                 'od_type': 'IncToDec',\n",
    "                 'od_wait': 24,\n",
    "                 'bootstrap_type': 'Bernoulli',\n",
    "                 'verbose': False, # False\n",
    "                 'grow_policy': 'Depthwise',\n",
    "                 'loss_function':'Logloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7186869902489976\n",
      "Fold 2 : 0.7105908265488873\n",
      "Fold 3 : 0.709094246352953\n",
      "Fold 4 : 0.7060278569511769\n",
      "Fold 5 : 0.7165366117997698\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "scores1=skf_model(CatBoostClassifier(**cat_params_l1),X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5929738849765258\n",
      "Fold 2 : 0.5819420625393015\n",
      "Fold 3 : 0.5969676920003995\n",
      "Fold 4 : 0.5842326750428632\n",
      "Fold 5 : 0.577475424677901\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "scores2=skf_model(CatBoostClassifier(**cat_params_l2,random_state=42),X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5867183478473982"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.712187306380357, 0.5867183478473982, 0.6494528271138775)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1,scores2, np.mean([scores1,scores2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params_l1 = {'n_estimators': 786,\n",
    "                'learning_rate': 0.008022202426311022,\n",
    "                'num_leaves': 212,\n",
    "                'max_depth': 9,\n",
    "                'min_child_samples': 105,\n",
    "                'min_child_weight': 15,\n",
    "                'subsample': 0.6241910706861232,\n",
    "                'colsample_bytree': 0.10092252740280591,\n",
    "                'reg_alpha': 0.0898095398969116,\n",
    "                'reg_lambda': 0.04729441023604163,#'n_jobs':-1}\n",
    "}\n",
    "\n",
    "lgbm_params_l2={'n_estimators': 186,\n",
    "                'learning_rate': 0.00458267933206545,\n",
    "                'num_leaves': 231,\n",
    "                'max_depth': 53, \n",
    "                'min_child_samples': 48,\n",
    "                'min_child_weight': 40,\n",
    "                'subsample': 0.872467055832323,\n",
    "                'colsample_bytree': 0.19672292565509458,\n",
    "                'reg_alpha': 0.013519705605919736, \n",
    "                'reg_lambda': 0.05393252179886955\n",
    "                #'n_jobs':-1}\n",
    "}\n",
    "\n",
    "\n",
    "# # #new \n",
    "#lgbm_params_l1={'n_estimators': 854, 'learning_rate': 0.004534684299532389, 'num_leaves': 237, 'max_depth': 177, 'min_child_samples': 86, 'min_child_weight': 39, 'subsample': 0.6297745985460238, 'colsample_bytree': 0.16624671663999285, 'reg_alpha': 0.4147866848224776, 'reg_lambda': 0.18650235966893608}\n",
    "#lgbm_params_l2={'n_estimators': 100, 'learning_rate': 0.044606202448458206, 'num_leaves': 41, 'max_depth': 207, 'min_child_samples': 149, 'min_child_weight': 190, 'subsample': 0.5158023863040262, 'colsample_bytree': 0.2641464920307482, 'reg_alpha': 0.12078683707184015, 'reg_lambda': 0.3067449049533006}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7219381522814583\n",
      "Fold 2 : 0.7151101238681687\n",
      "Fold 3 : 0.7128226935477252\n",
      "Fold 4 : 0.711887703838689\n",
      "Fold 5 : 0.7217735780893675\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "scores1=skf_model(LGBMClassifier(n_jobs=-1,random_state=42,**lgbm_params_l1),X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7167064503250817"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5982174295774648\n",
      "Fold 2 : 0.5793478105527925\n",
      "Fold 3 : 0.5931400290733158\n",
      "Fold 4 : 0.5858142881053414\n",
      "Fold 5 : 0.5705330086617542\n"
     ]
    }
   ],
   "source": [
    "scores2=skf_model(LGBMClassifier(n_jobs=-1,random_state=42,**lgbm_params_l2),X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7167064503250817, 0.5854105131941337, 0.6510584817596077)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.6310383278268565 before removing the outliers\n",
    "scores1,scores2, np.mean([scores1,scores2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                   &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                                   &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                                   &#x27;VSA_EState9&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.10092252740280591,\n",
       "                                learning_rate=0.008022202426311022, max_depth=9,\n",
       "                                min_child_samples=105, min_child_weight=15,\n",
       "                                n_estimators=786, num_leaves=212,\n",
       "                                random_state=42, reg_alpha=0.0898095398969116,\n",
       "                                reg_lambda=0.04729441023604163,\n",
       "                                subsample=0.6241910706861232))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                   &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                                   &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                                   &#x27;VSA_EState9&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.10092252740280591,\n",
       "                                learning_rate=0.008022202426311022, max_depth=9,\n",
       "                                min_child_samples=105, min_child_weight=15,\n",
       "                                n_estimators=786, num_leaves=212,\n",
       "                                random_state=42, reg_alpha=0.0898095398969116,\n",
       "                                reg_lambda=0.04729441023604163,\n",
       "                                subsample=0.6241910706861232))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;,\n",
       "                                  &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;,\n",
       "                                  &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;,\n",
       "                                  &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;,\n",
       "                                  &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;,\n",
       "                                  &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                  &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;,\n",
       "                                  &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;,\n",
       "                                  &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                  &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;, &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;, &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;, &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;, &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.10092252740280591,\n",
       "               learning_rate=0.008022202426311022, max_depth=9,\n",
       "               min_child_samples=105, min_child_weight=15, n_estimators=786,\n",
       "               num_leaves=212, random_state=42, reg_alpha=0.0898095398969116,\n",
       "               reg_lambda=0.04729441023604163, subsample=0.6241910706861232)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['NumHeteroatoms', 'fr_COO',\n",
       "                                                   'fr_COO2']),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['BertzCT', 'Chi1', 'Chi1n',\n",
       "                                                   'Chi1v', 'Chi2n', 'Chi2v',\n",
       "                                                   'Chi3v', 'Chi4n',\n",
       "                                                   'EState_VSA1', 'EState_VSA2',\n",
       "                                                   'ExactMolWt',\n",
       "                                                   'FpDensityMorgan1',\n",
       "                                                   'FpDensityMorgan2',\n",
       "                                                   'FpDensi...\n",
       "                                                   'PEOE_VSA8', 'SMR_VSA10',\n",
       "                                                   'SMR_VSA5', 'SlogP_VSA3',\n",
       "                                                   'VSA_EState9'])])),\n",
       "                ('classifier',\n",
       "                 LGBMClassifier(colsample_bytree=0.10092252740280591,\n",
       "                                learning_rate=0.008022202426311022, max_depth=9,\n",
       "                                min_child_samples=105, min_child_weight=15,\n",
       "                                n_estimators=786, num_leaves=212,\n",
       "                                random_state=42, reg_alpha=0.0898095398969116,\n",
       "                                reg_lambda=0.04729441023604163,\n",
       "                                subsample=0.6241910706861232))])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "lgbm_l1=LGBMClassifier(random_state=42,**lgbm_params_l1)\n",
    "\n",
    "# preprocess\n",
    "x_train,y_train=preprocess(X,y1)\n",
    "y_train=y_train.values.ravel()\n",
    "# get pipeline\n",
    "lgbm_l1=get_pipeline(lgbm_l1,numerical_cols_X)\n",
    "# fit model\n",
    "lgbm_l1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                   &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                                   &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                                   &#x27;VSA_EState9&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.19672292565509458,\n",
       "                                learning_rate=0.00458267933206545, max_depth=53,\n",
       "                                min_child_samples=48, min_child_weight=40,\n",
       "                                n_estimators=186, num_leaves=231,\n",
       "                                random_state=42, reg_alpha=0.013519705605919736,\n",
       "                                reg_lambda=0.05393252179886955,\n",
       "                                subsample=0.872467055832323))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                   &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                                   &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                                   &#x27;VSA_EState9&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.19672292565509458,\n",
       "                                learning_rate=0.00458267933206545, max_depth=53,\n",
       "                                min_child_samples=48, min_child_weight=40,\n",
       "                                n_estimators=186, num_leaves=231,\n",
       "                                random_state=42, reg_alpha=0.013519705605919736,\n",
       "                                reg_lambda=0.05393252179886955,\n",
       "                                subsample=0.872467055832323))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;,\n",
       "                                  &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;,\n",
       "                                  &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;,\n",
       "                                  &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;,\n",
       "                                  &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;,\n",
       "                                  &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                  &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;,\n",
       "                                  &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;,\n",
       "                                  &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                  &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;, &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;, &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;, &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;, &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.19672292565509458,\n",
       "               learning_rate=0.00458267933206545, max_depth=53,\n",
       "               min_child_samples=48, min_child_weight=40, n_estimators=186,\n",
       "               num_leaves=231, random_state=42, reg_alpha=0.013519705605919736,\n",
       "               reg_lambda=0.05393252179886955, subsample=0.872467055832323)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['NumHeteroatoms', 'fr_COO',\n",
       "                                                   'fr_COO2']),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['BertzCT', 'Chi1', 'Chi1n',\n",
       "                                                   'Chi1v', 'Chi2n', 'Chi2v',\n",
       "                                                   'Chi3v', 'Chi4n',\n",
       "                                                   'EState_VSA1', 'EState_VSA2',\n",
       "                                                   'ExactMolWt',\n",
       "                                                   'FpDensityMorgan1',\n",
       "                                                   'FpDensityMorgan2',\n",
       "                                                   'FpDensi...\n",
       "                                                   'PEOE_VSA8', 'SMR_VSA10',\n",
       "                                                   'SMR_VSA5', 'SlogP_VSA3',\n",
       "                                                   'VSA_EState9'])])),\n",
       "                ('classifier',\n",
       "                 LGBMClassifier(colsample_bytree=0.19672292565509458,\n",
       "                                learning_rate=0.00458267933206545, max_depth=53,\n",
       "                                min_child_samples=48, min_child_weight=40,\n",
       "                                n_estimators=186, num_leaves=231,\n",
       "                                random_state=42, reg_alpha=0.013519705605919736,\n",
       "                                reg_lambda=0.05393252179886955,\n",
       "                                subsample=0.872467055832323))])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "lgbm_l2=LGBMClassifier(random_state=42,**lgbm_params_l2)\n",
    "# preprocess\n",
    "x_train,y_train=preprocess(X2,y2)\n",
    "y_train=y_train.values.ravel()\n",
    "# get pipeline\n",
    "lgbm_l2=get_pipeline(lgbm_l2,numerical_cols_X2)\n",
    "# fit model\n",
    "lgbm_l2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X2.columns),len(X.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_l1 = {'n_estimators': 988,\n",
    "                 'learning_rate': 0.010098413045397634,\n",
    "                 'lambda': 0.002140241524002415,\n",
    "                 'alpha': 0.001208993581304336,\n",
    "                 'subsample': 0.769433783780473,\n",
    "                 'colsample_bytree': 0.14579274709142026,\n",
    "                 'max_depth': 85,\n",
    "                 'min_child_weight': 46,\n",
    "                 'eta': 0.0010503096218264492,\n",
    "                 'gamma': 0.13763171873234623, \n",
    "                 'scale_pos_weight': 71,\n",
    "                 'grow_policy': 'lossguide',\n",
    "                 #'n_jobs':-1}\n",
    "}\n",
    "\n",
    "#old\n",
    "# xgb_params_l2={'n_estimators': 625,\n",
    "#                'learning_rate': 0.003762652655389914,\n",
    "#                'lambda': 0.016968894970899047,\n",
    "#                'alpha': 0.0016184051167205714,\n",
    "#                'subsample': 0.6500284901379405,\n",
    "#                'colsample_bytree': 0.23032639126444657,\n",
    "#                'max_depth': 45,\n",
    "#                'min_child_weight': 97,\n",
    "#                'eta': 0.03498419914709866,\n",
    "#                'gamma': 0.8231225832500532,\n",
    "#                'scale_pos_weight': 42,\n",
    "#                'grow_policy': 'lossguide',\n",
    "#                #'n_jobs':-1}\n",
    "# }\n",
    "xgb_params_l2={'n_estimators': 240,\n",
    "               'learning_rate': 0.006496592390654572,\n",
    "               'lambda': 0.017511028649561642,\n",
    "               'alpha': 0.058015038023273506,\n",
    "               'subsample': 0.6034996424008736,\n",
    "               'colsample_bytree': 0.2742590004249605,\n",
    "               'max_depth': 25,\n",
    "               'min_child_weight': 118,\n",
    "               'eta': 0.028692162557239075,\n",
    "               'gamma': 0.009652756679188952,\n",
    "               'scale_pos_weight': 44,\n",
    "               'grow_policy': 'depthwise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7225604317843028\n",
      "Fold 2 : 0.7137142880077632\n",
      "Fold 3 : 0.7142172130586857\n",
      "Fold 4 : 0.7122115544920515\n",
      "Fold 5 : 0.724352773826458\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "scores1=skf_model(XGBClassifier(n_jobs=-1,**xgb_params_l1),X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5939711707746479\n",
      "Fold 2 : 0.5764730892356943\n",
      "Fold 3 : 0.5944515185813998\n",
      "Fold 4 : 0.5889486809107953\n",
      "Fold 5 : 0.5706794015817358\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "scores2=skf_model(XGBClassifier(n_jobs=-1,random_state=42,**xgb_params_l2),X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7174112522338523, 0.5849047722168546, 0.6511580122253534)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.6089709505596688 before removing the outliers\n",
    "scores1,scores2, np.mean([scores1,scores2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan3&#x27;,\n",
       "                                                   &#x27;HallKierAlpha&#x27;,\n",
       "                                                   &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                                   &#x27;MaxAbsEStateIndex&#x27;,\n",
       "                                                   &#x27;MinEStateInde...\n",
       "                               gpu_id=None, grow_policy=&#x27;lossguide&#x27;,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=0.002140241524002415,\n",
       "                               learning_rate=0.010098413045397634, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=85,\n",
       "                               max_leaves=None, min_child_weight=46,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=988, n_jobs=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan3&#x27;,\n",
       "                                                   &#x27;HallKierAlpha&#x27;,\n",
       "                                                   &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                                   &#x27;MaxAbsEStateIndex&#x27;,\n",
       "                                                   &#x27;MinEStateInde...\n",
       "                               gpu_id=None, grow_policy=&#x27;lossguide&#x27;,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=0.002140241524002415,\n",
       "                               learning_rate=0.010098413045397634, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=85,\n",
       "                               max_leaves=None, min_child_weight=46,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=988, n_jobs=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;,\n",
       "                                  &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;,\n",
       "                                  &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;,\n",
       "                                  &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;,\n",
       "                                  &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;,\n",
       "                                  &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                  &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;,\n",
       "                                  &#x27;NumHeteroatoms&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;,\n",
       "                                  &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;,\n",
       "                                  &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                  &#x27;VSA_EState9&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;, &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;, &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;, &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;, &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;, &#x27;NumHeteroatoms&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.001208993581304336, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.14579274709142026, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.0010503096218264492,\n",
       "              eval_metric=None, feature_types=None, gamma=0.13763171873234623,\n",
       "              gpu_id=None, grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, lambda=0.002140241524002415,\n",
       "              learning_rate=0.010098413045397634, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=85, max_leaves=None,\n",
       "              min_child_weight=46, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=988, n_jobs=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('num', MinMaxScaler(),\n",
       "                                                  ['BertzCT', 'Chi1', 'Chi1n',\n",
       "                                                   'Chi1v', 'Chi2n', 'Chi2v',\n",
       "                                                   'Chi3v', 'Chi4n',\n",
       "                                                   'EState_VSA1', 'EState_VSA2',\n",
       "                                                   'ExactMolWt',\n",
       "                                                   'FpDensityMorgan1',\n",
       "                                                   'FpDensityMorgan2',\n",
       "                                                   'FpDensityMorgan3',\n",
       "                                                   'HallKierAlpha',\n",
       "                                                   'HeavyAtomMolWt', 'Kappa3',\n",
       "                                                   'MaxAbsEStateIndex',\n",
       "                                                   'MinEStateInde...\n",
       "                               gpu_id=None, grow_policy='lossguide',\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=0.002140241524002415,\n",
       "                               learning_rate=0.010098413045397634, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=85,\n",
       "                               max_leaves=None, min_child_weight=46,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=988, n_jobs=None, ...))])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "xgb_l1=XGBClassifier(**xgb_params_l1)\n",
    "\n",
    "# preprocess\n",
    "x_train,y_train=preprocess(X,y1)\n",
    "y_train=y_train.values.ravel()\n",
    "# get pipeline\n",
    "xgb_l1=get_pipeline(xgb_l1,numerical_cols_X)\n",
    "# fit model\n",
    "xgb_l1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan3&#x27;,\n",
       "                                                   &#x27;HallKierAlpha&#x27;,\n",
       "                                                   &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                                   &#x27;MaxAbsEStateIndex&#x27;,\n",
       "                                                   &#x27;MinEStateIndex&#x27;,\n",
       "                                                   &#x27;NumHeteroatoms&#x27;,\n",
       "                                                   &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;,\n",
       "                                                   &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_V...\n",
       "                               gpu_id=None, grow_policy=&#x27;depthwise&#x27;,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=0.017511028649561642,\n",
       "                               learning_rate=0.006496592390654572, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=25,\n",
       "                               max_leaves=None, min_child_weight=118,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=240, n_jobs=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan3&#x27;,\n",
       "                                                   &#x27;HallKierAlpha&#x27;,\n",
       "                                                   &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                                   &#x27;MaxAbsEStateIndex&#x27;,\n",
       "                                                   &#x27;MinEStateIndex&#x27;,\n",
       "                                                   &#x27;NumHeteroatoms&#x27;,\n",
       "                                                   &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;,\n",
       "                                                   &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_V...\n",
       "                               gpu_id=None, grow_policy=&#x27;depthwise&#x27;,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=0.017511028649561642,\n",
       "                               learning_rate=0.006496592390654572, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=25,\n",
       "                               max_leaves=None, min_child_weight=118,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=240, n_jobs=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;,\n",
       "                                  &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;,\n",
       "                                  &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;,\n",
       "                                  &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                  &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;,\n",
       "                                  &#x27;NumHeteroatoms&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;,\n",
       "                                  &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;,\n",
       "                                  &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                  &#x27;VSA_EState9&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;, &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;, &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;, &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;, &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;, &#x27;NumHeteroatoms&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.058015038023273506, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.2742590004249605, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.028692162557239075,\n",
       "              eval_metric=None, feature_types=None, gamma=0.009652756679188952,\n",
       "              gpu_id=None, grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, lambda=0.017511028649561642,\n",
       "              learning_rate=0.006496592390654572, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=25, max_leaves=None,\n",
       "              min_child_weight=118, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=240, n_jobs=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('num', MinMaxScaler(),\n",
       "                                                  ['EState_VSA1', 'EState_VSA2',\n",
       "                                                   'ExactMolWt',\n",
       "                                                   'FpDensityMorgan1',\n",
       "                                                   'FpDensityMorgan2',\n",
       "                                                   'FpDensityMorgan3',\n",
       "                                                   'HallKierAlpha',\n",
       "                                                   'HeavyAtomMolWt', 'Kappa3',\n",
       "                                                   'MaxAbsEStateIndex',\n",
       "                                                   'MinEStateIndex',\n",
       "                                                   'NumHeteroatoms',\n",
       "                                                   'PEOE_VSA10', 'PEOE_VSA14',\n",
       "                                                   'PEOE_VSA6', 'PEOE_V...\n",
       "                               gpu_id=None, grow_policy='depthwise',\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               lambda=0.017511028649561642,\n",
       "                               learning_rate=0.006496592390654572, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=25,\n",
       "                               max_leaves=None, min_child_weight=118,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=240, n_jobs=None, ...))])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "xgb_l2=XGBClassifier(random_state=42,**xgb_params_l2)\n",
    "\n",
    "# preprocess\n",
    "x_train,y_train=preprocess(X2,y2)\n",
    "y_train=y_train.values.ravel()\n",
    "# get pipeline\n",
    "xgb_l2=get_pipeline(xgb_l2,numerical_cols_X2)\n",
    "# fit model\n",
    "xgb_l2.fit(x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hist Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_params_l1 = {'learning_rate': 0.1755720838510706,\n",
    "                  'max_iter': 2461,\n",
    "                  'max_depth': 189,\n",
    "                  'max_bins': 175,\n",
    "                  'l2_regularization': 0.7371155470044533,\n",
    "                  'min_samples_leaf': 19,\n",
    "                  'interaction_cst': 'pairwise',\n",
    "                  'max_leaf_nodes': 7,\n",
    "                  'scoring': 'roc_auc'}\n",
    "# Tuned\n",
    "hist_params_l2={'learning_rate': 0.0672877951220294,\n",
    "                'max_iter': 2354,\n",
    "                'max_depth': 28,\n",
    "                'max_bins': 14,\n",
    "                'l2_regularization': 0.28953194462072923,\n",
    "                'min_samples_leaf': 48,\n",
    "                'interaction_cst': 'no_interactions',\n",
    "                'max_leaf_nodes': 3}\n",
    "\n",
    "\n",
    "# old\n",
    "\n",
    "# hist_params_l2={'learning_rate': 0.13574592393722923,\n",
    "#                 'max_iter': 2939,\n",
    "#                 'max_depth': 23,\n",
    "#                 'max_bins': 27,\n",
    "#                 'l2_regularization': 0.21218320471327906,\n",
    "#                 'min_samples_leaf': 63,\n",
    "#                 'interaction_cst': 'no_interactions',\n",
    "#                 'max_leaf_nodes': 4,\n",
    "#                 'scoring': 'loss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7115009715779029\n",
      "Fold 2 : 0.7121458679690901\n",
      "Fold 3 : 0.698497402946823\n",
      "Fold 4 : 0.7022903128312614\n",
      "Fold 5 : 0.7138391022601549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "scores1=skf_model(HistGradientBoostingClassifier(random_state=42,**hist_params_l1),X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5900421801643192\n",
      "Fold 2 : 0.574705596524324\n",
      "Fold 3 : 0.5869782477224053\n",
      "Fold 4 : 0.583563179429044\n",
      "Fold 5 : 0.5688427414721797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "scores2=skf_model(HistGradientBoostingClassifier(random_state=42,**hist_params_l2),X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7076547315170465, 0.5808263890624544, 0.6442405602897505)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.6344600057018648 before removing the outliers\n",
    "scores1,scores2, np.mean([scores1,scores2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan3&#x27;,\n",
       "                                                   &#x27;HallKierAlpha&#x27;,\n",
       "                                                   &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                                   &#x27;MaxAbsEStateIndex&#x27;,\n",
       "                                                   &#x27;MinEStateIndex&#x27;,\n",
       "                                                   &#x27;NumHeteroatoms&#x27;,\n",
       "                                                   &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;,\n",
       "                                                   &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;,\n",
       "                                                   &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                                   &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                                   &#x27;VSA_EState9&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(interaction_cst=&#x27;no_interactions&#x27;,\n",
       "                                                l2_regularization=0.28953194462072923,\n",
       "                                                learning_rate=0.0672877951220294,\n",
       "                                                max_bins=14, max_depth=28,\n",
       "                                                max_iter=2354, max_leaf_nodes=3,\n",
       "                                                min_samples_leaf=48,\n",
       "                                                random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  [&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan3&#x27;,\n",
       "                                                   &#x27;HallKierAlpha&#x27;,\n",
       "                                                   &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                                   &#x27;MaxAbsEStateIndex&#x27;,\n",
       "                                                   &#x27;MinEStateIndex&#x27;,\n",
       "                                                   &#x27;NumHeteroatoms&#x27;,\n",
       "                                                   &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;,\n",
       "                                                   &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;,\n",
       "                                                   &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                                   &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                                   &#x27;VSA_EState9&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 HistGradientBoostingClassifier(interaction_cst=&#x27;no_interactions&#x27;,\n",
       "                                                l2_regularization=0.28953194462072923,\n",
       "                                                learning_rate=0.0672877951220294,\n",
       "                                                max_bins=14, max_depth=28,\n",
       "                                                max_iter=2354, max_leaf_nodes=3,\n",
       "                                                min_samples_leaf=48,\n",
       "                                                random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                 [&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;,\n",
       "                                  &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;,\n",
       "                                  &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;,\n",
       "                                  &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                  &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;,\n",
       "                                  &#x27;NumHeteroatoms&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;,\n",
       "                                  &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;,\n",
       "                                  &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;,\n",
       "                                  &#x27;VSA_EState9&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;, &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;, &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;, &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;, &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;, &#x27;NumHeteroatoms&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(interaction_cst=&#x27;no_interactions&#x27;,\n",
       "                               l2_regularization=0.28953194462072923,\n",
       "                               learning_rate=0.0672877951220294, max_bins=14,\n",
       "                               max_depth=28, max_iter=2354, max_leaf_nodes=3,\n",
       "                               min_samples_leaf=48, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('num', MinMaxScaler(),\n",
       "                                                  ['EState_VSA1', 'EState_VSA2',\n",
       "                                                   'ExactMolWt',\n",
       "                                                   'FpDensityMorgan1',\n",
       "                                                   'FpDensityMorgan2',\n",
       "                                                   'FpDensityMorgan3',\n",
       "                                                   'HallKierAlpha',\n",
       "                                                   'HeavyAtomMolWt', 'Kappa3',\n",
       "                                                   'MaxAbsEStateIndex',\n",
       "                                                   'MinEStateIndex',\n",
       "                                                   'NumHeteroatoms',\n",
       "                                                   'PEOE_VSA10', 'PEOE_VSA14',\n",
       "                                                   'PEOE_VSA6', 'PEOE_VSA7',\n",
       "                                                   'PEOE_VSA8', 'SMR_VSA10',\n",
       "                                                   'SMR_VSA5', 'SlogP_VSA3',\n",
       "                                                   'VSA_EState9'])])),\n",
       "                ('classifier',\n",
       "                 HistGradientBoostingClassifier(interaction_cst='no_interactions',\n",
       "                                                l2_regularization=0.28953194462072923,\n",
       "                                                learning_rate=0.0672877951220294,\n",
       "                                                max_bins=14, max_depth=28,\n",
       "                                                max_iter=2354, max_leaf_nodes=3,\n",
       "                                                min_samples_leaf=48,\n",
       "                                                random_state=42))])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "hist_l2=HistGradientBoostingClassifier(random_state=42,**hist_params_l2)\n",
    "\n",
    "# preprocess\n",
    "x_train,y_train=preprocess(X2,y2)\n",
    "y_train=y_train.values.ravel()\n",
    "# get pipeline\n",
    "hist_l2=get_pipeline(hist_l2,numerical_cols_X2)\n",
    "# fit model\n",
    "hist_l2.fit(x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params_l1 = {'learning_rate': 0.003755536444677597,\n",
    "                'n_estimators': 1650,\n",
    "                'max_depth': 72,\n",
    "                'min_samples_split': 74,\n",
    "                'min_samples_leaf': 78,\n",
    "                'max_features': 'log2',\n",
    "                'subsample': 0.20428215357261675}\n",
    "\n",
    "gb_params_l2={'learning_rate': 0.001689570321780246,\n",
    "              'n_estimators': 769,\n",
    "              'max_depth': 76,\n",
    "              'min_samples_split': 86,\n",
    "              'min_samples_leaf': 74,\n",
    "              'max_features': 'log2',\n",
    "              'subsample': 0.19812972424101377}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7183115001135727\n",
      "Fold 2 : 0.7121755239066992\n",
      "Fold 3 : 0.7077307364321642\n",
      "Fold 4 : 0.7106154811756515\n",
      "Fold 5 : 0.7128282417756102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "scores1=skf_model(GradientBoostingClassifier(random_state=42,**gb_params_l1),X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5912052523474178\n",
      "Fold 2 : 0.5839335734293717\n",
      "Fold 3 : 0.5904681552870157\n",
      "Fold 4 : 0.5872214947474131\n",
      "Fold 5 : 0.5736979336102916\n"
     ]
    }
   ],
   "source": [
    "scores2=skf_model(GradientBoostingClassifier(random_state=42,**gb_params_l2),X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7123322966807396, 0.585305281884302, 0.6488187892825208)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1,scores2, np.mean([scores1,scores2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "estimators_l1=[\n",
    "            ('rf',RandomForestClassifier(random_state=42,**rf_params_l1)),\n",
    "            ('lgbm',LGBMClassifier(random_state=42,**lgbm_params_l1)),\n",
    "            ('xgb',XGBClassifier(**xgb_params_l1))]\n",
    "\n",
    "estimators_l2=[('rf',RandomForestClassifier(random_state=42,**rf_params_l2)),\n",
    "            ('cat',CatBoostClassifier(random_state=42,**cat_params_l2)),\n",
    "            ('lgbm',LGBMClassifier(random_state=42,**lgbm_params_l2)),\n",
    "            ('xgb',XGBClassifier(random_state=42,**xgb_params_l2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vc_weights_l1={0.113851271566289, 0.47922230232379165, 0.2056789714580716,  0.913688205488072,  0.6028434701660855, 0.93217568007266}\n",
    "#tuned\n",
    "vc_weights_l1={\n",
    "               0.36959886757484034,\n",
    "               0.573982270131082,\n",
    "               0.58028298278592476}\n",
    "# tuned\n",
    "vc_weights_l2=[ \n",
    "                0.14665372361915316,\n",
    "                0.4606877513912636,\n",
    "                0.573160391973144, \n",
    "                0.8839181476361347]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7225550128045974\n",
      "Fold 2 : 0.7169289470492118\n",
      "Fold 3 : 0.7128765043071409\n",
      "Fold 4 : 0.7126198782339374\n",
      "Fold 5 : 0.7221271647587437\n"
     ]
    }
   ],
   "source": [
    "# import voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators_l1, \n",
    "                            voting='soft',\n",
    "                            weights=vc_weights_l1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "scores=skf_model(ensemble,X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7174215014307264"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5965933098591549\n",
      "Fold 2 : 0.58151832161436\n",
      "Fold 3 : 0.597112642453699\n",
      "Fold 4 : 0.5870836574151561\n",
      "Fold 5 : 0.5758633721453381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators_l2,\n",
    "                            voting='soft',\n",
    "                            weights=vc_weights_l2,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "scores2=skf_model(ensemble,X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7174215014307264, 0.5876342606975415, 0.652527881064134)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores,scores2, np.mean([scores,scores2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                             lambda=0.002140241524002415,\n",
       "                                                             learning_rate=0.010098413045397634,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=85,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=46,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=988,\n",
       "                                                             n_jobs=None, ...))],\n",
       "                                  n_jobs=-1, voting=&#x27;soft&#x27;,\n",
       "                                  weights={0.36959886757484034,\n",
       "                                           0.573982270131082,\n",
       "                                           0.5802829827859247}))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                             lambda=0.002140241524002415,\n",
       "                                                             learning_rate=0.010098413045397634,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=85,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=46,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=988,\n",
       "                                                             n_jobs=None, ...))],\n",
       "                                  n_jobs=-1, voting=&#x27;soft&#x27;,\n",
       "                                  weights={0.36959886757484034,\n",
       "                                           0.573982270131082,\n",
       "                                           0.5802829827859247}))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;,\n",
       "                                  &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;,\n",
       "                                  &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;,\n",
       "                                  &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;,\n",
       "                                  &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;,\n",
       "                                  &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                  &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;,\n",
       "                                  &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;,\n",
       "                                  &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                  &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;, &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;, &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;, &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;, &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                     max_depth=91,\n",
       "                                                     min_samples_leaf=18,\n",
       "                                                     min_samples_split=10,\n",
       "                                                     n_estimators=1173,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;lgbm&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.10092252740280591,\n",
       "                                             learning_rate=0.008022202426311022,\n",
       "                                             max_depth=9, min_child_samples=105,\n",
       "                                             min_child_weight=15,\n",
       "                                             n_estimators=786, num_leaves=212,\n",
       "                                             r...\n",
       "                                            lambda=0.002140241524002415,\n",
       "                                            learning_rate=0.010098413045397634,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=85,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=46, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=988, n_jobs=None, ...))],\n",
       "                 n_jobs=-1, voting=&#x27;soft&#x27;,\n",
       "                 weights={0.36959886757484034, 0.573982270131082,\n",
       "                          0.5802829827859247})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=91, min_samples_leaf=18,\n",
       "                       min_samples_split=10, n_estimators=1173,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.10092252740280591,\n",
       "               learning_rate=0.008022202426311022, max_depth=9,\n",
       "               min_child_samples=105, min_child_weight=15, n_estimators=786,\n",
       "               num_leaves=212, random_state=42, reg_alpha=0.0898095398969116,\n",
       "               reg_lambda=0.04729441023604163, subsample=0.6241910706861232)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.001208993581304336, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.14579274709142026, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.0010503096218264492,\n",
       "              eval_metric=None, feature_types=None, gamma=0.13763171873234623,\n",
       "              gpu_id=None, grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, lambda=0.002140241524002415,\n",
       "              learning_rate=0.010098413045397634, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=85, max_leaves=None,\n",
       "              min_child_weight=46, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=988, n_jobs=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['NumHeteroatoms', 'fr_COO',\n",
       "                                                   'fr_COO2']),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['BertzCT', 'Chi1', 'Chi1n',\n",
       "                                                   'Chi1v', 'Chi2n', 'Chi2v',\n",
       "                                                   'Chi3v', 'Chi4n',\n",
       "                                                   'EState_VSA1', 'EState_VSA2',\n",
       "                                                   'ExactMolWt',\n",
       "                                                   'FpDensityMorgan1',\n",
       "                                                   'FpDensityMorgan2',\n",
       "                                                   'FpDensi...\n",
       "                                                             lambda=0.002140241524002415,\n",
       "                                                             learning_rate=0.010098413045397634,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=85,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=46,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=988,\n",
       "                                                             n_jobs=None, ...))],\n",
       "                                  n_jobs=-1, voting='soft',\n",
       "                                  weights={0.36959886757484034,\n",
       "                                           0.573982270131082,\n",
       "                                           0.5802829827859247}))])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "vc_l1=VotingClassifier(estimators_l1, \n",
    "                       voting='soft',\n",
    "                       weights=vc_weights_l1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# preprocess\n",
    "x_train,y_train=preprocess(X,y1)\n",
    "y_train=y_train.values.ravel()\n",
    "# get pipeline\n",
    "vc_l1=get_pipeline(vc_l1,numerical_cols_X)\n",
    "# fit model\n",
    "vc_l1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                             learning_rate=0.006496592390654572,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=25,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=118,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=240,\n",
       "                                                             n_jobs=None, ...))],\n",
       "                                  n_jobs=-1, voting=&#x27;soft&#x27;,\n",
       "                                  weights=[0.14665372361915316,\n",
       "                                           0.4606877513912636,\n",
       "                                           0.573160391973144,\n",
       "                                           0.8839181476361347]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;,\n",
       "                                                   &#x27;fr_COO2&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;,\n",
       "                                                   &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;,\n",
       "                                                   &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;,\n",
       "                                                   &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;,\n",
       "                                                   &#x27;ExactMolWt&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan1&#x27;,\n",
       "                                                   &#x27;FpDensityMorgan2&#x27;,\n",
       "                                                   &#x27;FpDensi...\n",
       "                                                             learning_rate=0.006496592390654572,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=25,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=118,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=240,\n",
       "                                                             n_jobs=None, ...))],\n",
       "                                  n_jobs=-1, voting=&#x27;soft&#x27;,\n",
       "                                  weights=[0.14665372361915316,\n",
       "                                           0.4606877513912636,\n",
       "                                           0.573160391973144,\n",
       "                                           0.8839181476361347]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;,\n",
       "                                  &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;,\n",
       "                                  &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;,\n",
       "                                  &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;,\n",
       "                                  &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;,\n",
       "                                  &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;,\n",
       "                                  &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;,\n",
       "                                  &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;,\n",
       "                                  &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;,\n",
       "                                  &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;NumHeteroatoms&#x27;, &#x27;fr_COO&#x27;, &#x27;fr_COO2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BertzCT&#x27;, &#x27;Chi1&#x27;, &#x27;Chi1n&#x27;, &#x27;Chi1v&#x27;, &#x27;Chi2n&#x27;, &#x27;Chi2v&#x27;, &#x27;Chi3v&#x27;, &#x27;Chi4n&#x27;, &#x27;EState_VSA1&#x27;, &#x27;EState_VSA2&#x27;, &#x27;ExactMolWt&#x27;, &#x27;FpDensityMorgan1&#x27;, &#x27;FpDensityMorgan2&#x27;, &#x27;FpDensityMorgan3&#x27;, &#x27;HallKierAlpha&#x27;, &#x27;HeavyAtomMolWt&#x27;, &#x27;Kappa3&#x27;, &#x27;MaxAbsEStateIndex&#x27;, &#x27;MinEStateIndex&#x27;, &#x27;PEOE_VSA10&#x27;, &#x27;PEOE_VSA14&#x27;, &#x27;PEOE_VSA6&#x27;, &#x27;PEOE_VSA7&#x27;, &#x27;PEOE_VSA8&#x27;, &#x27;SMR_VSA10&#x27;, &#x27;SMR_VSA5&#x27;, &#x27;SlogP_VSA3&#x27;, &#x27;VSA_EState9&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                              RandomForestClassifier(max_depth=7,\n",
       "                                                     max_features=&#x27;log2&#x27;,\n",
       "                                                     min_samples_leaf=20,\n",
       "                                                     n_estimators=1371,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;cat&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x00000233B0A80C40&gt;),\n",
       "                             (&#x27;lgbm&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.19672292565509458,\n",
       "                                             learning_rate=0.00458267933206545,\n",
       "                                             max_depth=53, min_child_samples=48,\n",
       "                                             min_chi...\n",
       "                                            lambda=0.017511028649561642,\n",
       "                                            learning_rate=0.006496592390654572,\n",
       "                                            max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=25,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=118, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=240, n_jobs=None, ...))],\n",
       "                 n_jobs=-1, voting=&#x27;soft&#x27;,\n",
       "                 weights=[0.14665372361915316, 0.4606877513912636,\n",
       "                          0.573160391973144, 0.8839181476361347])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=7, max_features=&#x27;log2&#x27;, min_samples_leaf=20,\n",
       "                       n_estimators=1371, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x00000233B0A80C40&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.19672292565509458,\n",
       "               learning_rate=0.00458267933206545, max_depth=53,\n",
       "               min_child_samples=48, min_child_weight=40, n_estimators=186,\n",
       "               num_leaves=231, random_state=42, reg_alpha=0.013519705605919736,\n",
       "               reg_lambda=0.05393252179886955, subsample=0.872467055832323)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.058015038023273506, base_score=None, booster=None,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.2742590004249605, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.028692162557239075,\n",
       "              eval_metric=None, feature_types=None, gamma=0.009652756679188952,\n",
       "              gpu_id=None, grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, lambda=0.017511028649561642,\n",
       "              learning_rate=0.006496592390654572, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=25, max_leaves=None,\n",
       "              min_child_weight=118, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=240, n_jobs=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['NumHeteroatoms', 'fr_COO',\n",
       "                                                   'fr_COO2']),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['BertzCT', 'Chi1', 'Chi1n',\n",
       "                                                   'Chi1v', 'Chi2n', 'Chi2v',\n",
       "                                                   'Chi3v', 'Chi4n',\n",
       "                                                   'EState_VSA1', 'EState_VSA2',\n",
       "                                                   'ExactMolWt',\n",
       "                                                   'FpDensityMorgan1',\n",
       "                                                   'FpDensityMorgan2',\n",
       "                                                   'FpDensi...\n",
       "                                                             learning_rate=0.006496592390654572,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=25,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=118,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             n_estimators=240,\n",
       "                                                             n_jobs=None, ...))],\n",
       "                                  n_jobs=-1, voting='soft',\n",
       "                                  weights=[0.14665372361915316,\n",
       "                                           0.4606877513912636,\n",
       "                                           0.573160391973144,\n",
       "                                           0.8839181476361347]))])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "\n",
    "vc_l2=VotingClassifier(estimators_l2, voting='soft',\n",
    "                       weights=vc_weights_l2,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# preprocess\n",
    "x_train,y_train=preprocess(X2,y2)\n",
    "y_train=y_train.values.ravel()\n",
    "# get pipeline\n",
    "vc_l2=get_pipeline(vc_l2,numerical_cols_X2)\n",
    "# fit model\n",
    "vc_l2.fit(x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.7199060348919071\n",
      "Fold 2 : 0.7174912949789154\n",
      "Fold 3 : 0.7110410101830023\n",
      "Fold 4 : 0.71150345158377\n",
      "Fold 5 : 0.7182648061595429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "stacker=StackingClassifier(estimators_l1,final_estimator=LogisticRegression(),n_jobs=-1)\n",
    "\n",
    "scores=skf_model(stacker,X,y1,numerical_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 : 0.5908898180751173\n",
      "Fold 2 : 0.5846710112616476\n",
      "Fold 3 : 0.5932860198408736\n",
      "Fold 4 : 0.5919803989687518\n",
      "Fold 5 : 0.575217582101164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "stacker=StackingClassifier(estimators_l2,final_estimator=LogisticRegression(),n_jobs=-1)\n",
    "\n",
    "scores2=skf_model(stacker,X2,y2,numerical_cols_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7156413195594276, 0.5872089660495108, 0.6514251428044692)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores,scores2,np.mean([scores,scores2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # #params for catboost\n",
    "    # params = {\n",
    "    #     'loss_function': 'Logloss',\n",
    "    #     'eval_metric': 'AUC',\n",
    "    #     'verbose': False,\n",
    "    #     'random_seed': 42,\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "    #     'iterations': trial.suggest_int('iterations', 100, 4000),\n",
    "    #     'depth': trial.suggest_int('depth', 3, 10),\n",
    "    #     'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameter tuning using optuna for catboost\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier,GradientBoostingClassifier,RandomForestClassifier,VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from optuna import Trial\n",
    "def objective(trial: Trial):\n",
    "    w1=trial.suggest_float(\"w1\",0,1.0)\n",
    "    w2=trial.suggest_float(\"w2\",0,1.0)\n",
    "    w3=trial.suggest_float(\"w3\",0,1.0)\n",
    "    w4=trial.suggest_float(\"w4\",0,1.0)\n",
    "    w5=trial.suggest_float(\"w5\",0,1.0)\n",
    "    w6=trial.suggest_float(\"w6\",0,1.0)\n",
    "    weights=[w1,w2,w3,w4,w5,w6]\n",
    "    # create the ensemble model\n",
    "    model_obj = VotingClassifier(estimators_l1, voting='soft',\n",
    "                       weights=weights,\n",
    "                        n_jobs=-1)\n",
    "    skf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    scores=[]\n",
    "    i=0\n",
    "    for train_index, test_index in skf.split(X, y1):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y1.iloc[train_index,:], y1.iloc[test_index,:]\n",
    "        # preprocess\n",
    "        X_train,y_train=preprocess(X_train,y_train)\n",
    "        y_train=y_train.values.ravel()\n",
    "        y_test=y_test.values.ravel()\n",
    "        # get pipeline\n",
    "        model=get_pipeline(model_obj,numerical_cols_X2)\n",
    "        # fit model\n",
    "        model.fit(X_train,y_train)\n",
    "        # predict\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        val_preds = np.array(y_pred)[:,1]\n",
    "        score=roc_auc_score(y_test,val_preds)\n",
    "        scores.append(score)\n",
    "        trial.report(score, i)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        i+=1\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-02 22:30:22,735] A new study created in memory with name: no-name-25a7727d-3047-4cb6-894d-d789ebe6e9ba\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2feb55db2f441cc9c047ac28dfbf58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-02 22:34:34,698] Trial 4 pruned. \n",
      "[I 2023-07-02 22:34:51,857] Trial 5 pruned. \n",
      "[I 2023-07-02 22:35:27,280] Trial 0 pruned. \n",
      "[I 2023-07-02 22:37:28,220] Trial 2 pruned. \n",
      "[I 2023-07-02 22:41:31,570] Trial 3 finished with value: 0.7149350322984679 and parameters: {'w1': 0.8121305060751821, 'w2': 0.368931669092014, 'w3': 0.7803238405132261, 'w4': 0.8587092568422987, 'w5': 0.8092576934642723, 'w6': 0.6393101936281794}. Best is trial 3 with value: 0.7149350322984679.\n",
      "[I 2023-07-02 22:41:52,594] Trial 7 finished with value: 0.7148680342579115 and parameters: {'w1': 0.264550888662334, 'w2': 0.782040355693804, 'w3': 0.05322669877126618, 'w4': 0.5343927189924328, 'w5': 0.8216300398937468, 'w6': 0.6862951033166491}. Best is trial 3 with value: 0.7149350322984679.\n",
      "[I 2023-07-02 22:42:09,276] Trial 8 pruned. \n",
      "[I 2023-07-02 22:42:32,505] Trial 9 pruned. \n",
      "[I 2023-07-02 22:42:54,755] Trial 11 pruned. \n",
      "[I 2023-07-02 22:43:17,375] Trial 10 pruned. \n",
      "[I 2023-07-02 22:43:37,820] Trial 1 pruned. \n",
      "[I 2023-07-02 22:43:56,038] Trial 6 pruned. \n",
      "[I 2023-07-02 22:47:12,977] Trial 13 pruned. \n",
      "[I 2023-07-02 22:47:40,970] Trial 14 pruned. \n",
      "[I 2023-07-02 22:47:57,686] Trial 15 pruned. \n",
      "[I 2023-07-02 22:48:23,693] Trial 16 pruned. \n",
      "[I 2023-07-02 22:48:38,685] Trial 17 pruned. \n",
      "[I 2023-07-02 22:48:58,055] Trial 18 pruned. \n",
      "[I 2023-07-02 22:52:51,633] Trial 20 pruned. \n",
      "[I 2023-07-02 22:53:12,915] Trial 21 pruned. \n",
      "[I 2023-07-02 22:53:51,671] Trial 23 pruned. \n",
      "[I 2023-07-02 22:55:10,256] Trial 12 finished with value: 0.7150701884693926 and parameters: {'w1': 0.6722949407003089, 'w2': 0.5355799820103162, 'w3': 0.1529234135487555, 'w4': 0.9511270508222243, 'w5': 0.9814676532936242, 'w6': 0.40162081373045044}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 22:56:12,368] Trial 22 pruned. \n",
      "[I 2023-07-02 22:56:50,952] Trial 24 pruned. \n",
      "[I 2023-07-02 22:57:11,283] Trial 25 pruned. \n",
      "[I 2023-07-02 22:57:27,225] Trial 19 finished with value: 0.7150088414114019 and parameters: {'w1': 0.8222791309935518, 'w2': 0.6208050546481015, 'w3': 0.5031020329938671, 'w4': 0.9769299802263798, 'w5': 0.7819949792772318, 'w6': 0.039890083986761304}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 23:00:38,734] Trial 26 pruned. \n",
      "[I 2023-07-02 23:00:57,490] Trial 27 pruned. \n",
      "[I 2023-07-02 23:06:56,322] Trial 28 pruned. \n",
      "[I 2023-07-02 23:08:13,454] Trial 29 finished with value: 0.7150186008722195 and parameters: {'w1': 0.7023538225775324, 'w2': 0.5032346687150056, 'w3': 0.44679422518344614, 'w4': 0.8589310142767954, 'w5': 0.994017129974779, 'w6': 0.6705273549753247}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 23:09:16,855] Trial 30 pruned. \n",
      "[I 2023-07-02 23:09:49,698] Trial 31 finished with value: 0.7149724582203373 and parameters: {'w1': 0.6577253850325554, 'w2': 0.5113026572988109, 'w3': 0.14281740632798134, 'w4': 0.7751243335611921, 'w5': 0.9994196643006025, 'w6': 0.6286112363368112}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 23:10:12,957] Trial 32 finished with value: 0.7149954236173336 and parameters: {'w1': 0.6707547848051467, 'w2': 0.5122163360798448, 'w3': 0.12822505513331897, 'w4': 0.7621828778624425, 'w5': 0.9166558871427481, 'w6': 0.658158853093648}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 23:10:31,008] Trial 33 finished with value: 0.7150215816830687 and parameters: {'w1': 0.6590278737841969, 'w2': 0.5359381649133284, 'w3': 0.38162297672061246, 'w4': 0.8636201233426724, 'w5': 0.9096767398011641, 'w6': 0.19427659119606736}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 23:14:04,293] Trial 34 finished with value: 0.71501966087371 and parameters: {'w1': 0.6629080601799312, 'w2': 0.5502851794505887, 'w3': 0.391124471508142, 'w4': 0.8647161671640667, 'w5': 0.9050151080814329, 'w6': 0.17064820967375502}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 23:14:24,289] Trial 35 pruned. \n",
      "[I 2023-07-02 23:14:49,814] Trial 38 pruned. \n",
      "[I 2023-07-02 23:16:06,867] Trial 41 pruned. \n",
      "[I 2023-07-02 23:16:26,327] Trial 37 pruned. \n",
      "[I 2023-07-02 23:20:24,775] Trial 36 pruned. \n",
      "[I 2023-07-02 23:23:59,537] Trial 39 finished with value: 0.7150353253970329 and parameters: {'w1': 0.648634446438457, 'w2': 0.457130070186189, 'w3': 0.5564704951135948, 'w4': 0.9155641783029738, 'w5': 0.9219254354790216, 'w6': 0.5852391511227102}. Best is trial 12 with value: 0.7150701884693926.\n",
      "[I 2023-07-02 23:24:21,530] Trial 40 finished with value: 0.7150932007821688 and parameters: {'w1': 0.5942336986445661, 'w2': 0.45004126097670394, 'w3': 0.22899804810635754, 'w4': 0.9138741063634711, 'w5': 0.9147652608235067, 'w6': 0.20791503554518365}. Best is trial 40 with value: 0.7150932007821688.\n",
      "[I 2023-07-02 23:25:06,266] Trial 46 pruned. \n",
      "[I 2023-07-02 23:28:32,772] Trial 42 finished with value: 0.7150725222139118 and parameters: {'w1': 0.5853065410647352, 'w2': 0.43361058999994717, 'w3': 0.250853375126675, 'w4': 0.8668335448120605, 'w5': 0.8850498072902712, 'w6': 0.16393106682060865}. Best is trial 40 with value: 0.7150932007821688.\n",
      "[I 2023-07-02 23:28:57,923] Trial 43 finished with value: 0.715088273145523 and parameters: {'w1': 0.5917027840954395, 'w2': 0.457610012016462, 'w3': 0.37723768903266247, 'w4': 0.9154098513516178, 'w5': 0.8731059127375551, 'w6': 0.14956055909444152}. Best is trial 40 with value: 0.7150932007821688.\n",
      "[I 2023-07-02 23:29:20,026] Trial 44 finished with value: 0.7151013734534766 and parameters: {'w1': 0.5978792073469593, 'w2': 0.5797188305659391, 'w3': 0.2526562782356834, 'w4': 0.9298287479203007, 'w5': 0.8491997942021854, 'w6': 0.15149846218708835}. Best is trial 44 with value: 0.7151013734534766.\n",
      "[I 2023-07-02 23:29:43,339] Trial 47 pruned. \n",
      "[I 2023-07-02 23:30:53,511] Trial 45 pruned. \n",
      "[I 2023-07-02 23:35:52,628] Trial 54 pruned. \n",
      "[I 2023-07-02 23:37:04,559] Trial 55 pruned. \n",
      "[I 2023-07-02 23:39:05,037] Trial 48 finished with value: 0.715071046554431 and parameters: {'w1': 0.5892822773639732, 'w2': 0.39837277984450614, 'w3': 0.3652537998126359, 'w4': 0.8232876252244389, 'w5': 0.8547098445556803, 'w6': 0.47443506930838686}. Best is trial 44 with value: 0.7151013734534766.\n",
      "[I 2023-07-02 23:39:33,444] Trial 49 finished with value: 0.7150853729963368 and parameters: {'w1': 0.6105820199332027, 'w2': 0.5774836367690197, 'w3': 0.2639300627768723, 'w4': 0.9250639902715129, 'w5': 0.8455275143711186, 'w6': 0.2873429086240041}. Best is trial 44 with value: 0.7151013734534766.\n",
      "[I 2023-07-02 23:40:20,691] Trial 50 finished with value: 0.715149825286643 and parameters: {'w1': 0.5230292342979932, 'w2': 0.39467823106878097, 'w3': 0.2539560330118204, 'w4': 0.9323005418851945, 'w5': 0.8535766968300263, 'w6': 0.27305182738009437}. Best is trial 50 with value: 0.715149825286643.\n",
      "[I 2023-07-02 23:43:15,315] Trial 57 pruned. \n",
      "[I 2023-07-02 23:43:52,761] Trial 51 finished with value: 0.7151469517184091 and parameters: {'w1': 0.5276312991272093, 'w2': 0.4153492545496076, 'w3': 0.27066671319693425, 'w4': 0.9256208939219236, 'w5': 0.8438802459937531, 'w6': 0.3569958451296718}. Best is trial 50 with value: 0.715149825286643.\n",
      "[I 2023-07-02 23:44:12,537] Trial 52 finished with value: 0.7151511863250753 and parameters: {'w1': 0.5375835275015775, 'w2': 0.3751119578962242, 'w3': 0.2381497285619456, 'w4': 0.9347619497006634, 'w5': 0.8431921472158492, 'w6': 0.35048816906871383}. Best is trial 52 with value: 0.7151511863250753.\n",
      "[I 2023-07-02 23:44:27,697] Trial 53 finished with value: 0.7151582019864998 and parameters: {'w1': 0.5091310400806683, 'w2': 0.3914117108549683, 'w3': 0.23440951343815714, 'w4': 0.9366059551096759, 'w5': 0.8319607121315304, 'w6': 0.2813664071835593}. Best is trial 53 with value: 0.7151582019864998.\n",
      "[I 2023-07-02 23:45:49,699] Trial 60 pruned. \n",
      "[I 2023-07-02 23:49:06,464] Trial 56 finished with value: 0.7151432292938791 and parameters: {'w1': 0.533982735577991, 'w2': 0.37687747950199085, 'w3': 0.2640586535713774, 'w4': 0.935720756116849, 'w5': 0.8337840001763436, 'w6': 0.08889393201963058}. Best is trial 53 with value: 0.7151582019864998.\n",
      "[I 2023-07-02 23:51:31,968] Trial 58 finished with value: 0.7151688278467838 and parameters: {'w1': 0.4597048375025106, 'w2': 0.35698424084010055, 'w3': 0.3041923679514326, 'w4': 0.9444729546686628, 'w5': 0.8631469660379896, 'w6': 0.30866380663856136}. Best is trial 58 with value: 0.7151688278467838.\n",
      "[I 2023-07-02 23:51:50,187] Trial 59 finished with value: 0.715173066604811 and parameters: {'w1': 0.46779929781087176, 'w2': 0.3421829038626296, 'w3': 0.3037063896493461, 'w4': 0.9270423540339092, 'w5': 0.8370102596822282, 'w6': 0.30713734542509996}. Best is trial 59 with value: 0.715173066604811.\n",
      "[I 2023-07-02 23:53:31,823] Trial 66 pruned. \n",
      "[I 2023-07-02 23:54:20,517] Trial 61 finished with value: 0.7151145954856277 and parameters: {'w1': 0.5534034435860734, 'w2': 0.4639025195854814, 'w3': 0.3396572724475875, 'w4': 0.9193899741260015, 'w5': 0.8320098968077334, 'w6': 0.3006932079648289}. Best is trial 59 with value: 0.715173066604811.\n",
      "[I 2023-07-02 23:54:52,195] Trial 62 pruned. \n",
      "[I 2023-07-02 23:55:07,947] Trial 63 pruned. \n",
      "[I 2023-07-02 23:55:26,021] Trial 64 pruned. \n",
      "[I 2023-07-02 23:55:58,286] Trial 67 pruned. \n",
      "[I 2023-07-02 23:56:15,215] Trial 68 pruned. \n",
      "[I 2023-07-02 23:56:48,375] Trial 65 pruned. \n",
      "[I 2023-07-02 23:59:16,144] Trial 71 pruned. \n",
      "[I 2023-07-02 23:59:34,765] Trial 72 pruned. \n",
      "[I 2023-07-02 23:59:55,233] Trial 73 pruned. \n",
      "[I 2023-07-03 00:05:15,881] Trial 77 pruned. \n",
      "[I 2023-07-03 00:05:39,404] Trial 78 pruned. \n",
      "[I 2023-07-03 00:06:23,644] Trial 69 finished with value: 0.715174990264108 and parameters: {'w1': 0.4167822960000968, 'w2': 0.36959886757484034, 'w3': 0.2931434152156229, 'w4': 0.9973982270131082, 'w5': 0.9547103999896646, 'w6': 0.38028298278592476}. Best is trial 69 with value: 0.715174990264108.\n",
      "[I 2023-07-03 00:07:33,606] Trial 70 finished with value: 0.7151530994933479 and parameters: {'w1': 0.4431137289776568, 'w2': 0.36107095016596874, 'w3': 0.29278605627897014, 'w4': 0.9702781630915769, 'w5': 0.9543905072719152, 'w6': 0.3661696652010374}. Best is trial 69 with value: 0.715174990264108.\n",
      "[I 2023-07-03 00:09:44,754] Trial 74 finished with value: 0.7151304507866373 and parameters: {'w1': 0.43062467845792, 'w2': 0.3836051114407944, 'w3': 0.2979178390235548, 'w4': 0.804088071453319, 'w5': 0.8046615242849224, 'w6': 0.37650149335076155}. Best is trial 69 with value: 0.715174990264108.\n",
      "[I 2023-07-03 00:10:12,947] Trial 75 finished with value: 0.7151594632336117 and parameters: {'w1': 0.4934517245571897, 'w2': 0.3674028677371928, 'w3': 0.27581539902193963, 'w4': 0.8906509055702615, 'w5': 0.8095898952471712, 'w6': 0.3855431084877832}. Best is trial 69 with value: 0.715174990264108.\n",
      "[I 2023-07-03 00:10:56,279] Trial 76 finished with value: 0.7151058801892993 and parameters: {'w1': 0.48922309466469294, 'w2': 0.3792793701195549, 'w3': 0.28853532926408676, 'w4': 0.7991713980807644, 'w5': 0.8061505246772712, 'w6': 0.3777486993897713}. Best is trial 69 with value: 0.715174990264108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-03 00:14:51,028] Trial 79 finished with value: 0.7151340343857795 and parameters: {'w1': 0.5022071347443534, 'w2': 0.3759217126408302, 'w3': 0.32914775896450077, 'w4': 0.8836623374260081, 'w5': 0.8234182730263342, 'w6': 0.24085606690621703}. Best is trial 69 with value: 0.715174990264108.\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=2, min_early_stopping_rate=0)\n",
    "study = optuna.create_study(pruner=pruner,sampler=sampler,direction='maximize')\n",
    "study.optimize(objective, n_trials=100,n_jobs=-1,show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668355c10a764b69ad651a49f07bfebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-02 04:38:00,850] Trial 100 pruned. \n",
      "[I 2023-07-02 04:38:08,061] Trial 106 pruned. \n",
      "[I 2023-07-02 04:38:09,229] Trial 101 pruned. \n",
      "[I 2023-07-02 04:38:11,691] Trial 107 pruned. \n",
      "[I 2023-07-02 04:38:15,301] Trial 103 pruned. \n",
      "[I 2023-07-02 04:38:19,809] Trial 105 pruned. \n",
      "[I 2023-07-02 04:38:22,367] Trial 104 pruned. \n",
      "[I 2023-07-02 04:38:36,718] Trial 102 finished with value: 0.5853678041685173 and parameters: {'n_estimators': 518, 'learning_rate': 0.01628925247457682, 'lambda': 0.026769843999572506, 'alpha': 0.0894977092439457, 'subsample': 0.46765780750256974, 'colsample_bytree': 0.4327735480894985, 'max_depth': 8, 'min_child_weight': 95, 'eta': 0.02023749129398292, 'gamma': 0.002521154936835588, 'scale_pos_weight': 76, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:38:44,811] Trial 108 pruned. \n",
      "[I 2023-07-02 04:39:25,357] Trial 114 pruned. \n",
      "[I 2023-07-02 04:39:29,203] Trial 116 pruned. \n",
      "[I 2023-07-02 04:39:38,474] Trial 109 finished with value: 0.5844906725185658 and parameters: {'n_estimators': 496, 'learning_rate': 0.004997815615681226, 'lambda': 0.03181119911796983, 'alpha': 0.080751340924699, 'subsample': 0.5042477670351685, 'colsample_bytree': 0.4587049073092854, 'max_depth': 206, 'min_child_weight': 115, 'eta': 0.0084576472510797, 'gamma': 0.01320773500343454, 'scale_pos_weight': 40, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:40:11,272] Trial 118 pruned. \n",
      "[I 2023-07-02 04:40:20,055] Trial 119 pruned. \n",
      "[I 2023-07-02 04:40:37,400] Trial 112 finished with value: 0.5838737519489365 and parameters: {'n_estimators': 815, 'learning_rate': 0.0050815785675112895, 'lambda': 0.034067627576612566, 'alpha': 0.07999553774691523, 'subsample': 0.49715585894422243, 'colsample_bytree': 0.4657845486521678, 'max_depth': 208, 'min_child_weight': 96, 'eta': 0.007895226470355182, 'gamma': 0.0123149267168234, 'scale_pos_weight': 76, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:40:40,671] Trial 115 finished with value: 0.5853268783551366 and parameters: {'n_estimators': 796, 'learning_rate': 0.005571790023834978, 'lambda': 0.03224809911561858, 'alpha': 0.08885586335432928, 'subsample': 0.5017654278750877, 'colsample_bytree': 0.45537198458926004, 'max_depth': 23, 'min_child_weight': 115, 'eta': 0.016607424593893073, 'gamma': 0.012314278857692144, 'scale_pos_weight': 90, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:40:41,158] Trial 111 finished with value: 0.5848367410166515 and parameters: {'n_estimators': 793, 'learning_rate': 0.0044799844066741945, 'lambda': 0.033163005855532, 'alpha': 0.08937343711848918, 'subsample': 0.5043221197749425, 'colsample_bytree': 0.45934950076582215, 'max_depth': 206, 'min_child_weight': 95, 'eta': 0.008344192557527528, 'gamma': 0.012214778291384228, 'scale_pos_weight': 32, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:41:19,234] Trial 110 finished with value: 0.5845702828638935 and parameters: {'n_estimators': 1346, 'learning_rate': 0.00524720332073814, 'lambda': 0.03206082759959376, 'alpha': 0.08149905314729326, 'subsample': 0.4968369655378923, 'colsample_bytree': 0.45729747700819673, 'max_depth': 208, 'min_child_weight': 96, 'eta': 0.008563681883103797, 'gamma': 0.012822228875414048, 'scale_pos_weight': 40, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:41:25,842] Trial 121 pruned. \n",
      "[I 2023-07-02 04:41:32,934] Trial 123 pruned. \n",
      "[I 2023-07-02 04:41:42,615] Trial 122 pruned. \n",
      "[I 2023-07-02 04:41:52,428] Trial 113 finished with value: 0.5842725366024794 and parameters: {'n_estimators': 1343, 'learning_rate': 0.0051860703950053705, 'lambda': 0.03354363421544118, 'alpha': 0.08105110944778599, 'subsample': 0.49480130302000647, 'colsample_bytree': 0.45905729253858385, 'max_depth': 209, 'min_child_weight': 80, 'eta': 0.00760685700428242, 'gamma': 0.012431124477197178, 'scale_pos_weight': 38, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:41:53,774] Trial 120 pruned. \n",
      "[I 2023-07-02 04:41:58,800] Trial 124 pruned. \n",
      "[I 2023-07-02 04:41:59,925] Trial 127 pruned. \n",
      "[I 2023-07-02 04:42:11,260] Trial 125 pruned. \n",
      "[I 2023-07-02 04:42:29,667] Trial 130 pruned. \n",
      "[I 2023-07-02 04:42:47,314] Trial 134 pruned. \n",
      "[I 2023-07-02 04:42:48,822] Trial 133 pruned. \n",
      "[I 2023-07-02 04:42:57,997] Trial 136 pruned. \n",
      "[I 2023-07-02 04:43:05,622] Trial 126 finished with value: 0.5852573478972937 and parameters: {'n_estimators': 933, 'learning_rate': 0.009584545937670939, 'lambda': 0.024435392079656067, 'alpha': 0.09645215416835676, 'subsample': 0.4273841268718832, 'colsample_bytree': 0.519499978046771, 'max_depth': 17, 'min_child_weight': 114, 'eta': 0.023839203809417123, 'gamma': 0.0011005863314589234, 'scale_pos_weight': 63, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:43:10,180] Trial 132 pruned. \n",
      "[I 2023-07-02 04:43:17,864] Trial 129 pruned. \n",
      "[I 2023-07-02 04:43:18,697] Trial 128 finished with value: 0.5850797947139723 and parameters: {'n_estimators': 906, 'learning_rate': 0.008962911245065902, 'lambda': 0.03838234090362497, 'alpha': 0.07384985137400764, 'subsample': 0.35471977210255706, 'colsample_bytree': 0.5162025101800382, 'max_depth': 17, 'min_child_weight': 106, 'eta': 0.02412502821355708, 'gamma': 0.0011473820393057797, 'scale_pos_weight': 90, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:43:19,642] Trial 131 pruned. \n",
      "[I 2023-07-02 04:43:43,225] Trial 137 pruned. \n",
      "[I 2023-07-02 04:43:55,269] Trial 117 finished with value: 0.5860992510030806 and parameters: {'n_estimators': 1981, 'learning_rate': 0.002927742337770444, 'lambda': 0.0351548802339801, 'alpha': 0.08918789156099328, 'subsample': 0.5999265762505608, 'colsample_bytree': 0.3566509526542688, 'max_depth': 17, 'min_child_weight': 114, 'eta': 0.024501465731360472, 'gamma': 0.008247909453274471, 'scale_pos_weight': 87, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:43:55,976] Trial 139 pruned. \n",
      "[I 2023-07-02 04:44:02,580] Trial 135 pruned. \n",
      "[I 2023-07-02 04:44:03,914] Trial 141 pruned. \n",
      "[I 2023-07-02 04:44:11,327] Trial 142 pruned. \n",
      "[I 2023-07-02 04:44:25,529] Trial 145 pruned. \n",
      "[I 2023-07-02 04:44:30,521] Trial 148 pruned. \n",
      "[I 2023-07-02 04:44:58,839] Trial 144 pruned. \n",
      "[I 2023-07-02 04:45:03,491] Trial 138 finished with value: 0.585492308214767 and parameters: {'n_estimators': 1221, 'learning_rate': 0.007037421327171508, 'lambda': 0.04025250941283232, 'alpha': 0.07752175876854786, 'subsample': 0.4455809931673499, 'colsample_bytree': 0.4850770768164518, 'max_depth': 229, 'min_child_weight': 135, 'eta': 0.005852046093236729, 'gamma': 0.009506375672929179, 'scale_pos_weight': 44, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:45:08,367] Trial 140 finished with value: 0.5855390063023794 and parameters: {'n_estimators': 1038, 'learning_rate': 0.006693146946108135, 'lambda': 0.044995762521111884, 'alpha': 0.0857236964297081, 'subsample': 0.4501156614400753, 'colsample_bytree': 0.4990073443529607, 'max_depth': 233, 'min_child_weight': 132, 'eta': 0.005729284549235618, 'gamma': 0.010164789651901004, 'scale_pos_weight': 45, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:45:20,011] Trial 146 pruned. \n",
      "[I 2023-07-02 04:45:24,285] Trial 147 pruned. \n",
      "[I 2023-07-02 04:45:31,749] Trial 153 pruned. \n",
      "[I 2023-07-02 04:45:39,194] Trial 143 pruned. \n",
      "[I 2023-07-02 04:45:43,832] Trial 154 pruned. \n",
      "[I 2023-07-02 04:46:08,979] Trial 152 pruned. \n",
      "[I 2023-07-02 04:46:24,822] Trial 151 finished with value: 0.5841214842162401 and parameters: {'n_estimators': 413, 'learning_rate': 0.006906329122951483, 'lambda': 0.030648897231985425, 'alpha': 0.08653768254198811, 'subsample': 0.6348103200373626, 'colsample_bytree': 0.43735972574571047, 'max_depth': 219, 'min_child_weight': 119, 'eta': 0.029857356353970875, 'gamma': 0.004733670822096132, 'scale_pos_weight': 28, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:46:35,501] Trial 155 finished with value: 0.5845988603271925 and parameters: {'n_estimators': 476, 'learning_rate': 0.0062636545334353025, 'lambda': 0.022451888608130594, 'alpha': 0.08745261305255227, 'subsample': 0.39331711328146124, 'colsample_bytree': 0.4486742389591639, 'max_depth': 217, 'min_child_weight': 129, 'eta': 0.002607898701603585, 'gamma': 0.0041703375387267426, 'scale_pos_weight': 52, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:46:36,338] Trial 150 pruned. \n",
      "[I 2023-07-02 04:46:37,079] Trial 159 pruned. \n",
      "[I 2023-07-02 04:46:46,508] Trial 157 pruned. \n",
      "[I 2023-07-02 04:46:58,913] Trial 162 pruned. \n",
      "[I 2023-07-02 04:47:04,511] Trial 149 finished with value: 0.5848101965768622 and parameters: {'n_estimators': 1131, 'learning_rate': 0.006522094336979118, 'lambda': 0.03018850953256997, 'alpha': 0.08994369991751963, 'subsample': 0.6240185286748705, 'colsample_bytree': 0.43807771639385273, 'max_depth': 97, 'min_child_weight': 128, 'eta': 0.02909756328034263, 'gamma': 0.008167697300773694, 'scale_pos_weight': 53, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:47:10,453] Trial 161 pruned. \n",
      "[I 2023-07-02 04:47:26,711] Trial 164 pruned. \n",
      "[I 2023-07-02 04:47:31,456] Trial 165 pruned. \n",
      "[I 2023-07-02 04:47:32,283] Trial 156 pruned. \n",
      "[I 2023-07-02 04:47:45,142] Trial 160 pruned. \n",
      "[I 2023-07-02 04:47:47,309] Trial 167 pruned. \n",
      "[I 2023-07-02 04:47:51,919] Trial 166 pruned. \n",
      "[I 2023-07-02 04:48:29,888] Trial 170 pruned. \n",
      "[I 2023-07-02 04:48:36,098] Trial 158 pruned. \n",
      "[I 2023-07-02 04:48:44,143] Trial 173 pruned. \n",
      "[I 2023-07-02 04:49:07,070] Trial 168 finished with value: 0.5858448084983061 and parameters: {'n_estimators': 886, 'learning_rate': 0.00861342744898608, 'lambda': 0.048138943196224554, 'alpha': 0.07563030666450361, 'subsample': 0.45182136673738005, 'colsample_bytree': 0.47109628348265986, 'max_depth': 229, 'min_child_weight': 150, 'eta': 0.004336520650775398, 'gamma': 0.006070017001600734, 'scale_pos_weight': 41, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:49:10,665] Trial 169 pruned. \n",
      "[I 2023-07-02 04:49:29,379] Trial 175 pruned. \n",
      "[I 2023-07-02 04:49:33,758] Trial 171 finished with value: 0.5854070818793591 and parameters: {'n_estimators': 873, 'learning_rate': 0.008860207025903195, 'lambda': 0.04795258368356203, 'alpha': 0.07647555925295953, 'subsample': 0.45650051932479097, 'colsample_bytree': 0.5895364338259929, 'max_depth': 240, 'min_child_weight': 141, 'eta': 0.00523416694130213, 'gamma': 0.006425504282130366, 'scale_pos_weight': 47, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:49:33,992] Trial 172 finished with value: 0.5856284551733838 and parameters: {'n_estimators': 883, 'learning_rate': 0.008537681334587778, 'lambda': 0.044538206948376985, 'alpha': 0.08441220472346836, 'subsample': 0.4320867784510649, 'colsample_bytree': 0.5418470535880964, 'max_depth': 239, 'min_child_weight': 139, 'eta': 0.005416032883751285, 'gamma': 0.0065324334672346995, 'scale_pos_weight': 46, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:49:45,033] Trial 174 pruned. \n",
      "[I 2023-07-02 04:50:01,426] Trial 176 pruned. \n",
      "[I 2023-07-02 04:50:22,596] Trial 180 pruned. \n",
      "[I 2023-07-02 04:50:25,023] Trial 181 pruned. \n",
      "[I 2023-07-02 04:50:29,742] Trial 182 pruned. \n",
      "[I 2023-07-02 04:50:38,930] Trial 179 pruned. \n",
      "[I 2023-07-02 04:50:44,555] Trial 184 pruned. \n",
      "[I 2023-07-02 04:50:47,883] Trial 183 pruned. \n",
      "[I 2023-07-02 04:50:53,415] Trial 178 finished with value: 0.5856249998551312 and parameters: {'n_estimators': 841, 'learning_rate': 0.008548766076243983, 'lambda': 0.05012443284502032, 'alpha': 0.08426720195026641, 'subsample': 0.4307396237820473, 'colsample_bytree': 0.5109458508437916, 'max_depth': 231, 'min_child_weight': 135, 'eta': 0.009403663908295168, 'gamma': 0.002719642771007109, 'scale_pos_weight': 40, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:50:56,793] Trial 185 pruned. \n",
      "[I 2023-07-02 04:50:57,885] Trial 177 pruned. \n",
      "[I 2023-07-02 04:51:15,622] Trial 188 pruned. \n",
      "[I 2023-07-02 04:51:51,938] Trial 189 pruned. \n",
      "[I 2023-07-02 04:51:53,119] Trial 163 finished with value: 0.5826410684219017 and parameters: {'n_estimators': 1127, 'learning_rate': 0.0035760636123471873, 'lambda': 0.04044596695189077, 'alpha': 0.07921261512989088, 'subsample': 0.41478073067845456, 'colsample_bytree': 0.4755375560630457, 'max_depth': 247, 'min_child_weight': 32, 'eta': 0.006804135790277546, 'gamma': 0.01440098542144539, 'scale_pos_weight': 41, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:51:55,963] Trial 190 pruned. \n",
      "[I 2023-07-02 04:52:00,223] Trial 192 pruned. \n",
      "[I 2023-07-02 04:52:00,635] Trial 191 pruned. \n",
      "[I 2023-07-02 04:52:07,179] Trial 186 finished with value: 0.5851398402157054 and parameters: {'n_estimators': 959, 'learning_rate': 0.010050124409363438, 'lambda': 0.05013542117972529, 'alpha': 0.08046310153329937, 'subsample': 0.46308859808888053, 'colsample_bytree': 0.4174241062814136, 'max_depth': 238, 'min_child_weight': 144, 'eta': 0.005088455120259913, 'gamma': 0.006160793720622953, 'scale_pos_weight': 86, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:52:13,969] Trial 187 finished with value: 0.5851532302372123 and parameters: {'n_estimators': 852, 'learning_rate': 0.01059799701951544, 'lambda': 0.05447747559354267, 'alpha': 0.0677739435749784, 'subsample': 0.4976251583048231, 'colsample_bytree': 0.4207178238170133, 'max_depth': 238, 'min_child_weight': 146, 'eta': 0.017720369613817726, 'gamma': 0.006005008266701623, 'scale_pos_weight': 56, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:52:22,426] Trial 193 pruned. \n",
      "[I 2023-07-02 04:52:41,259] Trial 200 pruned. \n",
      "[I 2023-07-02 04:52:50,021] Trial 199 pruned. \n",
      "[I 2023-07-02 04:52:56,412] Trial 195 pruned. \n",
      "[I 2023-07-02 04:52:59,098] Trial 201 pruned. \n",
      "[I 2023-07-02 04:53:02,258] Trial 198 pruned. \n",
      "[I 2023-07-02 04:53:20,664] Trial 194 pruned. \n",
      "[I 2023-07-02 04:53:43,112] Trial 196 finished with value: 0.5859351498012859 and parameters: {'n_estimators': 902, 'learning_rate': 0.004820040440231285, 'lambda': 0.054798380238010404, 'alpha': 0.08936753602407896, 'subsample': 0.45505562343496675, 'colsample_bytree': 0.3208883724840325, 'max_depth': 76, 'min_child_weight': 146, 'eta': 0.03421385313844748, 'gamma': 0.0064718528006542635, 'scale_pos_weight': 96, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:53:48,498] Trial 197 pruned. \n",
      "[I 2023-07-02 04:53:52,067] Trial 203 pruned. \n",
      "[I 2023-07-02 04:54:11,871] Trial 207 pruned. \n",
      "[I 2023-07-02 04:54:24,996] Trial 209 pruned. \n",
      "[I 2023-07-02 04:54:32,409] Trial 204 pruned. \n",
      "[I 2023-07-02 04:54:38,949] Trial 206 finished with value: 0.5858773538492634 and parameters: {'n_estimators': 781, 'learning_rate': 0.007470920186874402, 'lambda': 0.021980265553181878, 'alpha': 0.05994902354244175, 'subsample': 0.5115739901672506, 'colsample_bytree': 0.3314375946936515, 'max_depth': 8, 'min_child_weight': 102, 'eta': 0.003121436265187992, 'gamma': 0.008945621914675003, 'scale_pos_weight': 37, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:54:40,529] Trial 205 finished with value: 0.5858186755823439 and parameters: {'n_estimators': 781, 'learning_rate': 0.007210803870720466, 'lambda': 0.02194312497556429, 'alpha': 0.09119390398916348, 'subsample': 0.43726646234108235, 'colsample_bytree': 0.5329072432255727, 'max_depth': 9, 'min_child_weight': 103, 'eta': 0.0032298562405484736, 'gamma': 0.007563710912330094, 'scale_pos_weight': 31, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:55:08,012] Trial 202 pruned. \n",
      "[I 2023-07-02 04:55:08,810] Trial 214 pruned. \n",
      "[I 2023-07-02 04:55:11,540] Trial 215 pruned. \n",
      "[I 2023-07-02 04:55:22,592] Trial 208 pruned. \n",
      "[I 2023-07-02 04:55:25,124] Trial 210 pruned. \n",
      "[I 2023-07-02 04:55:33,331] Trial 212 pruned. \n",
      "[I 2023-07-02 04:55:42,412] Trial 219 pruned. \n",
      "[I 2023-07-02 04:55:52,551] Trial 211 pruned. \n",
      "[I 2023-07-02 04:55:59,966] Trial 216 pruned. \n",
      "[I 2023-07-02 04:56:06,015] Trial 221 pruned. \n",
      "[I 2023-07-02 04:56:08,479] Trial 222 pruned. \n",
      "[I 2023-07-02 04:56:29,985] Trial 220 pruned. \n",
      "[I 2023-07-02 04:56:31,136] Trial 223 pruned. \n",
      "[I 2023-07-02 04:56:45,333] Trial 213 finished with value: 0.5862805948259263 and parameters: {'n_estimators': 1200, 'learning_rate': 0.0025136216288318084, 'lambda': 0.0221810209995172, 'alpha': 0.0903921290666632, 'subsample': 0.43500849823705906, 'colsample_bytree': 0.3129689010098964, 'max_depth': 214, 'min_child_weight': 153, 'eta': 0.0224101530244789, 'gamma': 0.011291467628414714, 'scale_pos_weight': 78, 'grow_policy': 'lossguide'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:56:47,400] Trial 217 pruned. \n",
      "[I 2023-07-02 04:57:07,663] Trial 224 finished with value: 0.585380914312465 and parameters: {'n_estimators': 875, 'learning_rate': 0.009081785133730648, 'lambda': 0.019581302767610515, 'alpha': 0.06550678910557317, 'subsample': 0.41180139155628925, 'colsample_bytree': 0.4547128510198502, 'max_depth': 5, 'min_child_weight': 111, 'eta': 0.0045654104074181, 'gamma': 0.02776851312139684, 'scale_pos_weight': 26, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:57:13,421] Trial 225 finished with value: 0.5859820534235467 and parameters: {'n_estimators': 855, 'learning_rate': 0.009150624354995422, 'lambda': 0.01989231547809284, 'alpha': 0.05921021294545469, 'subsample': 0.5891357953189306, 'colsample_bytree': 0.3386326873635257, 'max_depth': 5, 'min_child_weight': 112, 'eta': 0.004628797704431016, 'gamma': 0.011887688280541505, 'scale_pos_weight': 93, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:57:15,865] Trial 218 finished with value: 0.5854871210203101 and parameters: {'n_estimators': 775, 'learning_rate': 0.0024587236973108743, 'lambda': 0.021694999098084568, 'alpha': 0.06444887578975217, 'subsample': 0.434978880306078, 'colsample_bytree': 0.31063637771411906, 'max_depth': 15, 'min_child_weight': 107, 'eta': 0.021468812602970705, 'gamma': 0.00931526300601926, 'scale_pos_weight': 41, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:57:28,992] Trial 226 pruned. \n",
      "[I 2023-07-02 04:57:30,185] Trial 227 pruned. \n",
      "[I 2023-07-02 04:57:40,092] Trial 228 pruned. \n",
      "[I 2023-07-02 04:57:41,472] Trial 229 pruned. \n",
      "[I 2023-07-02 04:57:41,672] Trial 233 pruned. \n",
      "[I 2023-07-02 04:57:42,187] Trial 230 pruned. \n",
      "[I 2023-07-02 04:57:43,384] Trial 231 pruned. \n",
      "[I 2023-07-02 04:57:59,208] Trial 238 pruned. \n",
      "[I 2023-07-02 04:58:07,602] Trial 236 pruned. \n",
      "[I 2023-07-02 04:58:10,937] Trial 234 pruned. \n",
      "[I 2023-07-02 04:58:12,575] Trial 240 pruned. \n",
      "[I 2023-07-02 04:58:12,889] Trial 232 pruned. \n",
      "[I 2023-07-02 04:58:26,486] Trial 239 pruned. \n",
      "[I 2023-07-02 04:58:40,165] Trial 235 finished with value: 0.585957211546688 and parameters: {'n_estimators': 880, 'learning_rate': 0.009479343904479133, 'lambda': 0.02038213595585467, 'alpha': 0.06089789937849865, 'subsample': 0.5918249163483383, 'colsample_bytree': 0.2990368905355669, 'max_depth': 5, 'min_child_weight': 107, 'eta': 0.03121998264392601, 'gamma': 0.01139746959610926, 'scale_pos_weight': 93, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:58:43,044] Trial 237 pruned. \n",
      "[I 2023-07-02 04:58:44,213] Trial 243 pruned. \n",
      "[I 2023-07-02 04:58:56,292] Trial 244 pruned. \n",
      "[I 2023-07-02 04:58:59,746] Trial 247 pruned. \n",
      "[I 2023-07-02 04:59:12,447] Trial 248 pruned. \n",
      "[I 2023-07-02 04:59:39,918] Trial 251 finished with value: 0.5862531037708505 and parameters: {'n_estimators': 229, 'learning_rate': 0.006632078387457029, 'lambda': 0.014079083816843741, 'alpha': 0.06105006556891795, 'subsample': 0.6055006998209267, 'colsample_bytree': 0.27680103507357234, 'max_depth': 48, 'min_child_weight': 98, 'eta': 0.028949340339802676, 'gamma': 0.009124183263817892, 'scale_pos_weight': 44, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 04:59:52,337] Trial 245 pruned. \n",
      "[I 2023-07-02 04:59:55,274] Trial 241 pruned. \n",
      "[I 2023-07-02 05:00:01,456] Trial 254 pruned. \n",
      "[I 2023-07-02 05:00:04,541] Trial 255 pruned. \n",
      "[I 2023-07-02 05:00:06,923] Trial 242 finished with value: 0.5863528306784325 and parameters: {'n_estimators': 962, 'learning_rate': 0.0061310526568005355, 'lambda': 0.01731681271495338, 'alpha': 0.06700214160292697, 'subsample': 0.41636283432302734, 'colsample_bytree': 0.29963890934456977, 'max_depth': 228, 'min_child_weight': 117, 'eta': 0.023485885198869665, 'gamma': 0.027424752500374475, 'scale_pos_weight': 44, 'grow_policy': 'depthwise'}. Best is trial 97 with value: 0.5864109260560468.\n",
      "[I 2023-07-02 05:00:18,847] Trial 246 pruned. \n",
      "[I 2023-07-02 05:00:19,248] Trial 253 finished with value: 0.5869826332264374 and parameters: {'n_estimators': 240, 'learning_rate': 0.006496592390654572, 'lambda': 0.017511028649561642, 'alpha': 0.058015038023273506, 'subsample': 0.6034996424008736, 'colsample_bytree': 0.2742590004249605, 'max_depth': 25, 'min_child_weight': 118, 'eta': 0.028692162557239075, 'gamma': 0.009652756679188952, 'scale_pos_weight': 44, 'grow_policy': 'depthwise'}. Best is trial 253 with value: 0.5869826332264374.\n",
      "[I 2023-07-02 05:00:20,799] Trial 252 finished with value: 0.5845362551236288 and parameters: {'n_estimators': 561, 'learning_rate': 0.006196185492467015, 'lambda': 0.04278699944008354, 'alpha': 0.06083484562711512, 'subsample': 0.4609149865636789, 'colsample_bytree': 0.36559472962441636, 'max_depth': 11, 'min_child_weight': 119, 'eta': 0.022762109261606434, 'gamma': 0.009424017454731422, 'scale_pos_weight': 99, 'grow_policy': 'depthwise'}. Best is trial 253 with value: 0.5869826332264374.\n",
      "[I 2023-07-02 05:00:24,367] Trial 249 finished with value: 0.5859700366381537 and parameters: {'n_estimators': 844, 'learning_rate': 0.006358583184891686, 'lambda': 0.024410069339039244, 'alpha': 0.05988432631675475, 'subsample': 0.6020601634784309, 'colsample_bytree': 0.24901698854023704, 'max_depth': 10, 'min_child_weight': 98, 'eta': 0.03108575186969133, 'gamma': 0.029324091413684146, 'scale_pos_weight': 95, 'grow_policy': 'depthwise'}. Best is trial 253 with value: 0.5869826332264374.\n",
      "[I 2023-07-02 05:00:24,599] Trial 256 pruned. \n",
      "[I 2023-07-02 05:00:29,354] Trial 258 pruned. \n",
      "[I 2023-07-02 05:00:35,747] Trial 257 pruned. \n",
      "[I 2023-07-02 05:00:39,733] Trial 250 finished with value: 0.5854629797100802 and parameters: {'n_estimators': 833, 'learning_rate': 0.006128234477603242, 'lambda': 0.01739458791869076, 'alpha': 0.056992908199076556, 'subsample': 0.6086191251927616, 'colsample_bytree': 0.3300017671173832, 'max_depth': 19, 'min_child_weight': 98, 'eta': 0.03238220500190753, 'gamma': 0.013906321133171796, 'scale_pos_weight': 94, 'grow_policy': 'depthwise'}. Best is trial 253 with value: 0.5869826332264374.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\rafay\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rafay\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:100\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(futures) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_jobs:\n\u001b[1;32m--> 100\u001b[0m     completed, futures \u001b[39m=\u001b[39m wait(futures, return_when\u001b[39m=\u001b[39;49mFIRST_COMPLETED)\n\u001b[0;32m    101\u001b[0m     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n",
      "File \u001b[1;32mc:\\Users\\rafay\\anaconda3\\lib\\concurrent\\futures\\_base.py:307\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(fs, timeout, return_when)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[39mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[0;32m    305\u001b[0m     waiter \u001b[39m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[1;32m--> 307\u001b[0m waiter\u001b[39m.\u001b[39;49mevent\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    308\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fs:\n\u001b[0;32m    309\u001b[0m     \u001b[39mwith\u001b[39;00m f\u001b[39m.\u001b[39m_condition:\n",
      "File \u001b[1;32mc:\\Users\\rafay\\anaconda3\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\rafay\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=200,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c927ffa72404684b2e2b3a59ad72403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-02 03:30:50,004] Trial 407 pruned. \n",
      "[I 2023-07-02 03:30:50,437] Trial 406 pruned. \n",
      "[I 2023-07-02 03:30:50,686] Trial 403 pruned. \n",
      "[I 2023-07-02 03:30:50,697] Trial 400 pruned. \n",
      "[I 2023-07-02 03:30:51,567] Trial 405 pruned. \n",
      "[I 2023-07-02 03:30:52,000] Trial 404 pruned. \n",
      "[I 2023-07-02 03:30:52,919] Trial 401 pruned. \n",
      "[I 2023-07-02 03:30:54,090] Trial 402 pruned. \n",
      "[I 2023-07-02 03:30:55,434] Trial 409 pruned. \n",
      "[I 2023-07-02 03:30:55,586] Trial 410 pruned. \n",
      "[I 2023-07-02 03:30:55,715] Trial 413 pruned. \n",
      "[I 2023-07-02 03:30:55,823] Trial 414 pruned. \n",
      "[I 2023-07-02 03:30:57,228] Trial 408 pruned. \n",
      "[I 2023-07-02 03:30:57,608] Trial 415 pruned. \n",
      "[I 2023-07-02 03:30:58,953] Trial 412 pruned. \n",
      "[I 2023-07-02 03:31:00,786] Trial 411 pruned. \n",
      "[I 2023-07-02 03:31:01,635] Trial 417 pruned. \n",
      "[I 2023-07-02 03:31:01,959] Trial 416 pruned. \n",
      "[I 2023-07-02 03:31:05,312] Trial 424 pruned. \n",
      "[I 2023-07-02 03:31:05,447] Trial 419 pruned. \n",
      "[I 2023-07-02 03:31:06,141] Trial 418 finished with value: 0.5845289788288472 and parameters: {'n_estimators': 276, 'learning_rate': 0.02800218671514747, 'num_leaves': 82, 'max_depth': 329, 'min_child_samples': 91, 'min_child_weight': 192, 'subsample': 0.7101406177220354, 'colsample_bytree': 0.21685686548213345, 'reg_alpha': 0.7444671054022491, 'reg_lambda': 0.5003367929630619}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:31:06,506] Trial 420 finished with value: 0.5844036339437386 and parameters: {'n_estimators': 276, 'learning_rate': 0.028211326554533126, 'num_leaves': 43, 'max_depth': 234, 'min_child_samples': 92, 'min_child_weight': 196, 'subsample': 0.7098596929865456, 'colsample_bytree': 0.21822954567897443, 'reg_alpha': 0.7413264689973443, 'reg_lambda': 0.42078333252026484}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:31:06,837] Trial 421 pruned. \n",
      "[I 2023-07-02 03:31:07,036] Trial 422 pruned. \n",
      "[I 2023-07-02 03:31:08,936] Trial 423 pruned. \n",
      "[I 2023-07-02 03:31:10,534] Trial 425 pruned. \n",
      "[I 2023-07-02 03:31:11,865] Trial 428 pruned. \n",
      "[I 2023-07-02 03:31:12,577] Trial 431 pruned. \n",
      "[I 2023-07-02 03:31:13,246] Trial 429 pruned. \n",
      "[I 2023-07-02 03:31:14,120] Trial 427 pruned. \n",
      "[I 2023-07-02 03:31:14,480] Trial 426 pruned. \n",
      "[I 2023-07-02 03:31:14,955] Trial 433 pruned. \n",
      "[I 2023-07-02 03:31:15,366] Trial 430 pruned. \n",
      "[I 2023-07-02 03:31:17,669] Trial 438 pruned. \n",
      "[I 2023-07-02 03:31:19,012] Trial 432 finished with value: 0.5847826820507854 and parameters: {'n_estimators': 342, 'learning_rate': 0.01932533443337105, 'num_leaves': 65, 'max_depth': 197, 'min_child_samples': 103, 'min_child_weight': 210, 'subsample': 0.7566614853313737, 'colsample_bytree': 0.240999983736016, 'reg_alpha': 0.6034381986482245, 'reg_lambda': 0.023557852588228012}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:31:20,350] Trial 439 pruned. \n",
      "[I 2023-07-02 03:31:21,124] Trial 440 pruned. \n",
      "[I 2023-07-02 03:31:21,221] Trial 436 pruned. \n",
      "[I 2023-07-02 03:31:22,297] Trial 434 finished with value: 0.584924653277759 and parameters: {'n_estimators': 340, 'learning_rate': 0.01930469593378136, 'num_leaves': 67, 'max_depth': 216, 'min_child_samples': 106, 'min_child_weight': 211, 'subsample': 0.7327588617079922, 'colsample_bytree': 0.27863116198216276, 'reg_alpha': 0.5798154734943616, 'reg_lambda': 0.028100581000483682}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:31:22,383] Trial 437 pruned. \n",
      "[I 2023-07-02 03:31:23,974] Trial 441 pruned. \n",
      "[I 2023-07-02 03:31:24,400] Trial 435 pruned. \n",
      "[I 2023-07-02 03:31:24,924] Trial 443 pruned. \n",
      "[I 2023-07-02 03:31:26,034] Trial 442 pruned. \n",
      "[I 2023-07-02 03:31:27,806] Trial 446 pruned. \n",
      "[I 2023-07-02 03:31:28,962] Trial 447 pruned. \n",
      "[I 2023-07-02 03:31:29,680] Trial 451 pruned. \n",
      "[I 2023-07-02 03:31:29,852] Trial 445 pruned. \n",
      "[I 2023-07-02 03:31:30,666] Trial 449 pruned. \n",
      "[I 2023-07-02 03:31:31,974] Trial 450 pruned. \n",
      "[I 2023-07-02 03:31:32,636] Trial 452 pruned. \n",
      "[I 2023-07-02 03:31:32,807] Trial 444 pruned. \n",
      "[I 2023-07-02 03:31:35,569] Trial 448 finished with value: 0.5836695803494761 and parameters: {'n_estimators': 306, 'learning_rate': 0.022011517319264828, 'num_leaves': 16, 'max_depth': 206, 'min_child_samples': 109, 'min_child_weight': 117, 'subsample': 0.7599389529173082, 'colsample_bytree': 0.27750668489084857, 'reg_alpha': 0.5804601326715142, 'reg_lambda': 0.015123036787293055}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:31:36,502] Trial 454 pruned. \n",
      "[I 2023-07-02 03:31:37,104] Trial 456 pruned. \n",
      "[I 2023-07-02 03:31:37,571] Trial 458 pruned. \n",
      "[I 2023-07-02 03:31:37,574] Trial 455 pruned. \n",
      "[I 2023-07-02 03:31:38,629] Trial 457 pruned. \n",
      "[I 2023-07-02 03:31:39,616] Trial 453 pruned. \n",
      "[I 2023-07-02 03:31:40,116] Trial 462 pruned. \n",
      "[I 2023-07-02 03:31:41,139] Trial 463 pruned. \n",
      "[I 2023-07-02 03:31:42,322] Trial 465 pruned. \n",
      "[I 2023-07-02 03:31:42,599] Trial 461 pruned. \n",
      "[I 2023-07-02 03:31:42,919] Trial 467 pruned. \n",
      "[I 2023-07-02 03:31:43,430] Trial 466 pruned. \n",
      "[I 2023-07-02 03:31:44,761] Trial 459 pruned. \n",
      "[I 2023-07-02 03:31:46,452] Trial 464 pruned. \n",
      "[I 2023-07-02 03:31:46,924] Trial 470 pruned. \n",
      "[I 2023-07-02 03:31:47,585] Trial 460 pruned. \n",
      "[I 2023-07-02 03:31:48,254] Trial 472 pruned. \n",
      "[I 2023-07-02 03:31:49,249] Trial 468 pruned. \n",
      "[I 2023-07-02 03:31:50,025] Trial 474 pruned. \n",
      "[I 2023-07-02 03:31:50,690] Trial 473 pruned. \n",
      "[I 2023-07-02 03:31:51,389] Trial 478 pruned. \n",
      "[I 2023-07-02 03:31:52,240] Trial 471 finished with value: 0.5856315632179412 and parameters: {'n_estimators': 251, 'learning_rate': 0.01818959996353613, 'num_leaves': 36, 'max_depth': 254, 'min_child_samples': 136, 'min_child_weight': 205, 'subsample': 0.8162544429223004, 'colsample_bytree': 0.21990779655930143, 'reg_alpha': 0.46264544794546963, 'reg_lambda': 0.3591546373644098}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:31:53,070] Trial 469 pruned. \n",
      "[I 2023-07-02 03:31:53,971] Trial 475 pruned. \n",
      "[I 2023-07-02 03:31:55,805] Trial 482 pruned. \n",
      "[I 2023-07-02 03:31:57,348] Trial 480 pruned. \n",
      "[I 2023-07-02 03:31:57,851] Trial 477 pruned. \n",
      "[I 2023-07-02 03:31:58,395] Trial 484 pruned. \n",
      "[I 2023-07-02 03:31:58,722] Trial 481 pruned. \n",
      "[I 2023-07-02 03:31:58,976] Trial 479 pruned. \n",
      "[I 2023-07-02 03:32:01,220] Trial 485 pruned. \n",
      "[I 2023-07-02 03:32:03,537] Trial 476 pruned. \n",
      "[I 2023-07-02 03:32:03,675] Trial 487 pruned. \n",
      "[I 2023-07-02 03:32:04,039] Trial 489 pruned. \n",
      "[I 2023-07-02 03:32:04,266] Trial 491 pruned. \n",
      "[I 2023-07-02 03:32:05,146] Trial 490 pruned. \n",
      "[I 2023-07-02 03:32:05,243] Trial 486 finished with value: 0.5847070090596959 and parameters: {'n_estimators': 208, 'learning_rate': 0.02339504897669451, 'num_leaves': 40, 'max_depth': 249, 'min_child_samples': 104, 'min_child_weight': 214, 'subsample': 0.8516813913316086, 'colsample_bytree': 0.213188672003721, 'reg_alpha': 0.4393988769664487, 'reg_lambda': 0.21302716163599691}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:06,074] Trial 483 pruned. \n",
      "[I 2023-07-02 03:32:06,659] Trial 488 pruned. \n",
      "[I 2023-07-02 03:32:08,279] Trial 492 pruned. \n",
      "[I 2023-07-02 03:32:09,595] Trial 493 pruned. \n",
      "[I 2023-07-02 03:32:10,076] Trial 495 pruned. \n",
      "[I 2023-07-02 03:32:11,030] Trial 496 pruned. \n",
      "[I 2023-07-02 03:32:11,852] Trial 499 pruned. \n",
      "[I 2023-07-02 03:32:11,974] Trial 498 pruned. \n",
      "[I 2023-07-02 03:32:13,377] Trial 497 pruned. \n",
      "[I 2023-07-02 03:32:14,833] Trial 504 pruned. \n",
      "[I 2023-07-02 03:32:15,622] Trial 503 pruned. \n",
      "[I 2023-07-02 03:32:17,963] Trial 505 pruned. \n",
      "[I 2023-07-02 03:32:18,483] Trial 500 finished with value: 0.5836638274689026 and parameters: {'n_estimators': 347, 'learning_rate': 0.015458373395438055, 'num_leaves': 61, 'max_depth': 189, 'min_child_samples': 94, 'min_child_weight': 203, 'subsample': 0.7368722314940396, 'colsample_bytree': 0.5380077265221906, 'reg_alpha': 0.9998022586192812, 'reg_lambda': 0.09827431585193844}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:18,744] Trial 501 pruned. \n",
      "[I 2023-07-02 03:32:19,264] Trial 508 pruned. \n",
      "[I 2023-07-02 03:32:20,213] Trial 502 pruned. \n",
      "[I 2023-07-02 03:32:22,075] Trial 512 pruned. \n",
      "[I 2023-07-02 03:32:22,403] Trial 506 finished with value: 0.5849156387852418 and parameters: {'n_estimators': 241, 'learning_rate': 0.019493709202202846, 'num_leaves': 62, 'max_depth': 174, 'min_child_samples': 89, 'min_child_weight': 147, 'subsample': 0.696689717571294, 'colsample_bytree': 0.2350299141840499, 'reg_alpha': 0.3232002774602463, 'reg_lambda': 0.39185668992504274}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:22,456] Trial 509 pruned. \n",
      "[I 2023-07-02 03:32:23,859] Trial 513 pruned. \n",
      "[I 2023-07-02 03:32:25,074] Trial 511 pruned. \n",
      "[I 2023-07-02 03:32:25,658] Trial 510 pruned. \n",
      "[I 2023-07-02 03:32:27,913] Trial 514 pruned. \n",
      "[I 2023-07-02 03:32:28,139] Trial 517 pruned. \n",
      "[I 2023-07-02 03:32:29,367] Trial 494 pruned. \n",
      "[I 2023-07-02 03:32:29,786] Trial 515 pruned. \n",
      "[I 2023-07-02 03:32:29,834] Trial 516 pruned. \n",
      "[I 2023-07-02 03:32:31,956] Trial 520 pruned. \n",
      "[I 2023-07-02 03:32:32,139] Trial 521 pruned. \n",
      "[I 2023-07-02 03:32:32,227] Trial 518 pruned. \n",
      "[I 2023-07-02 03:32:35,493] Trial 523 pruned. \n",
      "[I 2023-07-02 03:32:36,021] Trial 522 finished with value: 0.5851687347535268 and parameters: {'n_estimators': 191, 'learning_rate': 0.027079029114922312, 'num_leaves': 7, 'max_depth': 166, 'min_child_samples': 95, 'min_child_weight': 153, 'subsample': 0.6912336060952747, 'colsample_bytree': 0.23327413517880333, 'reg_alpha': 0.3209112642925208, 'reg_lambda': 0.3912624330693897}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:36,818] Trial 524 pruned. \n",
      "[I 2023-07-02 03:32:39,262] Trial 526 pruned. \n",
      "[I 2023-07-02 03:32:41,380] Trial 507 pruned. \n",
      "[I 2023-07-02 03:32:41,699] Trial 530 pruned. \n",
      "[I 2023-07-02 03:32:42,175] Trial 531 pruned. \n",
      "[I 2023-07-02 03:32:43,807] Trial 529 finished with value: 0.584459922530411 and parameters: {'n_estimators': 170, 'learning_rate': 0.02800757781793972, 'num_leaves': 11, 'max_depth': 174, 'min_child_samples': 95, 'min_child_weight': 146, 'subsample': 0.7126200580931279, 'colsample_bytree': 0.24740685751615818, 'reg_alpha': 0.3141080828339734, 'reg_lambda': 0.27097416752973313}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:44,114] Trial 525 finished with value: 0.5841841773583145 and parameters: {'n_estimators': 301, 'learning_rate': 0.019027438659263457, 'num_leaves': 23, 'max_depth': 174, 'min_child_samples': 100, 'min_child_weight': 146, 'subsample': 0.6779343212553468, 'colsample_bytree': 0.24136848358548352, 'reg_alpha': 0.297322776989085, 'reg_lambda': 0.41750031151001626}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:44,459] Trial 533 pruned. \n",
      "[I 2023-07-02 03:32:44,919] Trial 532 pruned. \n",
      "[I 2023-07-02 03:32:48,017] Trial 519 pruned. \n",
      "[I 2023-07-02 03:32:48,369] Trial 534 finished with value: 0.5853492863242347 and parameters: {'n_estimators': 174, 'learning_rate': 0.027229299093724676, 'num_leaves': 7, 'max_depth': 157, 'min_child_samples': 117, 'min_child_weight': 158, 'subsample': 0.8126494307493515, 'colsample_bytree': 0.19939159709656837, 'reg_alpha': 0.31682468135251124, 'reg_lambda': 0.41865499800905603}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:48,857] Trial 536 finished with value: 0.5857304097930015 and parameters: {'n_estimators': 166, 'learning_rate': 0.026697004150342384, 'num_leaves': 5, 'max_depth': 154, 'min_child_samples': 118, 'min_child_weight': 165, 'subsample': 0.8196322826872637, 'colsample_bytree': 0.22007741285799687, 'reg_alpha': 0.2596390333214287, 'reg_lambda': 0.16787299801708194}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:50,226] Trial 538 finished with value: 0.5849871155838876 and parameters: {'n_estimators': 157, 'learning_rate': 0.031106268835020594, 'num_leaves': 19, 'max_depth': 165, 'min_child_samples': 89, 'min_child_weight': 162, 'subsample': 0.8130732190871639, 'colsample_bytree': 0.2035869203294805, 'reg_alpha': 0.38114742413824676, 'reg_lambda': 0.3051639433632434}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:32:51,581] Trial 527 pruned. \n",
      "[I 2023-07-02 03:32:51,719] Trial 542 pruned. \n",
      "[I 2023-07-02 03:32:52,026] Trial 540 pruned. \n",
      "[I 2023-07-02 03:32:52,061] Trial 537 pruned. \n",
      "[I 2023-07-02 03:32:53,360] Trial 528 pruned. \n",
      "[I 2023-07-02 03:32:53,672] Trial 541 pruned. \n",
      "[I 2023-07-02 03:32:53,994] Trial 539 pruned. \n",
      "[I 2023-07-02 03:32:55,467] Trial 544 pruned. \n",
      "[I 2023-07-02 03:32:56,239] Trial 546 pruned. \n",
      "[I 2023-07-02 03:32:56,694] Trial 545 pruned. \n",
      "[I 2023-07-02 03:32:57,076] Trial 547 pruned. \n",
      "[I 2023-07-02 03:32:57,999] Trial 548 pruned. \n",
      "[I 2023-07-02 03:32:58,758] Trial 549 pruned. \n",
      "[I 2023-07-02 03:32:59,427] Trial 535 pruned. \n",
      "[I 2023-07-02 03:32:59,534] Trial 543 finished with value: 0.5847526161381298 and parameters: {'n_estimators': 147, 'learning_rate': 0.031082275911566818, 'num_leaves': 7, 'max_depth': 157, 'min_child_samples': 123, 'min_child_weight': 157, 'subsample': 0.8177072983772659, 'colsample_bytree': 0.2081349583831993, 'reg_alpha': 0.24482369905396126, 'reg_lambda': 0.11667070908710737}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:01,818] Trial 555 pruned. \n",
      "[I 2023-07-02 03:33:02,267] Trial 552 pruned. \n",
      "[I 2023-07-02 03:33:02,853] Trial 550 pruned. \n",
      "[I 2023-07-02 03:33:03,748] Trial 551 pruned. \n",
      "[I 2023-07-02 03:33:04,910] Trial 560 pruned. \n",
      "[I 2023-07-02 03:33:05,345] Trial 553 finished with value: 0.5850026736919365 and parameters: {'n_estimators': 186, 'learning_rate': 0.029891826886782276, 'num_leaves': 12, 'max_depth': 141, 'min_child_samples': 108, 'min_child_weight': 169, 'subsample': 0.8013481851485093, 'colsample_bytree': 0.21673382610982478, 'reg_alpha': 0.3552803650121665, 'reg_lambda': 0.29630482583783213}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:05,473] Trial 554 finished with value: 0.5852287274867662 and parameters: {'n_estimators': 184, 'learning_rate': 0.028627270098102956, 'num_leaves': 19, 'max_depth': 150, 'min_child_samples': 110, 'min_child_weight': 170, 'subsample': 0.8058598082896147, 'colsample_bytree': 0.21685532147605896, 'reg_alpha': 0.21045379320126884, 'reg_lambda': 0.15152764869776583}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:05,950] Trial 561 pruned. \n",
      "[I 2023-07-02 03:33:07,361] Trial 559 pruned. \n",
      "[I 2023-07-02 03:33:07,498] Trial 557 finished with value: 0.5824362013610964 and parameters: {'n_estimators': 180, 'learning_rate': 0.027888999529677452, 'num_leaves': 18, 'max_depth': 141, 'min_child_samples': 141, 'min_child_weight': 150, 'subsample': 0.8042670692881121, 'colsample_bytree': 0.45057574263881184, 'reg_alpha': 0.22607361803052, 'reg_lambda': 0.039288381082181356}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:08,321] Trial 556 finished with value: 0.5845850785441371 and parameters: {'n_estimators': 202, 'learning_rate': 0.029576116437506746, 'num_leaves': 17, 'max_depth': 146, 'min_child_samples': 130, 'min_child_weight': 150, 'subsample': 0.8030702877112017, 'colsample_bytree': 0.2255683291287897, 'reg_alpha': 0.23010732670746614, 'reg_lambda': 0.1637088873074112}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:09,836] Trial 558 finished with value: 0.585045304064096 and parameters: {'n_estimators': 191, 'learning_rate': 0.02891759390876411, 'num_leaves': 14, 'max_depth': 163, 'min_child_samples': 139, 'min_child_weight': 150, 'subsample': 0.6129168390061731, 'colsample_bytree': 0.2250704924286992, 'reg_alpha': 0.8247256769888291, 'reg_lambda': 0.2918317004097793}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:09,955] Trial 564 pruned. \n",
      "[I 2023-07-02 03:33:11,312] Trial 565 pruned. \n",
      "[I 2023-07-02 03:33:11,931] Trial 563 pruned. \n",
      "[I 2023-07-02 03:33:12,227] Trial 567 pruned. \n",
      "[I 2023-07-02 03:33:13,216] Trial 568 pruned. \n",
      "[I 2023-07-02 03:33:14,085] Trial 562 finished with value: 0.5847182299417424 and parameters: {'n_estimators': 211, 'learning_rate': 0.022619274835461507, 'num_leaves': 11, 'max_depth': 165, 'min_child_samples': 132, 'min_child_weight': 149, 'subsample': 0.8048464991936244, 'colsample_bytree': 0.21730638253870066, 'reg_alpha': 0.36908980698944, 'reg_lambda': 0.29502558915957733}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:14,826] Trial 566 finished with value: 0.5849407177578055 and parameters: {'n_estimators': 198, 'learning_rate': 0.030843577122085648, 'num_leaves': 21, 'max_depth': 165, 'min_child_samples': 113, 'min_child_weight': 176, 'subsample': 0.8069633749653283, 'colsample_bytree': 0.2186994696683622, 'reg_alpha': 0.2121367502360718, 'reg_lambda': 0.29710837569748744}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:15,312] Trial 569 pruned. \n",
      "[I 2023-07-02 03:33:16,096] Trial 570 pruned. \n",
      "[I 2023-07-02 03:33:17,871] Trial 571 finished with value: 0.584885207901593 and parameters: {'n_estimators': 173, 'learning_rate': 0.03041444542163172, 'num_leaves': 11, 'max_depth': 166, 'min_child_samples': 139, 'min_child_weight': 161, 'subsample': 0.8296668468764369, 'colsample_bytree': 0.21919040785424154, 'reg_alpha': 0.21563977769721163, 'reg_lambda': 0.2343015556057867}. Best is trial 342 with value: 0.5858319533844203.\n",
      "[I 2023-07-02 03:33:18,797] Trial 574 finished with value: 0.5859887520781273 and parameters: {'n_estimators': 140, 'learning_rate': 0.030804645562132842, 'num_leaves': 11, 'max_depth': 155, 'min_child_samples': 137, 'min_child_weight': 164, 'subsample': 0.794984112627714, 'colsample_bytree': 0.2585015642686539, 'reg_alpha': 0.203388953337945, 'reg_lambda': 0.2820024593291725}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:18,997] Trial 572 finished with value: 0.5844968397057769 and parameters: {'n_estimators': 165, 'learning_rate': 0.032927978764362174, 'num_leaves': 12, 'max_depth': 168, 'min_child_samples': 141, 'min_child_weight': 161, 'subsample': 0.6135755268740897, 'colsample_bytree': 0.20808668303001165, 'reg_alpha': 0.2073225281422783, 'reg_lambda': 0.2745676459965133}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:19,636] Trial 573 finished with value: 0.5850959719637359 and parameters: {'n_estimators': 172, 'learning_rate': 0.030321519103517398, 'num_leaves': 12, 'max_depth': 150, 'min_child_samples': 140, 'min_child_weight': 167, 'subsample': 0.8462923091484476, 'colsample_bytree': 0.20240521214616483, 'reg_alpha': 0.26978957267949455, 'reg_lambda': 0.15143120133132226}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:21,010] Trial 575 finished with value: 0.5852423671699754 and parameters: {'n_estimators': 165, 'learning_rate': 0.02957289004069316, 'num_leaves': 9, 'max_depth': 153, 'min_child_samples': 112, 'min_child_weight': 160, 'subsample': 0.6130721305702042, 'colsample_bytree': 0.25490862346772675, 'reg_alpha': 0.2830532779931474, 'reg_lambda': 0.28939805620216713}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:21,130] Trial 576 finished with value: 0.5850520502519237 and parameters: {'n_estimators': 163, 'learning_rate': 0.030020914595841965, 'num_leaves': 13, 'max_depth': 152, 'min_child_samples': 139, 'min_child_weight': 173, 'subsample': 0.5966011890643855, 'colsample_bytree': 0.20037025447268597, 'reg_alpha': 0.20783904481802612, 'reg_lambda': 0.2933067627273341}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:21,764] Trial 577 finished with value: 0.5849631571687567 and parameters: {'n_estimators': 165, 'learning_rate': 0.03163288259592506, 'num_leaves': 11, 'max_depth': 154, 'min_child_samples': 139, 'min_child_weight': 180, 'subsample': 0.7957175035745415, 'colsample_bytree': 0.19841867141240446, 'reg_alpha': 0.19986730055322321, 'reg_lambda': 0.28152430897649183}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:22,372] Trial 581 pruned. \n",
      "[I 2023-07-02 03:33:22,414] Trial 578 finished with value: 0.5850678139506463 and parameters: {'n_estimators': 156, 'learning_rate': 0.031709151928787066, 'num_leaves': 14, 'max_depth': 152, 'min_child_samples': 152, 'min_child_weight': 177, 'subsample': 0.8108550583111107, 'colsample_bytree': 0.19882839374839964, 'reg_alpha': 0.21655318597985984, 'reg_lambda': 0.298311332777292}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:22,728] Trial 582 pruned. \n",
      "[I 2023-07-02 03:33:24,620] Trial 584 pruned. \n",
      "[I 2023-07-02 03:33:25,024] Trial 579 finished with value: 0.5854174136896342 and parameters: {'n_estimators': 162, 'learning_rate': 0.029780699360064555, 'num_leaves': 13, 'max_depth': 152, 'min_child_samples': 144, 'min_child_weight': 180, 'subsample': 0.8442026649542085, 'colsample_bytree': 0.19911018658945887, 'reg_alpha': 0.19964463921301723, 'reg_lambda': 0.2885170726735829}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:25,257] Trial 580 pruned. \n",
      "[I 2023-07-02 03:33:25,671] Trial 585 pruned. \n",
      "[I 2023-07-02 03:33:26,424] Trial 588 pruned. \n",
      "[I 2023-07-02 03:33:27,066] Trial 587 pruned. \n",
      "[I 2023-07-02 03:33:28,424] Trial 589 pruned. \n",
      "[I 2023-07-02 03:33:28,924] Trial 583 pruned. \n",
      "[I 2023-07-02 03:33:28,975] Trial 591 pruned. \n",
      "[I 2023-07-02 03:33:29,300] Trial 590 pruned. \n",
      "[I 2023-07-02 03:33:29,999] Trial 586 pruned. \n",
      "[I 2023-07-02 03:33:30,543] Trial 592 pruned. \n",
      "[I 2023-07-02 03:33:31,064] Trial 593 pruned. \n",
      "[I 2023-07-02 03:33:31,867] Trial 595 pruned. \n",
      "[I 2023-07-02 03:33:32,660] Trial 598 pruned. \n",
      "[I 2023-07-02 03:33:32,983] Trial 594 pruned. \n",
      "[I 2023-07-02 03:33:33,720] Trial 597 pruned. \n",
      "[I 2023-07-02 03:33:33,841] Trial 596 finished with value: 0.5847367923547343 and parameters: {'n_estimators': 165, 'learning_rate': 0.03263040894767697, 'num_leaves': 17, 'max_depth': 134, 'min_child_samples': 138, 'min_child_weight': 179, 'subsample': 0.8725571525644491, 'colsample_bytree': 0.1964666184061999, 'reg_alpha': 0.2129931099625903, 'reg_lambda': 0.2666979859622475}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:33,914] Trial 599 pruned. \n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=200,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd3cfd39c214b93b30e6070787717dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-02 03:33:46,693] Trial 606 pruned. \n",
      "[I 2023-07-02 03:33:47,371] Trial 607 pruned. \n",
      "[I 2023-07-02 03:33:48,997] Trial 604 finished with value: 0.5850008369683112 and parameters: {'n_estimators': 178, 'learning_rate': 0.030165505879538184, 'num_leaves': 21, 'max_depth': 160, 'min_child_samples': 146, 'min_child_weight': 167, 'subsample': 0.8115293558151238, 'colsample_bytree': 0.20674850112515608, 'reg_alpha': 0.19803303233069153, 'reg_lambda': 0.3299965774581455}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:49,162] Trial 601 pruned. \n",
      "[I 2023-07-02 03:33:49,747] Trial 602 pruned. \n",
      "[I 2023-07-02 03:33:49,987] Trial 603 finished with value: 0.5850541888412838 and parameters: {'n_estimators': 186, 'learning_rate': 0.029265592575978088, 'num_leaves': 24, 'max_depth': 162, 'min_child_samples': 138, 'min_child_weight': 165, 'subsample': 0.7930587422510882, 'colsample_bytree': 0.22565142990120426, 'reg_alpha': 0.19389117884739276, 'reg_lambda': 0.3187070886784414}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:50,160] Trial 600 finished with value: 0.5849754910595435 and parameters: {'n_estimators': 183, 'learning_rate': 0.029645520485834607, 'num_leaves': 24, 'max_depth': 144, 'min_child_samples': 143, 'min_child_weight': 165, 'subsample': 0.8123019362983079, 'colsample_bytree': 0.208740672018353, 'reg_alpha': 0.26857189365631867, 'reg_lambda': 0.3156305962812591}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:50,204] Trial 605 finished with value: 0.5850245682836518 and parameters: {'n_estimators': 186, 'learning_rate': 0.029397600390775203, 'num_leaves': 23, 'max_depth': 144, 'min_child_samples': 143, 'min_child_weight': 164, 'subsample': 0.8110920062698898, 'colsample_bytree': 0.2237869932844951, 'reg_alpha': 0.19591292010107045, 'reg_lambda': 0.3111194820758604}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:53,574] Trial 608 finished with value: 0.5854524947127198 and parameters: {'n_estimators': 189, 'learning_rate': 0.029136385709603505, 'num_leaves': 7, 'max_depth': 143, 'min_child_samples': 147, 'min_child_weight': 163, 'subsample': 0.8097767107851281, 'colsample_bytree': 0.22474336840218959, 'reg_alpha': 0.19591579787050414, 'reg_lambda': 0.33617841705763135}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:54,158] Trial 615 pruned. \n",
      "[I 2023-07-02 03:33:54,798] Trial 609 finished with value: 0.58532260690075 and parameters: {'n_estimators': 187, 'learning_rate': 0.029696686256306504, 'num_leaves': 22, 'max_depth': 160, 'min_child_samples': 136, 'min_child_weight': 172, 'subsample': 0.7959221657880596, 'colsample_bytree': 0.22373642340119093, 'reg_alpha': 0.2666550946882269, 'reg_lambda': 0.30771391752062033}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:55,685] Trial 610 pruned. \n",
      "[I 2023-07-02 03:33:55,917] Trial 611 pruned. \n",
      "[I 2023-07-02 03:33:56,215] Trial 616 pruned. \n",
      "[I 2023-07-02 03:33:57,647] Trial 614 pruned. \n",
      "[I 2023-07-02 03:33:58,152] Trial 613 pruned. \n",
      "[I 2023-07-02 03:33:58,340] Trial 612 finished with value: 0.5844427129986511 and parameters: {'n_estimators': 139, 'learning_rate': 0.03670042088711906, 'num_leaves': 19, 'max_depth': 162, 'min_child_samples': 164, 'min_child_weight': 171, 'subsample': 0.8206302511484213, 'colsample_bytree': 0.22633095181802287, 'reg_alpha': 0.2620306463608807, 'reg_lambda': 0.34255104783738577}. Best is trial 574 with value: 0.5859887520781273.\n",
      "[I 2023-07-02 03:33:58,711] Trial 618 pruned. \n",
      "[I 2023-07-02 03:34:00,000] Trial 619 pruned. \n",
      "[I 2023-07-02 03:34:01,165] Trial 617 pruned. \n",
      "[I 2023-07-02 03:34:04,095] Trial 620 finished with value: 0.5860964922951825 and parameters: {'n_estimators': 227, 'learning_rate': 0.02789151732850725, 'num_leaves': 5, 'max_depth': 126, 'min_child_samples': 136, 'min_child_weight': 171, 'subsample': 0.7929242733517304, 'colsample_bytree': 0.248181052977835, 'reg_alpha': 0.1499342638828079, 'reg_lambda': 0.3433835470235215}. Best is trial 620 with value: 0.5860964922951825.\n",
      "[I 2023-07-02 03:34:05,033] Trial 627 pruned. \n",
      "[I 2023-07-02 03:34:05,804] Trial 621 finished with value: 0.5858084925504181 and parameters: {'n_estimators': 233, 'learning_rate': 0.02768097801851097, 'num_leaves': 6, 'max_depth': 146, 'min_child_samples': 135, 'min_child_weight': 172, 'subsample': 0.8403966662939172, 'colsample_bytree': 0.25237934519825095, 'reg_alpha': 0.26141108675877955, 'reg_lambda': 0.3574879259069956}. Best is trial 620 with value: 0.5860964922951825.\n",
      "[I 2023-07-02 03:34:05,953] Trial 626 pruned. \n",
      "[I 2023-07-02 03:34:07,194] Trial 622 pruned. \n",
      "[I 2023-07-02 03:34:07,823] Trial 623 finished with value: 0.5855737278919253 and parameters: {'n_estimators': 232, 'learning_rate': 0.02702688892272574, 'num_leaves': 6, 'max_depth': 148, 'min_child_samples': 136, 'min_child_weight': 172, 'subsample': 0.7932870424674502, 'colsample_bytree': 0.24132848970506662, 'reg_alpha': 0.13896978587001246, 'reg_lambda': 0.3617572744002526}. Best is trial 620 with value: 0.5860964922951825.\n",
      "[I 2023-07-02 03:34:08,210] Trial 625 finished with value: 0.5835547042800988 and parameters: {'n_estimators': 228, 'learning_rate': 0.027107371825914713, 'num_leaves': 14, 'max_depth': 147, 'min_child_samples': 136, 'min_child_weight': 171, 'subsample': 0.7954256143786211, 'colsample_bytree': 0.06331667902945765, 'reg_alpha': 0.18137521833971937, 'reg_lambda': 0.13846590965674266}. Best is trial 620 with value: 0.5860964922951825.\n",
      "[I 2023-07-02 03:34:09,238] Trial 624 pruned. \n",
      "[I 2023-07-02 03:34:09,415] Trial 630 pruned. \n",
      "[I 2023-07-02 03:34:09,687] Trial 631 pruned. \n",
      "[I 2023-07-02 03:34:10,551] Trial 632 pruned. \n",
      "[I 2023-07-02 03:34:12,211] Trial 633 pruned. \n",
      "[I 2023-07-02 03:34:12,734] Trial 629 pruned. \n",
      "[I 2023-07-02 03:34:13,797] Trial 636 pruned. \n",
      "[I 2023-07-02 03:34:14,162] Trial 628 pruned. \n",
      "[I 2023-07-02 03:34:15,391] Trial 638 pruned. \n",
      "[I 2023-07-02 03:34:16,534] Trial 637 pruned. \n",
      "[I 2023-07-02 03:34:16,741] Trial 634 pruned. \n",
      "[I 2023-07-02 03:34:18,162] Trial 639 pruned. \n",
      "[I 2023-07-02 03:34:18,797] Trial 635 finished with value: 0.5864747718200681 and parameters: {'n_estimators': 255, 'learning_rate': 0.02519520422628258, 'num_leaves': 4, 'max_depth': 156, 'min_child_samples': 133, 'min_child_weight': 174, 'subsample': 0.5745498721350651, 'colsample_bytree': 0.2641400840946442, 'reg_alpha': 0.13769192293954782, 'reg_lambda': 0.37298069605031287}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:34:18,977] Trial 640 finished with value: 0.5854897401610424 and parameters: {'n_estimators': 153, 'learning_rate': 0.03721149082238458, 'num_leaves': 6, 'max_depth': 136, 'min_child_samples': 143, 'min_child_weight': 174, 'subsample': 0.8537680058658681, 'colsample_bytree': 0.2782782051748298, 'reg_alpha': 0.11636788699457182, 'reg_lambda': 0.3747327223009214}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:34:21,105] Trial 641 finished with value: 0.5859527257054868 and parameters: {'n_estimators': 157, 'learning_rate': 0.0372263710391139, 'num_leaves': 6, 'max_depth': 134, 'min_child_samples': 141, 'min_child_weight': 167, 'subsample': 0.7839110986687019, 'colsample_bytree': 0.244272148773575, 'reg_alpha': 0.09967707887499702, 'reg_lambda': 0.35961258636319865}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:34:22,819] Trial 645 pruned. \n",
      "[I 2023-07-02 03:34:23,498] Trial 643 finished with value: 0.5852934582804694 and parameters: {'n_estimators': 156, 'learning_rate': 0.03409642140723144, 'num_leaves': 8, 'max_depth': 156, 'min_child_samples': 127, 'min_child_weight': 166, 'subsample': 0.8974415999928781, 'colsample_bytree': 0.2805902828387704, 'reg_alpha': 0.2922160213404213, 'reg_lambda': 0.17228426065272984}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:34:23,801] Trial 648 pruned. \n",
      "[I 2023-07-02 03:34:24,220] Trial 647 pruned. \n",
      "[I 2023-07-02 03:34:24,697] Trial 646 pruned. \n",
      "[I 2023-07-02 03:34:26,631] Trial 644 finished with value: 0.5848047621225902 and parameters: {'n_estimators': 185, 'learning_rate': 0.0350088005286467, 'num_leaves': 8, 'max_depth': 138, 'min_child_samples': 143, 'min_child_weight': 166, 'subsample': 0.8350172482574405, 'colsample_bytree': 0.2806927657413011, 'reg_alpha': 0.278493799889289, 'reg_lambda': 0.1618321816843979}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:34:26,952] Trial 653 pruned. \n",
      "[I 2023-07-02 03:34:27,582] Trial 649 pruned. \n",
      "[I 2023-07-02 03:34:29,780] Trial 655 pruned. \n",
      "[I 2023-07-02 03:34:30,553] Trial 654 pruned. \n",
      "[I 2023-07-02 03:34:30,775] Trial 642 pruned. \n",
      "[I 2023-07-02 03:34:32,674] Trial 657 pruned. \n",
      "[I 2023-07-02 03:34:32,785] Trial 650 finished with value: 0.583754681985352 and parameters: {'n_estimators': 198, 'learning_rate': 0.0355515275105442, 'num_leaves': 8, 'max_depth': 133, 'min_child_samples': 155, 'min_child_weight': 168, 'subsample': 0.8509308700978461, 'colsample_bytree': 0.28082173143027944, 'reg_alpha': 0.07205269533676367, 'reg_lambda': 0.3912928274091184}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:34:34,535] Trial 656 pruned. \n",
      "[I 2023-07-02 03:34:34,867] Trial 652 pruned. \n",
      "[I 2023-07-02 03:34:35,751] Trial 660 pruned. \n",
      "[I 2023-07-02 03:34:36,062] Trial 658 pruned. \n",
      "[I 2023-07-02 03:34:36,778] Trial 662 pruned. \n",
      "[I 2023-07-02 03:34:36,896] Trial 661 pruned. \n",
      "[I 2023-07-02 03:34:37,839] Trial 659 pruned. \n",
      "[I 2023-07-02 03:34:39,456] Trial 651 pruned. \n",
      "[I 2023-07-02 03:34:40,217] Trial 663 pruned. \n",
      "[I 2023-07-02 03:34:41,468] Trial 666 pruned. \n",
      "[I 2023-07-02 03:34:42,500] Trial 669 pruned. \n",
      "[I 2023-07-02 03:34:43,336] Trial 668 pruned. \n",
      "[I 2023-07-02 03:34:43,491] Trial 664 pruned. \n",
      "[I 2023-07-02 03:34:44,522] Trial 671 pruned. \n",
      "[I 2023-07-02 03:34:44,527] Trial 672 pruned. \n",
      "[I 2023-07-02 03:34:45,094] Trial 670 pruned. \n",
      "[I 2023-07-02 03:34:45,656] Trial 673 pruned. \n",
      "[I 2023-07-02 03:34:46,120] Trial 665 pruned. \n",
      "[I 2023-07-02 03:34:46,726] Trial 667 pruned. \n",
      "[I 2023-07-02 03:34:49,206] Trial 675 pruned. \n",
      "[I 2023-07-02 03:34:50,369] Trial 674 pruned. \n",
      "[I 2023-07-02 03:34:52,090] Trial 681 pruned. \n",
      "[I 2023-07-02 03:34:52,275] Trial 679 pruned. \n",
      "[I 2023-07-02 03:34:53,140] Trial 677 pruned. \n",
      "[I 2023-07-02 03:34:53,430] Trial 682 pruned. \n",
      "[I 2023-07-02 03:34:53,643] Trial 678 pruned. \n",
      "[I 2023-07-02 03:34:56,032] Trial 683 pruned. \n",
      "[I 2023-07-02 03:34:56,351] Trial 676 pruned. \n",
      "[I 2023-07-02 03:34:56,899] Trial 680 pruned. \n",
      "[I 2023-07-02 03:34:58,532] Trial 685 pruned. \n",
      "[I 2023-07-02 03:34:59,207] Trial 684 pruned. \n",
      "[I 2023-07-02 03:34:59,491] Trial 687 pruned. \n",
      "[I 2023-07-02 03:34:59,671] Trial 686 pruned. \n",
      "[I 2023-07-02 03:35:00,696] Trial 689 pruned. \n",
      "[I 2023-07-02 03:35:01,067] Trial 688 pruned. \n",
      "[I 2023-07-02 03:35:02,226] Trial 692 pruned. \n",
      "[I 2023-07-02 03:35:03,168] Trial 690 pruned. \n",
      "[I 2023-07-02 03:35:03,925] Trial 694 pruned. \n",
      "[I 2023-07-02 03:35:04,947] Trial 697 pruned. \n",
      "[I 2023-07-02 03:35:06,616] Trial 699 pruned. \n",
      "[I 2023-07-02 03:35:07,805] Trial 693 pruned. \n",
      "[I 2023-07-02 03:35:08,509] Trial 701 pruned. \n",
      "[I 2023-07-02 03:35:08,616] Trial 695 pruned. \n",
      "[I 2023-07-02 03:35:10,266] Trial 698 pruned. \n",
      "[I 2023-07-02 03:35:11,478] Trial 696 pruned. \n",
      "[I 2023-07-02 03:35:12,089] Trial 700 finished with value: 0.5846956820990915 and parameters: {'n_estimators': 132, 'learning_rate': 0.033575131773506864, 'num_leaves': 27, 'max_depth': 116, 'min_child_samples': 140, 'min_child_weight': 156, 'subsample': 0.5463612431230489, 'colsample_bytree': 0.23159268042937986, 'reg_alpha': 0.10297544759412662, 'reg_lambda': 0.12825611557533095}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:35:12,409] Trial 703 pruned. \n",
      "[I 2023-07-02 03:35:13,933] Trial 702 pruned. \n",
      "[I 2023-07-02 03:35:14,695] Trial 705 pruned. \n",
      "[I 2023-07-02 03:35:14,904] Trial 704 pruned. \n",
      "[I 2023-07-02 03:35:15,136] Trial 691 pruned. \n",
      "[I 2023-07-02 03:35:15,655] Trial 706 pruned. \n",
      "[I 2023-07-02 03:35:18,394] Trial 710 pruned. \n",
      "[I 2023-07-02 03:35:20,544] Trial 708 pruned. \n",
      "[I 2023-07-02 03:35:20,825] Trial 709 pruned. \n",
      "[I 2023-07-02 03:35:21,036] Trial 713 pruned. \n",
      "[I 2023-07-02 03:35:21,808] Trial 714 pruned. \n",
      "[I 2023-07-02 03:35:22,238] Trial 715 pruned. \n",
      "[I 2023-07-02 03:35:22,566] Trial 712 pruned. \n",
      "[I 2023-07-02 03:35:23,885] Trial 711 pruned. \n",
      "[I 2023-07-02 03:35:25,694] Trial 716 pruned. \n",
      "[I 2023-07-02 03:35:26,600] Trial 721 pruned. \n",
      "[I 2023-07-02 03:35:26,946] Trial 722 pruned. \n",
      "[I 2023-07-02 03:35:27,761] Trial 717 pruned. \n",
      "[I 2023-07-02 03:35:27,813] Trial 718 pruned. \n",
      "[I 2023-07-02 03:35:28,796] Trial 723 pruned. \n",
      "[I 2023-07-02 03:35:29,999] Trial 724 pruned. \n",
      "[I 2023-07-02 03:35:30,573] Trial 719 finished with value: 0.5851195881211824 and parameters: {'n_estimators': 157, 'learning_rate': 0.026644886183169108, 'num_leaves': 17, 'max_depth': 150, 'min_child_samples': 126, 'min_child_weight': 162, 'subsample': 0.6470478572714927, 'colsample_bytree': 0.21646297930622183, 'reg_alpha': 0.21221960763905928, 'reg_lambda': 0.17437393536767054}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:35:30,997] Trial 720 finished with value: 0.5852378403903064 and parameters: {'n_estimators': 156, 'learning_rate': 0.02661876817324955, 'num_leaves': 20, 'max_depth': 152, 'min_child_samples': 145, 'min_child_weight': 166, 'subsample': 0.569907097143346, 'colsample_bytree': 0.21169141867411842, 'reg_alpha': 0.21431559544314696, 'reg_lambda': 0.38235136840092804}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:35:31,361] Trial 727 pruned. \n",
      "[I 2023-07-02 03:35:31,928] Trial 707 pruned. \n",
      "[I 2023-07-02 03:35:33,558] Trial 728 pruned. \n",
      "[I 2023-07-02 03:35:34,771] Trial 726 pruned. \n",
      "[I 2023-07-02 03:35:35,534] Trial 725 finished with value: 0.585480085008602 and parameters: {'n_estimators': 159, 'learning_rate': 0.026763249188740706, 'num_leaves': 160, 'max_depth': 141, 'min_child_samples': 145, 'min_child_weight': 173, 'subsample': 0.895806839198233, 'colsample_bytree': 0.2275009005153544, 'reg_alpha': 0.45252777451725995, 'reg_lambda': 0.3229044053048612}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:35:36,922] Trial 731 pruned. \n",
      "[I 2023-07-02 03:35:38,214] Trial 735 pruned. \n",
      "[I 2023-07-02 03:35:39,434] Trial 734 pruned. \n",
      "[I 2023-07-02 03:35:40,410] Trial 737 pruned. \n",
      "[I 2023-07-02 03:35:41,070] Trial 738 pruned. \n",
      "[I 2023-07-02 03:35:42,936] Trial 740 pruned. \n",
      "[I 2023-07-02 03:35:42,986] Trial 739 pruned. \n",
      "[I 2023-07-02 03:35:44,102] Trial 733 finished with value: 0.5848853872893593 and parameters: {'n_estimators': 241, 'learning_rate': 0.023475277489321194, 'num_leaves': 33, 'max_depth': 138, 'min_child_samples': 158, 'min_child_weight': 156, 'subsample': 0.6575658291569588, 'colsample_bytree': 0.25765585316987033, 'reg_alpha': 0.18416252890501428, 'reg_lambda': 0.39634332718837717}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:35:45,631] Trial 741 pruned. \n",
      "[I 2023-07-02 03:35:46,184] Trial 736 finished with value: 0.5850659520625493 and parameters: {'n_estimators': 228, 'learning_rate': 0.022848734152118765, 'num_leaves': 164, 'max_depth': 137, 'min_child_samples': 148, 'min_child_weight': 177, 'subsample': 0.5667110602411338, 'colsample_bytree': 0.2567821008686925, 'reg_alpha': 0.45894559699483595, 'reg_lambda': 0.4053186902319882}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:35:47,031] Trial 729 pruned. \n",
      "[I 2023-07-02 03:35:47,992] Trial 744 pruned. \n",
      "[I 2023-07-02 03:35:48,735] Trial 747 pruned. \n",
      "[I 2023-07-02 03:35:49,710] Trial 748 pruned. \n",
      "[I 2023-07-02 03:35:51,287] Trial 742 pruned. \n",
      "[I 2023-07-02 03:35:51,457] Trial 746 pruned. \n",
      "[I 2023-07-02 03:35:53,062] Trial 750 pruned. \n",
      "[I 2023-07-02 03:35:53,183] Trial 730 pruned. \n",
      "[I 2023-07-02 03:35:53,831] Trial 749 pruned. \n",
      "[I 2023-07-02 03:35:54,402] Trial 732 pruned. \n",
      "[I 2023-07-02 03:35:56,062] Trial 751 pruned. \n",
      "[I 2023-07-02 03:35:58,044] Trial 754 pruned. \n",
      "[I 2023-07-02 03:35:58,184] Trial 753 pruned. \n",
      "[I 2023-07-02 03:36:00,082] Trial 757 pruned. \n",
      "[I 2023-07-02 03:36:01,076] Trial 755 pruned. \n",
      "[I 2023-07-02 03:36:01,488] Trial 756 pruned. \n",
      "[I 2023-07-02 03:36:02,625] Trial 759 pruned. \n",
      "[I 2023-07-02 03:36:02,886] Trial 743 pruned. \n",
      "[I 2023-07-02 03:36:03,208] Trial 758 pruned. \n",
      "[I 2023-07-02 03:36:04,627] Trial 760 pruned. \n",
      "[I 2023-07-02 03:36:05,821] Trial 765 pruned. \n",
      "[I 2023-07-02 03:36:06,445] Trial 766 pruned. \n",
      "[I 2023-07-02 03:36:06,604] Trial 764 pruned. \n",
      "[I 2023-07-02 03:36:06,764] Trial 761 pruned. \n",
      "[I 2023-07-02 03:36:06,963] Trial 762 pruned. \n",
      "[I 2023-07-02 03:36:09,001] Trial 763 pruned. \n",
      "[I 2023-07-02 03:36:10,237] Trial 767 pruned. \n",
      "[I 2023-07-02 03:36:11,537] Trial 745 pruned. \n",
      "[I 2023-07-02 03:36:12,363] Trial 771 pruned. \n",
      "[I 2023-07-02 03:36:13,064] Trial 772 pruned. \n",
      "[I 2023-07-02 03:36:14,460] Trial 773 pruned. \n",
      "[I 2023-07-02 03:36:14,598] Trial 769 finished with value: 0.5852099522894089 and parameters: {'n_estimators': 169, 'learning_rate': 0.02467384180140526, 'num_leaves': 171, 'max_depth': 159, 'min_child_samples': 136, 'min_child_weight': 182, 'subsample': 0.8130430541372247, 'colsample_bytree': 0.20936480691415343, 'reg_alpha': 0.18885212825220818, 'reg_lambda': 0.3360156666322464}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:14,872] Trial 775 pruned. \n",
      "[I 2023-07-02 03:36:14,907] Trial 770 finished with value: 0.5835186028107351 and parameters: {'n_estimators': 172, 'learning_rate': 0.03865872167779568, 'num_leaves': 23, 'max_depth': 157, 'min_child_samples': 135, 'min_child_weight': 181, 'subsample': 0.5247003306039544, 'colsample_bytree': 0.20407527458174013, 'reg_alpha': 0.19615560310276361, 'reg_lambda': 0.32933034436255254}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:16,766] Trial 752 pruned. \n",
      "[I 2023-07-02 03:36:18,520] Trial 777 pruned. \n",
      "[I 2023-07-02 03:36:18,801] Trial 778 pruned. \n",
      "[I 2023-07-02 03:36:19,258] Trial 779 pruned. \n",
      "[I 2023-07-02 03:36:19,472] Trial 780 pruned. \n",
      "[I 2023-07-02 03:36:20,129] Trial 781 pruned. \n",
      "[I 2023-07-02 03:36:20,333] Trial 774 pruned. \n",
      "[I 2023-07-02 03:36:23,021] Trial 782 pruned. \n",
      "[I 2023-07-02 03:36:24,042] Trial 787 pruned. \n",
      "[I 2023-07-02 03:36:24,845] Trial 784 pruned. \n",
      "[I 2023-07-02 03:36:25,675] Trial 788 pruned. \n",
      "[I 2023-07-02 03:36:25,993] Trial 786 pruned. \n",
      "[I 2023-07-02 03:36:26,976] Trial 785 pruned. \n",
      "[I 2023-07-02 03:36:28,269] Trial 783 pruned. \n",
      "[I 2023-07-02 03:36:28,529] Trial 776 pruned. \n",
      "[I 2023-07-02 03:36:28,846] Trial 789 pruned. \n",
      "[I 2023-07-02 03:36:30,994] Trial 790 pruned. \n",
      "[I 2023-07-02 03:36:31,490] Trial 793 pruned. \n",
      "[I 2023-07-02 03:36:35,297] Trial 768 pruned. \n",
      "[I 2023-07-02 03:36:37,609] Trial 794 pruned. \n",
      "[I 2023-07-02 03:36:37,617] Trial 792 pruned. \n",
      "[I 2023-07-02 03:36:37,647] Trial 798 pruned. \n",
      "[I 2023-07-02 03:36:37,863] Trial 796 finished with value: 0.5840443250222193 and parameters: {'n_estimators': 257, 'learning_rate': 0.03023377643614117, 'num_leaves': 184, 'max_depth': 159, 'min_child_samples': 140, 'min_child_weight': 177, 'subsample': 0.553011358344973, 'colsample_bytree': 0.2643301988635375, 'reg_alpha': 0.14274456870545568, 'reg_lambda': 0.5735726799847087}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:38,617] Trial 797 finished with value: 0.5839808936483504 and parameters: {'n_estimators': 256, 'learning_rate': 0.029632854973536654, 'num_leaves': 170, 'max_depth': 159, 'min_child_samples': 113, 'min_child_weight': 177, 'subsample': 0.606759781042488, 'colsample_bytree': 0.25069008743794874, 'reg_alpha': 0.8383861776860906, 'reg_lambda': 0.817428911128627}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:40,028] Trial 799 finished with value: 0.583789160271062 and parameters: {'n_estimators': 255, 'learning_rate': 0.028123105580791882, 'num_leaves': 168, 'max_depth': 157, 'min_child_samples': 114, 'min_child_weight': 174, 'subsample': 0.9362864282665466, 'colsample_bytree': 0.2615415139684829, 'reg_alpha': 0.4716612423216211, 'reg_lambda': 0.45471955862704033}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:41,193] Trial 791 pruned. \n",
      "[I 2023-07-02 03:36:41,527] Trial 795 pruned. \n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=200,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2ae49cd9de45569ac4aa7eb3034140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-02 03:36:45,685] Trial 805 pruned. \n",
      "[I 2023-07-02 03:36:45,933] Trial 802 pruned. \n",
      "[I 2023-07-02 03:36:47,942] Trial 807 pruned. \n",
      "[I 2023-07-02 03:36:48,644] Trial 801 pruned. \n",
      "[I 2023-07-02 03:36:50,709] Trial 800 pruned. \n",
      "[I 2023-07-02 03:36:50,738] Trial 809 pruned. \n",
      "[I 2023-07-02 03:36:51,634] Trial 811 pruned. \n",
      "[I 2023-07-02 03:36:53,225] Trial 810 pruned. \n",
      "[I 2023-07-02 03:36:53,523] Trial 803 finished with value: 0.5852656239222036 and parameters: {'n_estimators': 206, 'learning_rate': 0.028080283077030185, 'num_leaves': 23, 'max_depth': 152, 'min_child_samples': 155, 'min_child_weight': 168, 'subsample': 0.6480534852074774, 'colsample_bytree': 0.1993697854715269, 'reg_alpha': 0.80495864777286, 'reg_lambda': 0.07512886087805769}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:53,944] Trial 804 finished with value: 0.5853074760230382 and parameters: {'n_estimators': 211, 'learning_rate': 0.027447568321228303, 'num_leaves': 178, 'max_depth': 122, 'min_child_samples': 155, 'min_child_weight': 170, 'subsample': 0.8030675313546229, 'colsample_bytree': 0.201016355006838, 'reg_alpha': 0.410923753689574, 'reg_lambda': 0.21893960108149313}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:54,577] Trial 808 finished with value: 0.5843864896254971 and parameters: {'n_estimators': 162, 'learning_rate': 0.03409256108725956, 'num_leaves': 12, 'max_depth': 154, 'min_child_samples': 152, 'min_child_weight': 168, 'subsample': 0.9471284747389349, 'colsample_bytree': 0.19823078256363982, 'reg_alpha': 0.5093737810824897, 'reg_lambda': 0.9772527321064302}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:54,935] Trial 806 pruned. \n",
      "[I 2023-07-02 03:36:57,782] Trial 815 pruned. \n",
      "[I 2023-07-02 03:36:59,119] Trial 812 finished with value: 0.58387283783218 and parameters: {'n_estimators': 149, 'learning_rate': 0.03648831607024969, 'num_leaves': 17, 'max_depth': 142, 'min_child_samples': 141, 'min_child_weight': 162, 'subsample': 0.778185098157873, 'colsample_bytree': 0.20885859346657487, 'reg_alpha': 0.5270598573924032, 'reg_lambda': 0.23882264304916345}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:36:59,637] Trial 819 pruned. \n",
      "[I 2023-07-02 03:36:59,797] Trial 813 finished with value: 0.5845160355464947 and parameters: {'n_estimators': 161, 'learning_rate': 0.03269988907421638, 'num_leaves': 17, 'max_depth': 154, 'min_child_samples': 141, 'min_child_weight': 164, 'subsample': 0.9603669119181351, 'colsample_bytree': 0.2151431122457677, 'reg_alpha': 0.25476633786641234, 'reg_lambda': 0.4147497578210736}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:00,004] Trial 814 finished with value: 0.5844689110117208 and parameters: {'n_estimators': 168, 'learning_rate': 0.03313860364773895, 'num_leaves': 106, 'max_depth': 153, 'min_child_samples': 132, 'min_child_weight': 163, 'subsample': 0.7813443542430265, 'colsample_bytree': 0.21571290927774112, 'reg_alpha': 0.042296828705584974, 'reg_lambda': 0.3937507192113538}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:00,475] Trial 818 pruned. \n",
      "[I 2023-07-02 03:37:00,877] Trial 817 pruned. \n",
      "[I 2023-07-02 03:37:02,031] Trial 816 pruned. \n",
      "[I 2023-07-02 03:37:03,253] Trial 820 pruned. \n",
      "[I 2023-07-02 03:37:05,162] Trial 821 pruned. \n",
      "[I 2023-07-02 03:37:06,735] Trial 822 pruned. \n",
      "[I 2023-07-02 03:37:06,905] Trial 823 pruned. \n",
      "[I 2023-07-02 03:37:07,267] Trial 826 pruned. \n",
      "[I 2023-07-02 03:37:07,350] Trial 828 pruned. \n",
      "[I 2023-07-02 03:37:07,692] Trial 824 pruned. \n",
      "[I 2023-07-02 03:37:08,046] Trial 825 pruned. \n",
      "[I 2023-07-02 03:37:11,092] Trial 829 pruned. \n",
      "[I 2023-07-02 03:37:12,800] Trial 827 finished with value: 0.5833185995939283 and parameters: {'n_estimators': 243, 'learning_rate': 0.02807843428556369, 'num_leaves': 24, 'max_depth': 133, 'min_child_samples': 162, 'min_child_weight': 151, 'subsample': 0.7905970329577481, 'colsample_bytree': 0.16575220907292418, 'reg_alpha': 0.8689428327894136, 'reg_lambda': 0.250761401535071}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:14,054] Trial 830 pruned. \n",
      "[I 2023-07-02 03:37:14,665] Trial 832 pruned. \n",
      "[I 2023-07-02 03:37:14,860] Trial 833 pruned. \n",
      "[I 2023-07-02 03:37:15,158] Trial 834 pruned. \n",
      "[I 2023-07-02 03:37:15,227] Trial 835 pruned. \n",
      "[I 2023-07-02 03:37:17,360] Trial 837 pruned. \n",
      "[I 2023-07-02 03:37:17,539] Trial 836 pruned. \n",
      "[I 2023-07-02 03:37:19,895] Trial 840 pruned. \n",
      "[I 2023-07-02 03:37:20,047] Trial 839 pruned. \n",
      "[I 2023-07-02 03:37:20,320] Trial 842 pruned. \n",
      "[I 2023-07-02 03:37:20,806] Trial 841 pruned. \n",
      "[I 2023-07-02 03:37:21,667] Trial 843 pruned. \n",
      "[I 2023-07-02 03:37:23,305] Trial 838 finished with value: 0.5841291502924048 and parameters: {'n_estimators': 208, 'learning_rate': 0.0268797006082589, 'num_leaves': 14, 'max_depth': 143, 'min_child_samples': 151, 'min_child_weight': 171, 'subsample': 0.8794259098398485, 'colsample_bytree': 0.24608360225591114, 'reg_alpha': 0.8235729283500894, 'reg_lambda': 0.7685791761719292}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:24,210] Trial 848 pruned. \n",
      "[I 2023-07-02 03:37:25,285] Trial 850 pruned. \n",
      "[I 2023-07-02 03:37:25,880] Trial 849 pruned. \n",
      "[I 2023-07-02 03:37:26,012] Trial 845 pruned. \n",
      "[I 2023-07-02 03:37:26,709] Trial 844 pruned. \n",
      "[I 2023-07-02 03:37:26,828] Trial 847 pruned. \n",
      "[I 2023-07-02 03:37:27,117] Trial 846 pruned. \n",
      "[I 2023-07-02 03:37:27,893] Trial 851 pruned. \n",
      "[I 2023-07-02 03:37:30,249] Trial 852 pruned. \n",
      "[I 2023-07-02 03:37:30,477] Trial 831 pruned. \n",
      "[I 2023-07-02 03:37:32,775] Trial 853 pruned. \n",
      "[I 2023-07-02 03:37:34,043] Trial 854 pruned. \n",
      "[I 2023-07-02 03:37:34,657] Trial 856 pruned. \n",
      "[I 2023-07-02 03:37:34,781] Trial 857 pruned. \n",
      "[I 2023-07-02 03:37:35,301] Trial 858 pruned. \n",
      "[I 2023-07-02 03:37:35,752] Trial 855 pruned. \n",
      "[I 2023-07-02 03:37:35,956] Trial 859 pruned. \n",
      "[I 2023-07-02 03:37:37,532] Trial 860 pruned. \n",
      "[I 2023-07-02 03:37:39,327] Trial 863 pruned. \n",
      "[I 2023-07-02 03:37:39,466] Trial 862 pruned. \n",
      "[I 2023-07-02 03:37:40,600] Trial 861 pruned. \n",
      "[I 2023-07-02 03:37:40,872] Trial 865 pruned. \n",
      "[I 2023-07-02 03:37:41,999] Trial 868 pruned. \n",
      "[I 2023-07-02 03:37:43,600] Trial 867 pruned. \n",
      "[I 2023-07-02 03:37:44,636] Trial 871 pruned. \n",
      "[I 2023-07-02 03:37:45,137] Trial 864 finished with value: 0.5856419473680728 and parameters: {'n_estimators': 134, 'learning_rate': 0.029233418906851136, 'num_leaves': 18, 'max_depth': 152, 'min_child_samples': 129, 'min_child_weight': 182, 'subsample': 0.6123875014170105, 'colsample_bytree': 0.22612678773281092, 'reg_alpha': 0.07884819319471034, 'reg_lambda': 0.45250502485884453}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:45,320] Trial 870 pruned. \n",
      "[I 2023-07-02 03:37:45,694] Trial 869 pruned. \n",
      "[I 2023-07-02 03:37:46,191] Trial 866 finished with value: 0.583691408436529 and parameters: {'n_estimators': 128, 'learning_rate': 0.02962231321722354, 'num_leaves': 30, 'max_depth': 157, 'min_child_samples': 133, 'min_child_weight': 169, 'subsample': 0.5802963292456922, 'colsample_bytree': 0.7247333321217531, 'reg_alpha': 0.1327798663916837, 'reg_lambda': 0.9898267423703302}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:49,012] Trial 873 pruned. \n",
      "[I 2023-07-02 03:37:50,043] Trial 874 pruned. \n",
      "[I 2023-07-02 03:37:50,242] Trial 872 pruned. \n",
      "[I 2023-07-02 03:37:50,445] Trial 876 pruned. \n",
      "[I 2023-07-02 03:37:52,087] Trial 880 pruned. \n",
      "[I 2023-07-02 03:37:53,656] Trial 878 pruned. \n",
      "[I 2023-07-02 03:37:54,810] Trial 882 pruned. \n",
      "[I 2023-07-02 03:37:55,310] Trial 875 finished with value: 0.5857040250320823 and parameters: {'n_estimators': 214, 'learning_rate': 0.023190518921854437, 'num_leaves': 6, 'max_depth': 168, 'min_child_samples': 111, 'min_child_weight': 168, 'subsample': 0.6009512703446691, 'colsample_bytree': 0.2307258429751384, 'reg_alpha': 0.24042499508799775, 'reg_lambda': 0.3646764852325632}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:56,653] Trial 881 pruned. \n",
      "[I 2023-07-02 03:37:57,498] Trial 879 finished with value: 0.5849970461731255 and parameters: {'n_estimators': 216, 'learning_rate': 0.02663902018182234, 'num_leaves': 15, 'max_depth': 146, 'min_child_samples': 142, 'min_child_weight': 181, 'subsample': 0.6009691152657459, 'colsample_bytree': 0.2187874851548106, 'reg_alpha': 0.10870087718715393, 'reg_lambda': 0.3705430430866287}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:37:57,652] Trial 883 pruned. \n",
      "[I 2023-07-02 03:37:59,540] Trial 885 pruned. \n",
      "[I 2023-07-02 03:38:00,263] Trial 888 pruned. \n",
      "[I 2023-07-02 03:38:00,909] Trial 884 finished with value: 0.5844199379703452 and parameters: {'n_estimators': 208, 'learning_rate': 0.030997467576304435, 'num_leaves': 15, 'max_depth': 147, 'min_child_samples': 128, 'min_child_weight': 184, 'subsample': 0.6027178968955399, 'colsample_bytree': 0.1996495381891669, 'reg_alpha': 0.2398195357195565, 'reg_lambda': 0.9751973838028559}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:38:02,828] Trial 886 pruned. \n",
      "[I 2023-07-02 03:38:03,078] Trial 889 pruned. \n",
      "[I 2023-07-02 03:38:03,591] Trial 893 pruned. \n",
      "[I 2023-07-02 03:38:04,261] Trial 891 pruned. \n",
      "[I 2023-07-02 03:38:04,983] Trial 892 pruned. \n",
      "[I 2023-07-02 03:38:06,011] Trial 887 finished with value: 0.5851328855620341 and parameters: {'n_estimators': 215, 'learning_rate': 0.02618366991195014, 'num_leaves': 8, 'max_depth': 184, 'min_child_samples': 125, 'min_child_weight': 178, 'subsample': 0.6275978749530746, 'colsample_bytree': 0.20692296158227114, 'reg_alpha': 0.2435539633793662, 'reg_lambda': 0.36887489262342504}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:38:06,875] Trial 890 pruned. \n",
      "[I 2023-07-02 03:38:08,009] Trial 894 pruned. \n",
      "[I 2023-07-02 03:38:09,767] Trial 899 pruned. \n",
      "[I 2023-07-02 03:38:09,925] Trial 877 pruned. \n",
      "[I 2023-07-02 03:38:10,323] Trial 896 pruned. \n",
      "[I 2023-07-02 03:38:10,590] Trial 900 pruned. \n",
      "[I 2023-07-02 03:38:10,909] Trial 897 pruned. \n",
      "[I 2023-07-02 03:38:11,213] Trial 901 pruned. \n",
      "[I 2023-07-02 03:38:13,502] Trial 895 pruned. \n",
      "[I 2023-07-02 03:38:15,177] Trial 898 pruned. \n",
      "[I 2023-07-02 03:38:15,328] Trial 902 pruned. \n",
      "[I 2023-07-02 03:38:16,855] Trial 903 pruned. \n",
      "[I 2023-07-02 03:38:17,929] Trial 906 pruned. \n",
      "[I 2023-07-02 03:38:18,358] Trial 908 pruned. \n",
      "[I 2023-07-02 03:38:18,872] Trial 904 pruned. \n",
      "[I 2023-07-02 03:38:19,483] Trial 905 pruned. \n",
      "[I 2023-07-02 03:38:20,843] Trial 909 pruned. \n",
      "[I 2023-07-02 03:38:21,071] Trial 910 pruned. \n",
      "[I 2023-07-02 03:38:22,379] Trial 912 pruned. \n",
      "[I 2023-07-02 03:38:23,016] Trial 913 pruned. \n",
      "[I 2023-07-02 03:38:24,313] Trial 907 finished with value: 0.5839179207485291 and parameters: {'n_estimators': 240, 'learning_rate': 0.02750204075545033, 'num_leaves': 12, 'max_depth': 157, 'min_child_samples': 133, 'min_child_weight': 162, 'subsample': 0.766386653607293, 'colsample_bytree': 0.2711382486109144, 'reg_alpha': 0.5085953603308686, 'reg_lambda': 0.4513323389480024}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:38:24,988] Trial 914 pruned. \n",
      "[I 2023-07-02 03:38:25,506] Trial 916 pruned. \n",
      "[I 2023-07-02 03:38:26,698] Trial 918 pruned. \n",
      "[I 2023-07-02 03:38:26,947] Trial 915 finished with value: 0.5845746528713797 and parameters: {'n_estimators': 100, 'learning_rate': 0.05956616954057952, 'num_leaves': 11, 'max_depth': 135, 'min_child_samples': 156, 'min_child_weight': 161, 'subsample': 0.6402841280045797, 'colsample_bytree': 0.2716526059101468, 'reg_alpha': 0.541652867965981, 'reg_lambda': 0.38925139871690706}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:38:27,897] Trial 911 finished with value: 0.5848276825121441 and parameters: {'n_estimators': 235, 'learning_rate': 0.02328779426695929, 'num_leaves': 12, 'max_depth': 158, 'min_child_samples': 133, 'min_child_weight': 162, 'subsample': 0.5791587257635546, 'colsample_bytree': 0.26821141129574966, 'reg_alpha': 0.9575862760426591, 'reg_lambda': 0.3938805104944572}. Best is trial 635 with value: 0.5864747718200681.\n",
      "[I 2023-07-02 03:38:28,441] Trial 920 pruned. \n",
      "[I 2023-07-02 03:38:29,827] Trial 917 pruned. \n",
      "[I 2023-07-02 03:38:30,198] Trial 922 pruned. \n",
      "[I 2023-07-02 03:38:31,592] Trial 924 pruned. \n",
      "[I 2023-07-02 03:38:32,748] Trial 923 pruned. \n",
      "[I 2023-07-02 03:38:33,930] Trial 928 pruned. \n",
      "[I 2023-07-02 03:38:35,653] Trial 919 pruned. \n",
      "[I 2023-07-02 03:38:36,559] Trial 926 pruned. \n",
      "[I 2023-07-02 03:38:36,812] Trial 925 pruned. \n",
      "[I 2023-07-02 03:38:36,947] Trial 929 pruned. \n",
      "[I 2023-07-02 03:38:38,189] Trial 921 pruned. \n",
      "[I 2023-07-02 03:38:39,252] Trial 927 pruned. \n",
      "[I 2023-07-02 03:38:40,748] Trial 930 pruned. \n",
      "[I 2023-07-02 03:38:41,387] Trial 934 pruned. \n",
      "[I 2023-07-02 03:38:41,984] Trial 932 pruned. \n",
      "[I 2023-07-02 03:38:43,470] Trial 936 pruned. \n",
      "[I 2023-07-02 03:38:44,146] Trial 937 finished with value: 0.5865752954768694 and parameters: {'n_estimators': 101, 'learning_rate': 0.04690869066818215, 'num_leaves': 6, 'max_depth': 149, 'min_child_samples': 167, 'min_child_weight': 182, 'subsample': 0.9898445595230461, 'colsample_bytree': 0.25091523433824614, 'reg_alpha': 0.07390004843770646, 'reg_lambda': 0.266759505866569}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:38:45,166] Trial 933 pruned. \n",
      "[I 2023-07-02 03:38:45,759] Trial 931 pruned. \n",
      "[I 2023-07-02 03:38:46,453] Trial 940 pruned. \n",
      "[I 2023-07-02 03:38:47,155] Trial 939 pruned. \n",
      "[I 2023-07-02 03:38:47,406] Trial 935 pruned. \n",
      "[I 2023-07-02 03:38:47,865] Trial 941 pruned. \n",
      "[I 2023-07-02 03:38:47,872] Trial 938 pruned. \n",
      "[I 2023-07-02 03:38:48,617] Trial 943 pruned. \n",
      "[I 2023-07-02 03:38:51,028] Trial 942 pruned. \n",
      "[I 2023-07-02 03:38:52,266] Trial 948 pruned. \n",
      "[I 2023-07-02 03:38:52,331] Trial 949 pruned. \n",
      "[I 2023-07-02 03:38:52,640] Trial 946 pruned. \n",
      "[I 2023-07-02 03:38:52,982] Trial 947 pruned. \n",
      "[I 2023-07-02 03:38:53,537] Trial 944 pruned. \n",
      "[I 2023-07-02 03:38:54,826] Trial 945 pruned. \n",
      "[I 2023-07-02 03:38:55,094] Trial 951 pruned. \n",
      "[I 2023-07-02 03:38:57,052] Trial 950 finished with value: 0.5862443143837623 and parameters: {'n_estimators': 108, 'learning_rate': 0.04355325152207967, 'num_leaves': 9, 'max_depth': 127, 'min_child_samples': 175, 'min_child_weight': 176, 'subsample': 0.9288504087060572, 'colsample_bytree': 0.24823931446230188, 'reg_alpha': 0.07973031282347162, 'reg_lambda': 0.30267755228461696}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:38:57,823] Trial 952 pruned. \n",
      "[I 2023-07-02 03:38:58,683] Trial 956 pruned. \n",
      "[I 2023-07-02 03:38:59,816] Trial 954 pruned. \n",
      "[I 2023-07-02 03:39:00,330] Trial 958 pruned. \n",
      "[I 2023-07-02 03:39:00,941] Trial 955 pruned. \n",
      "[I 2023-07-02 03:39:02,466] Trial 961 pruned. \n",
      "[I 2023-07-02 03:39:02,601] Trial 959 pruned. \n",
      "[I 2023-07-02 03:39:03,397] Trial 953 finished with value: 0.5844238467518601 and parameters: {'n_estimators': 159, 'learning_rate': 0.04837831463441937, 'num_leaves': 10, 'max_depth': 164, 'min_child_samples': 182, 'min_child_weight': 185, 'subsample': 0.9611165787124735, 'colsample_bytree': 0.24966423296637602, 'reg_alpha': 0.07975744217508754, 'reg_lambda': 0.30114310074533573}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:39:04,012] Trial 960 pruned. \n",
      "[I 2023-07-02 03:39:05,246] Trial 957 finished with value: 0.585197219336884 and parameters: {'n_estimators': 165, 'learning_rate': 0.04361326281773404, 'num_leaves': 13, 'max_depth': 165, 'min_child_samples': 124, 'min_child_weight': 183, 'subsample': 0.9514373547857101, 'colsample_bytree': 0.24930991732015878, 'reg_alpha': 0.586435879526263, 'reg_lambda': 0.7860029747622632}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:39:05,947] Trial 963 pruned. \n",
      "[I 2023-07-02 03:39:06,216] Trial 962 pruned. \n",
      "[I 2023-07-02 03:39:06,279] Trial 964 pruned. \n",
      "[I 2023-07-02 03:39:09,912] Trial 965 pruned. \n",
      "[I 2023-07-02 03:39:10,093] Trial 966 pruned. \n",
      "[I 2023-07-02 03:39:10,881] Trial 970 pruned. \n",
      "[I 2023-07-02 03:39:11,083] Trial 967 pruned. \n",
      "[I 2023-07-02 03:39:11,620] Trial 968 pruned. \n",
      "[I 2023-07-02 03:39:13,234] Trial 969 pruned. \n",
      "[I 2023-07-02 03:39:13,544] Trial 972 pruned. \n",
      "[I 2023-07-02 03:39:14,956] Trial 973 pruned. \n",
      "[I 2023-07-02 03:39:15,881] Trial 971 finished with value: 0.5830947869795888 and parameters: {'n_estimators': 212, 'learning_rate': 0.04612544384414975, 'num_leaves': 6, 'max_depth': 133, 'min_child_samples': 185, 'min_child_weight': 177, 'subsample': 0.9427496197365233, 'colsample_bytree': 0.031155531654743995, 'reg_alpha': 0.7476856745338339, 'reg_lambda': 0.2023738309135371}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:39:16,580] Trial 976 pruned. \n",
      "[I 2023-07-02 03:39:17,460] Trial 979 pruned. \n",
      "[I 2023-07-02 03:39:17,756] Trial 978 pruned. \n",
      "[I 2023-07-02 03:39:19,967] Trial 975 pruned. \n",
      "[I 2023-07-02 03:39:20,381] Trial 977 pruned. \n",
      "[I 2023-07-02 03:39:20,832] Trial 981 pruned. \n",
      "[I 2023-07-02 03:39:21,468] Trial 984 pruned. \n",
      "[I 2023-07-02 03:39:21,834] Trial 980 pruned. \n",
      "[I 2023-07-02 03:39:22,961] Trial 983 pruned. \n",
      "[I 2023-07-02 03:39:23,414] Trial 982 pruned. \n",
      "[I 2023-07-02 03:39:25,069] Trial 985 pruned. \n",
      "[I 2023-07-02 03:39:25,872] Trial 986 pruned. \n",
      "[I 2023-07-02 03:39:26,911] Trial 987 pruned. \n",
      "[I 2023-07-02 03:39:27,494] Trial 989 pruned. \n",
      "[I 2023-07-02 03:39:28,855] Trial 992 pruned. \n",
      "[I 2023-07-02 03:39:29,155] Trial 991 pruned. \n",
      "[I 2023-07-02 03:39:30,965] Trial 994 pruned. \n",
      "[I 2023-07-02 03:39:31,656] Trial 996 pruned. \n",
      "[I 2023-07-02 03:39:31,807] Trial 974 pruned. \n",
      "[I 2023-07-02 03:39:32,393] Trial 995 finished with value: 0.5834003156909778 and parameters: {'n_estimators': 100, 'learning_rate': 0.06185325448805588, 'num_leaves': 35, 'max_depth': 260, 'min_child_samples': 151, 'min_child_weight': 182, 'subsample': 0.886331598846807, 'colsample_bytree': 0.22855374089377645, 'reg_alpha': 0.8116530783304159, 'reg_lambda': 0.5835054945299354}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:39:33,372] Trial 997 pruned. \n",
      "[I 2023-07-02 03:39:33,904] Trial 998 pruned. \n",
      "[I 2023-07-02 03:39:34,274] Trial 999 pruned. \n",
      "[I 2023-07-02 03:39:36,008] Trial 988 pruned. \n",
      "[I 2023-07-02 03:39:36,245] Trial 990 pruned. \n",
      "[I 2023-07-02 03:39:36,739] Trial 993 pruned. \n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=200,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c169e895f49146719abfaa82f5ce9a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-07-02 03:40:03,215] Trial 1004 pruned. \n",
      "[I 2023-07-02 03:40:03,411] Trial 1006 pruned. \n",
      "[I 2023-07-02 03:40:04,986] Trial 1005 pruned. \n",
      "[I 2023-07-02 03:40:05,796] Trial 1007 pruned. \n",
      "[I 2023-07-02 03:40:07,014] Trial 1000 pruned. \n",
      "[I 2023-07-02 03:40:08,107] Trial 1002 pruned. \n",
      "[I 2023-07-02 03:40:08,620] Trial 1009 pruned. \n",
      "[I 2023-07-02 03:40:09,869] Trial 1001 pruned. \n",
      "[I 2023-07-02 03:40:10,592] Trial 1011 pruned. \n",
      "[I 2023-07-02 03:40:10,998] Trial 1012 pruned. \n",
      "[I 2023-07-02 03:40:11,949] Trial 1010 pruned. \n",
      "[I 2023-07-02 03:40:12,174] Trial 1003 pruned. \n",
      "[I 2023-07-02 03:40:13,869] Trial 1014 pruned. \n",
      "[I 2023-07-02 03:40:16,160] Trial 1018 pruned. \n",
      "[I 2023-07-02 03:40:17,353] Trial 1019 pruned. \n",
      "[I 2023-07-02 03:40:17,767] Trial 1016 finished with value: 0.584716539240983 and parameters: {'n_estimators': 147, 'learning_rate': 0.027555979962876162, 'num_leaves': 154, 'max_depth': 147, 'min_child_samples': 127, 'min_child_weight': 165, 'subsample': 0.7969346276001489, 'colsample_bytree': 0.23658934438379997, 'reg_alpha': 0.41673460734782525, 'reg_lambda': 0.9255950340248555}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:18,076] Trial 1008 pruned. \n",
      "[I 2023-07-02 03:40:18,457] Trial 1013 finished with value: 0.5841549005007471 and parameters: {'n_estimators': 226, 'learning_rate': 0.02856427773690391, 'num_leaves': 186, 'max_depth': 272, 'min_child_samples': 129, 'min_child_weight': 160, 'subsample': 0.9362453162072477, 'colsample_bytree': 0.26193027086069176, 'reg_alpha': 0.4691625287529419, 'reg_lambda': 0.3384640019264013}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:19,314] Trial 1015 finished with value: 0.5845037786276502 and parameters: {'n_estimators': 230, 'learning_rate': 0.028322359074632052, 'num_leaves': 164, 'max_depth': 147, 'min_child_samples': 127, 'min_child_weight': 164, 'subsample': 0.8469287170827868, 'colsample_bytree': 0.23205082838922414, 'reg_alpha': 0.7074837831706587, 'reg_lambda': 0.035215802067944744}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:21,622] Trial 1017 finished with value: 0.5844839859102564 and parameters: {'n_estimators': 228, 'learning_rate': 0.027865946836602245, 'num_leaves': 12, 'max_depth': 148, 'min_child_samples': 126, 'min_child_weight': 164, 'subsample': 0.922470778265059, 'colsample_bytree': 0.2392580129305602, 'reg_alpha': 0.20204931236423104, 'reg_lambda': 0.331235395139999}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:23,206] Trial 1022 pruned. \n",
      "[I 2023-07-02 03:40:24,692] Trial 1023 pruned. \n",
      "[I 2023-07-02 03:40:25,996] Trial 1027 pruned. \n",
      "[I 2023-07-02 03:40:26,552] Trial 1021 pruned. \n",
      "[I 2023-07-02 03:40:26,740] Trial 1024 pruned. \n",
      "[I 2023-07-02 03:40:26,767] Trial 1020 finished with value: 0.5850250705188786 and parameters: {'n_estimators': 304, 'learning_rate': 0.019565963122006286, 'num_leaves': 7, 'max_depth': 137, 'min_child_samples': 116, 'min_child_weight': 165, 'subsample': 0.8017803031731107, 'colsample_bytree': 0.21926114217527132, 'reg_alpha': 0.732321810760046, 'reg_lambda': 0.33205220278562}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:27,600] Trial 1026 pruned. \n",
      "[I 2023-07-02 03:40:30,450] Trial 1025 pruned. \n",
      "[I 2023-07-02 03:40:31,238] Trial 1032 pruned. \n",
      "[I 2023-07-02 03:40:32,082] Trial 1034 pruned. \n",
      "[I 2023-07-02 03:40:32,139] Trial 1028 pruned. \n",
      "[I 2023-07-02 03:40:32,426] Trial 1029 pruned. \n",
      "[I 2023-07-02 03:40:34,560] Trial 1033 finished with value: 0.5837825618054774 and parameters: {'n_estimators': 100, 'learning_rate': 0.074133215365873, 'num_leaves': 20, 'max_depth': 110, 'min_child_samples': 140, 'min_child_weight': 180, 'subsample': 0.9545826737103735, 'colsample_bytree': 0.16182800749677823, 'reg_alpha': 0.015285790284357934, 'reg_lambda': 0.38210561131452936}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:34,734] Trial 1030 pruned. \n",
      "[I 2023-07-02 03:40:34,778] Trial 1036 pruned. \n",
      "[I 2023-07-02 03:40:36,151] Trial 1035 pruned. \n",
      "[I 2023-07-02 03:40:37,129] Trial 1031 pruned. \n",
      "[I 2023-07-02 03:40:38,528] Trial 1038 pruned. \n",
      "[I 2023-07-02 03:40:40,086] Trial 1037 pruned. \n",
      "[I 2023-07-02 03:40:40,634] Trial 1039 pruned. \n",
      "[I 2023-07-02 03:40:41,730] Trial 1043 pruned. \n",
      "[I 2023-07-02 03:40:41,878] Trial 1045 pruned. \n",
      "[I 2023-07-02 03:40:42,891] Trial 1040 pruned. \n",
      "[I 2023-07-02 03:40:44,067] Trial 1044 pruned. \n",
      "[I 2023-07-02 03:40:44,485] Trial 1046 pruned. \n",
      "[I 2023-07-02 03:40:45,626] Trial 1041 pruned. \n",
      "[I 2023-07-02 03:40:46,936] Trial 1048 pruned. \n",
      "[I 2023-07-02 03:40:47,127] Trial 1047 pruned. \n",
      "[I 2023-07-02 03:40:47,326] Trial 1042 finished with value: 0.584481419827169 and parameters: {'n_estimators': 180, 'learning_rate': 0.02616597552827681, 'num_leaves': 29, 'max_depth': 156, 'min_child_samples': 107, 'min_child_weight': 168, 'subsample': 0.999799184938166, 'colsample_bytree': 0.3061588454908414, 'reg_alpha': 0.3760426974669758, 'reg_lambda': 0.3109114947517518}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:49,653] Trial 1051 pruned. \n",
      "[I 2023-07-02 03:40:50,160] Trial 1053 pruned. \n",
      "[I 2023-07-02 03:40:50,770] Trial 1049 pruned. \n",
      "[I 2023-07-02 03:40:52,959] Trial 1056 pruned. \n",
      "[I 2023-07-02 03:40:53,149] Trial 1055 pruned. \n",
      "[I 2023-07-02 03:40:53,359] Trial 1054 pruned. \n",
      "[I 2023-07-02 03:40:54,153] Trial 1059 pruned. \n",
      "[I 2023-07-02 03:40:54,211] Trial 1050 pruned. \n",
      "[I 2023-07-02 03:40:55,379] Trial 1058 pruned. \n",
      "[I 2023-07-02 03:40:56,008] Trial 1052 finished with value: 0.5850808706036346 and parameters: {'n_estimators': 208, 'learning_rate': 0.021912810387808176, 'num_leaves': 11, 'max_depth': 173, 'min_child_samples': 136, 'min_child_weight': 161, 'subsample': 0.9152355840563652, 'colsample_bytree': 0.19712807107580274, 'reg_alpha': 0.2527814855092224, 'reg_lambda': 0.16402639728062435}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:40:57,465] Trial 1057 pruned. \n",
      "[I 2023-07-02 03:40:59,251] Trial 1061 pruned. \n",
      "[I 2023-07-02 03:40:59,972] Trial 1063 pruned. \n",
      "[I 2023-07-02 03:41:01,246] Trial 1065 pruned. \n",
      "[I 2023-07-02 03:41:01,572] Trial 1064 pruned. \n",
      "[I 2023-07-02 03:41:01,622] Trial 1066 pruned. \n",
      "[I 2023-07-02 03:41:02,448] Trial 1067 pruned. \n",
      "[I 2023-07-02 03:41:03,530] Trial 1060 pruned. \n",
      "[I 2023-07-02 03:41:03,913] Trial 1062 finished with value: 0.5845239454656826 and parameters: {'n_estimators': 132, 'learning_rate': 0.051828882178668934, 'num_leaves': 7, 'max_depth': 149, 'min_child_samples': 121, 'min_child_weight': 163, 'subsample': 0.8748793494496386, 'colsample_bytree': 0.268802441746585, 'reg_alpha': 0.6226825118335714, 'reg_lambda': 0.9166674178272967}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:05,891] Trial 1068 pruned. \n",
      "[I 2023-07-02 03:41:07,624] Trial 1075 pruned. \n",
      "[I 2023-07-02 03:41:08,590] Trial 1069 finished with value: 0.5839810312889278 and parameters: {'n_estimators': 175, 'learning_rate': 0.02837094925665329, 'num_leaves': 16, 'max_depth': 139, 'min_child_samples': 122, 'min_child_weight': 148, 'subsample': 0.9505067520556715, 'colsample_bytree': 0.25011339269088156, 'reg_alpha': 0.13797902197827222, 'reg_lambda': 0.8779227286366873}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:08,753] Trial 1071 pruned. \n",
      "[I 2023-07-02 03:41:09,716] Trial 1074 pruned. \n",
      "[I 2023-07-02 03:41:10,747] Trial 1077 pruned. \n",
      "[I 2023-07-02 03:41:11,525] Trial 1076 pruned. \n",
      "[I 2023-07-02 03:41:12,286] Trial 1072 finished with value: 0.5853056854338489 and parameters: {'n_estimators': 180, 'learning_rate': 0.028913491039677063, 'num_leaves': 16, 'max_depth': 137, 'min_child_samples': 183, 'min_child_weight': 191, 'subsample': 0.8500466603621889, 'colsample_bytree': 0.23301438847581185, 'reg_alpha': 0.19248117877214665, 'reg_lambda': 0.2803850127979326}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:12,794] Trial 1073 pruned. \n",
      "[I 2023-07-02 03:41:14,079] Trial 1080 pruned. \n",
      "[I 2023-07-02 03:41:14,628] Trial 1078 pruned. \n",
      "[I 2023-07-02 03:41:14,808] Trial 1081 pruned. \n",
      "[I 2023-07-02 03:41:16,202] Trial 1083 pruned. \n",
      "[I 2023-07-02 03:41:17,039] Trial 1084 pruned. \n",
      "[I 2023-07-02 03:41:18,070] Trial 1079 pruned. \n",
      "[I 2023-07-02 03:41:18,274] Trial 1082 pruned. \n",
      "[I 2023-07-02 03:41:19,650] Trial 1086 pruned. \n",
      "[I 2023-07-02 03:41:19,867] Trial 1085 pruned. \n",
      "[I 2023-07-02 03:41:22,516] Trial 1088 pruned. \n",
      "[I 2023-07-02 03:41:22,656] Trial 1093 pruned. \n",
      "[I 2023-07-02 03:41:22,796] Trial 1090 pruned. \n",
      "[I 2023-07-02 03:41:23,181] Trial 1092 pruned. \n",
      "[I 2023-07-02 03:41:23,907] Trial 1070 pruned. \n",
      "[I 2023-07-02 03:41:27,294] Trial 1094 pruned. \n",
      "[I 2023-07-02 03:41:27,520] Trial 1089 finished with value: 0.5836894266040982 and parameters: {'n_estimators': 268, 'learning_rate': 0.03170636928929394, 'num_leaves': 10, 'max_depth': 119, 'min_child_samples': 183, 'min_child_weight': 192, 'subsample': 0.8377538281407839, 'colsample_bytree': 0.28063531960950966, 'reg_alpha': 0.07859508729484306, 'reg_lambda': 0.340792539914852}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:28,742] Trial 1091 pruned. \n",
      "[I 2023-07-02 03:41:30,726] Trial 1096 finished with value: 0.5848949117571163 and parameters: {'n_estimators': 166, 'learning_rate': 0.03911279120608259, 'num_leaves': 6, 'max_depth': 131, 'min_child_samples': 178, 'min_child_weight': 188, 'subsample': 0.8241408265027536, 'colsample_bytree': 0.279391503943645, 'reg_alpha': 0.2732781227123533, 'reg_lambda': 0.8650926639727663}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:31,921] Trial 1100 pruned. \n",
      "[I 2023-07-02 03:41:32,507] Trial 1099 pruned. \n",
      "[I 2023-07-02 03:41:32,827] Trial 1087 pruned. \n",
      "[I 2023-07-02 03:41:33,348] Trial 1101 pruned. \n",
      "[I 2023-07-02 03:41:34,865] Trial 1098 pruned. \n",
      "[I 2023-07-02 03:41:35,133] Trial 1097 pruned. \n",
      "[I 2023-07-02 03:41:35,640] Trial 1095 pruned. \n",
      "[I 2023-07-02 03:41:35,882] Trial 1102 pruned. \n",
      "[I 2023-07-02 03:41:38,249] Trial 1103 pruned. \n",
      "[I 2023-07-02 03:41:38,784] Trial 1106 pruned. \n",
      "[I 2023-07-02 03:41:40,895] Trial 1105 pruned. \n",
      "[I 2023-07-02 03:41:41,406] Trial 1111 pruned. \n",
      "[I 2023-07-02 03:41:41,803] Trial 1109 pruned. \n",
      "[I 2023-07-02 03:41:42,060] Trial 1112 pruned. \n",
      "[I 2023-07-02 03:41:42,993] Trial 1107 finished with value: 0.586142077849306 and parameters: {'n_estimators': 101, 'learning_rate': 0.045493368911789414, 'num_leaves': 21, 'max_depth': 182, 'min_child_samples': 139, 'min_child_weight': 183, 'subsample': 0.8103104916924243, 'colsample_bytree': 0.2496951281484171, 'reg_alpha': 0.39329708520260365, 'reg_lambda': 0.2750136586236175}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:44,906] Trial 1110 pruned. \n",
      "[I 2023-07-02 03:41:45,070] Trial 1108 pruned. \n",
      "[I 2023-07-02 03:41:46,872] Trial 1117 pruned. \n",
      "[I 2023-07-02 03:41:47,577] Trial 1115 pruned. \n",
      "[I 2023-07-02 03:41:48,673] Trial 1116 pruned. \n",
      "[I 2023-07-02 03:41:49,404] Trial 1119 pruned. \n",
      "[I 2023-07-02 03:41:50,629] Trial 1120 pruned. \n",
      "[I 2023-07-02 03:41:51,287] Trial 1118 finished with value: 0.5855349892041065 and parameters: {'n_estimators': 112, 'learning_rate': 0.044519333366705015, 'num_leaves': 30, 'max_depth': 192, 'min_child_samples': 144, 'min_child_weight': 185, 'subsample': 0.8257511711404535, 'colsample_bytree': 0.24421720205720643, 'reg_alpha': 0.44664174791312283, 'reg_lambda': 0.276721145831732}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:52,049] Trial 1114 pruned. \n",
      "[I 2023-07-02 03:41:52,841] Trial 1104 pruned. \n",
      "[I 2023-07-02 03:41:54,105] Trial 1122 pruned. \n",
      "[I 2023-07-02 03:41:54,558] Trial 1125 pruned. \n",
      "[I 2023-07-02 03:41:56,326] Trial 1126 pruned. \n",
      "[I 2023-07-02 03:41:57,355] Trial 1123 pruned. \n",
      "[I 2023-07-02 03:41:58,083] Trial 1127 finished with value: 0.5865581581607484 and parameters: {'n_estimators': 101, 'learning_rate': 0.0447959244621752, 'num_leaves': 22, 'max_depth': 193, 'min_child_samples': 144, 'min_child_weight': 179, 'subsample': 0.8005220538394741, 'colsample_bytree': 0.25013633652065537, 'reg_alpha': 0.44993347309975373, 'reg_lambda': 0.24268230469685415}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:41:58,326] Trial 1128 pruned. \n",
      "[I 2023-07-02 03:41:59,396] Trial 1124 pruned. \n",
      "[I 2023-07-02 03:42:00,511] Trial 1129 finished with value: 0.5861282500809922 and parameters: {'n_estimators': 106, 'learning_rate': 0.044133290139127576, 'num_leaves': 34, 'max_depth': 188, 'min_child_samples': 142, 'min_child_weight': 178, 'subsample': 0.8005205200706713, 'colsample_bytree': 0.25105131573988804, 'reg_alpha': 0.35928596359381904, 'reg_lambda': 0.2982321364989406}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:42:01,315] Trial 1131 pruned. \n",
      "[I 2023-07-02 03:42:01,613] Trial 1121 pruned. \n",
      "[I 2023-07-02 03:42:03,024] Trial 1134 pruned. \n",
      "[I 2023-07-02 03:42:03,601] Trial 1132 pruned. \n",
      "[I 2023-07-02 03:42:05,495] Trial 1133 pruned. \n",
      "[I 2023-07-02 03:42:06,214] Trial 1135 pruned. \n",
      "[I 2023-07-02 03:42:07,411] Trial 1136 pruned. \n",
      "[I 2023-07-02 03:42:07,752] Trial 1137 finished with value: 0.586067462697535 and parameters: {'n_estimators': 108, 'learning_rate': 0.04500195499455108, 'num_leaves': 32, 'max_depth': 202, 'min_child_samples': 141, 'min_child_weight': 188, 'subsample': 0.6851228550208042, 'colsample_bytree': 0.26589680777380553, 'reg_alpha': 0.4687748257695746, 'reg_lambda': 0.267267591324707}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:42:08,116] Trial 1113 pruned. \n",
      "[I 2023-07-02 03:42:09,620] Trial 1139 pruned. \n",
      "[I 2023-07-02 03:42:10,057] Trial 1138 pruned. \n",
      "[I 2023-07-02 03:42:12,582] Trial 1141 finished with value: 0.5861763806132032 and parameters: {'n_estimators': 106, 'learning_rate': 0.04485253236526553, 'num_leaves': 39, 'max_depth': 192, 'min_child_samples': 142, 'min_child_weight': 186, 'subsample': 0.5985552553547746, 'colsample_bytree': 0.2624057833445023, 'reg_alpha': 0.11768812505435439, 'reg_lambda': 0.4150838606187084}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:42:12,758] Trial 1140 finished with value: 0.5833224098414254 and parameters: {'n_estimators': 133, 'learning_rate': 0.04885582030451151, 'num_leaves': 31, 'max_depth': 196, 'min_child_samples': 142, 'min_child_weight': 183, 'subsample': 0.5967856561389503, 'colsample_bytree': 0.2827310783302612, 'reg_alpha': 0.36401448400183645, 'reg_lambda': 0.4131733595682111}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:42:13,262] Trial 1145 pruned. \n",
      "[I 2023-07-02 03:42:14,569] Trial 1142 finished with value: 0.585616005236235 and parameters: {'n_estimators': 102, 'learning_rate': 0.04856167904791291, 'num_leaves': 37, 'max_depth': 194, 'min_child_samples': 147, 'min_child_weight': 188, 'subsample': 0.7203415092330647, 'colsample_bytree': 0.2687973703225984, 'reg_alpha': 0.09636077630533313, 'reg_lambda': 0.41235635741596466}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:42:15,848] Trial 1144 pruned. \n",
      "[I 2023-07-02 03:42:16,439] Trial 1143 finished with value: 0.5850290031800507 and parameters: {'n_estimators': 138, 'learning_rate': 0.044474008581331, 'num_leaves': 41, 'max_depth': 196, 'min_child_samples': 149, 'min_child_weight': 190, 'subsample': 0.9894427900475611, 'colsample_bytree': 0.26554118563829054, 'reg_alpha': 0.3644552444916118, 'reg_lambda': 0.2798209630985383}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:42:17,921] Trial 1147 pruned. \n",
      "[I 2023-07-02 03:42:18,094] Trial 1146 finished with value: 0.5827331269145289 and parameters: {'n_estimators': 142, 'learning_rate': 0.04321171129718375, 'num_leaves': 39, 'max_depth': 187, 'min_child_samples': 147, 'min_child_weight': 194, 'subsample': 0.8170198337348711, 'colsample_bytree': 0.5907330635735144, 'reg_alpha': 0.5161570881353663, 'reg_lambda': 0.3016629623665567}. Best is trial 937 with value: 0.5865752954768694.\n",
      "[I 2023-07-02 03:42:19,868] Trial 1148 finished with value: 0.5866526840445634 and parameters: {'n_estimators': 100, 'learning_rate': 0.044606202448458206, 'num_leaves': 41, 'max_depth': 207, 'min_child_samples': 149, 'min_child_weight': 190, 'subsample': 0.5158023863040262, 'colsample_bytree': 0.2641464920307482, 'reg_alpha': 0.12078683707184015, 'reg_lambda': 0.3067449049533006}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:20,391] Trial 1149 pruned. \n",
      "[I 2023-07-02 03:42:20,926] Trial 1150 pruned. \n",
      "[I 2023-07-02 03:42:21,551] Trial 1130 pruned. \n",
      "[I 2023-07-02 03:42:22,976] Trial 1151 pruned. \n",
      "[I 2023-07-02 03:42:24,173] Trial 1152 pruned. \n",
      "[I 2023-07-02 03:42:25,437] Trial 1154 pruned. \n",
      "[I 2023-07-02 03:42:26,481] Trial 1153 pruned. \n",
      "[I 2023-07-02 03:42:27,125] Trial 1155 pruned. \n",
      "[I 2023-07-02 03:42:28,346] Trial 1156 pruned. \n",
      "[I 2023-07-02 03:42:29,308] Trial 1157 pruned. \n",
      "[I 2023-07-02 03:42:29,575] Trial 1158 pruned. \n",
      "[I 2023-07-02 03:42:30,616] Trial 1159 pruned. \n",
      "[I 2023-07-02 03:42:31,263] Trial 1160 pruned. \n",
      "[I 2023-07-02 03:42:33,208] Trial 1161 finished with value: 0.5837598324103153 and parameters: {'n_estimators': 139, 'learning_rate': 0.04156579376411623, 'num_leaves': 37, 'max_depth': 209, 'min_child_samples': 147, 'min_child_weight': 186, 'subsample': 0.5721633125378689, 'colsample_bytree': 0.29541410610091673, 'reg_alpha': 0.10128755582012969, 'reg_lambda': 0.3343772891181171}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:33,814] Trial 1162 pruned. \n",
      "[I 2023-07-02 03:42:34,095] Trial 1163 finished with value: 0.5863615225570677 and parameters: {'n_estimators': 100, 'learning_rate': 0.04788693295247705, 'num_leaves': 35, 'max_depth': 207, 'min_child_samples': 147, 'min_child_weight': 186, 'subsample': 0.5232604796769454, 'colsample_bytree': 0.2805821431837869, 'reg_alpha': 0.10618248695498173, 'reg_lambda': 0.3512297756383041}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:36,173] Trial 1164 finished with value: 0.5859702645230777 and parameters: {'n_estimators': 100, 'learning_rate': 0.049864446216416995, 'num_leaves': 37, 'max_depth': 211, 'min_child_samples': 146, 'min_child_weight': 187, 'subsample': 0.5915874261597416, 'colsample_bytree': 0.28049350066019174, 'reg_alpha': 0.10338371003861566, 'reg_lambda': 0.35661005230260107}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:37,947] Trial 1165 finished with value: 0.5843329817678636 and parameters: {'n_estimators': 140, 'learning_rate': 0.04820210631070887, 'num_leaves': 36, 'max_depth': 207, 'min_child_samples': 145, 'min_child_weight': 184, 'subsample': 0.5195054949587252, 'colsample_bytree': 0.2752987798190062, 'reg_alpha': 0.13983529750067916, 'reg_lambda': 0.35305624932763485}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:38,113] Trial 1166 finished with value: 0.5851324147755376 and parameters: {'n_estimators': 141, 'learning_rate': 0.04126456226861587, 'num_leaves': 36, 'max_depth': 213, 'min_child_samples': 138, 'min_child_weight': 186, 'subsample': 0.5162075761573877, 'colsample_bytree': 0.27913312343413493, 'reg_alpha': 0.13826091535321455, 'reg_lambda': 0.3570066107591721}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:38,390] Trial 1168 finished with value: 0.5855645054923082 and parameters: {'n_estimators': 128, 'learning_rate': 0.04237786236533363, 'num_leaves': 37, 'max_depth': 208, 'min_child_samples': 145, 'min_child_weight': 185, 'subsample': 0.548928407637536, 'colsample_bytree': 0.26650736425184324, 'reg_alpha': 0.056442222631917865, 'reg_lambda': 0.3582167222275802}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:39,066] Trial 1167 finished with value: 0.5852152378758342 and parameters: {'n_estimators': 141, 'learning_rate': 0.043928373319685, 'num_leaves': 35, 'max_depth': 201, 'min_child_samples': 145, 'min_child_weight': 185, 'subsample': 0.533789513574738, 'colsample_bytree': 0.27426253514235255, 'reg_alpha': 0.1363594250389278, 'reg_lambda': 0.354980868019144}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:41,479] Trial 1172 pruned. \n",
      "[I 2023-07-02 03:42:41,629] Trial 1169 finished with value: 0.583865453787076 and parameters: {'n_estimators': 145, 'learning_rate': 0.05040274196486133, 'num_leaves': 34, 'max_depth': 211, 'min_child_samples': 144, 'min_child_weight': 185, 'subsample': 0.5500691831183055, 'colsample_bytree': 0.26703866662742637, 'reg_alpha': 0.12823896185577235, 'reg_lambda': 0.36111723190205736}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:41,953] Trial 1171 finished with value: 0.5848944983384691 and parameters: {'n_estimators': 138, 'learning_rate': 0.05062284896437144, 'num_leaves': 34, 'max_depth': 210, 'min_child_samples': 137, 'min_child_weight': 196, 'subsample': 0.5319788103523694, 'colsample_bytree': 0.2702685808554131, 'reg_alpha': 0.13382597765128176, 'reg_lambda': 0.37123049372981615}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:42,092] Trial 1170 finished with value: 0.5848519110173467 and parameters: {'n_estimators': 145, 'learning_rate': 0.04332157272319108, 'num_leaves': 33, 'max_depth': 212, 'min_child_samples': 138, 'min_child_weight': 184, 'subsample': 0.5116379529312524, 'colsample_bytree': 0.26300349927336397, 'reg_alpha': 0.13715671124357423, 'reg_lambda': 0.3592594232072972}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:42,982] Trial 1173 pruned. \n",
      "[I 2023-07-02 03:42:46,041] Trial 1174 pruned. \n",
      "[I 2023-07-02 03:42:46,481] Trial 1175 pruned. \n",
      "[I 2023-07-02 03:42:46,538] Trial 1176 pruned. \n",
      "[I 2023-07-02 03:42:49,182] Trial 1181 pruned. \n",
      "[I 2023-07-02 03:42:49,623] Trial 1177 pruned. \n",
      "[I 2023-07-02 03:42:50,007] Trial 1178 pruned. \n",
      "[I 2023-07-02 03:42:50,294] Trial 1180 pruned. \n",
      "[I 2023-07-02 03:42:51,345] Trial 1179 finished with value: 0.5833567841130499 and parameters: {'n_estimators': 132, 'learning_rate': 0.044510852640753024, 'num_leaves': 41, 'max_depth': 216, 'min_child_samples': 139, 'min_child_weight': 192, 'subsample': 0.5023379561822657, 'colsample_bytree': 0.2937776943654169, 'reg_alpha': 0.05054100069600226, 'reg_lambda': 0.38174728705838484}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:42:52,190] Trial 1184 pruned. \n",
      "[I 2023-07-02 03:42:53,967] Trial 1182 pruned. \n",
      "[I 2023-07-02 03:42:54,721] Trial 1183 pruned. \n",
      "[I 2023-07-02 03:42:57,291] Trial 1188 pruned. \n",
      "[I 2023-07-02 03:42:57,896] Trial 1189 pruned. \n",
      "[I 2023-07-02 03:42:58,660] Trial 1185 pruned. \n",
      "[I 2023-07-02 03:42:59,329] Trial 1191 pruned. \n",
      "[I 2023-07-02 03:43:00,023] Trial 1192 pruned. \n",
      "[I 2023-07-02 03:43:00,088] Trial 1186 pruned. \n",
      "[I 2023-07-02 03:43:00,526] Trial 1187 finished with value: 0.5856327799382033 and parameters: {'n_estimators': 141, 'learning_rate': 0.04066523379462568, 'num_leaves': 31, 'max_depth': 197, 'min_child_samples': 134, 'min_child_weight': 188, 'subsample': 0.5207077201692697, 'colsample_bytree': 0.2573890573750323, 'reg_alpha': 0.09660263949291806, 'reg_lambda': 0.40814757529346446}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:43:01,776] Trial 1190 finished with value: 0.5836355967740544 and parameters: {'n_estimators': 146, 'learning_rate': 0.04052961738643331, 'num_leaves': 38, 'max_depth': 197, 'min_child_samples': 147, 'min_child_weight': 187, 'subsample': 0.583628571768293, 'colsample_bytree': 0.28614707807779993, 'reg_alpha': 0.09875147769843887, 'reg_lambda': 0.4186428737882778}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:43:04,565] Trial 1193 finished with value: 0.5847996688140906 and parameters: {'n_estimators': 149, 'learning_rate': 0.04741525448761088, 'num_leaves': 32, 'max_depth': 199, 'min_child_samples': 148, 'min_child_weight': 199, 'subsample': 0.5498028567183926, 'colsample_bytree': 0.25581174949814306, 'reg_alpha': 0.09339191690262127, 'reg_lambda': 0.7444372280060616}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:43:04,825] Trial 1194 pruned. \n",
      "[I 2023-07-02 03:43:05,405] Trial 1195 finished with value: 0.5846981735721777 and parameters: {'n_estimators': 149, 'learning_rate': 0.04753952943673073, 'num_leaves': 33, 'max_depth': 192, 'min_child_samples': 146, 'min_child_weight': 185, 'subsample': 0.5884761090434424, 'colsample_bytree': 0.25433996236655854, 'reg_alpha': 0.0962469573476256, 'reg_lambda': 0.8010242249039068}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:43:05,679] Trial 1196 pruned. \n",
      "[I 2023-07-02 03:43:05,843] Trial 1199 finished with value: 0.5851015617596267 and parameters: {'n_estimators': 145, 'learning_rate': 0.04780956379997277, 'num_leaves': 37, 'max_depth': 207, 'min_child_samples': 134, 'min_child_weight': 199, 'subsample': 0.5272307584529349, 'colsample_bytree': 0.2538142670078069, 'reg_alpha': 0.07727821181337965, 'reg_lambda': 0.42732953392813733}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:43:05,899] Trial 1198 finished with value: 0.5846508457970746 and parameters: {'n_estimators': 154, 'learning_rate': 0.04794395434089444, 'num_leaves': 35, 'max_depth': 188, 'min_child_samples': 146, 'min_child_weight': 198, 'subsample': 0.5883764166689416, 'colsample_bytree': 0.25553936877840383, 'reg_alpha': 0.123541891279708, 'reg_lambda': 0.7110536468821405}. Best is trial 1148 with value: 0.5866526840445634.\n",
      "[I 2023-07-02 03:43:05,949] Trial 1197 pruned. \n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=200,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Hyper parameter tuning using optuna for lgbm\n",
    "\n",
    "# import optuna\n",
    "# from optuna.samplers import TPESampler\n",
    "# from optuna.pruners import SuccessiveHalvingPruner\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from optuna import Trial\n",
    "\n",
    "# def objective(trial: Trial):\n",
    "#     #params for lgbm\n",
    "#     params = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5,log=True),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 10, 256),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 10, 100),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 2, 256),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 2, 256),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.1, 1.0,log=True),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0,log=True),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 0.99,log=True),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 0.99,log=True),\n",
    "#         'random_state': 42,\n",
    "#         'n_jobs': -1,\n",
    "#         'objective': 'binary',\n",
    "#         'metric': 'auc',\n",
    "#     }\n",
    "#     model_obj=MultiOutputClassifier(LGBMClassifier(**params))\n",
    "#     skf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "#     scores=[]\n",
    "#     i=0\n",
    "#     for train_index, test_index in skf.split(X, y):\n",
    "#         X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "#         y_train, y_test = y.iloc[train_index,:], y.iloc[test_index,:]\n",
    "#         # preprocess\n",
    "#         X_train,y_train=preprocess(X_train,y_train)\n",
    "#         # get pipeline\n",
    "#         model=get_pipeline(model_obj)\n",
    "#         # fit model\n",
    "#         model.fit(X_train,y_train)\n",
    "#         # predict\n",
    "#         y_pred=model.predict_proba(X_test)\n",
    "#         val_preds = np.array(y_pred)[:,:,1].T\n",
    "#         score=roc_auc_score(y_test,val_preds)\n",
    "#         scores.append(score)\n",
    "#         trial.report(score, i)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "#         i+=1\n",
    "#     return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-28 00:40:15,124] A new study created in memory with name: no-name-e48fa94d-890f-4e49-bea5-fdbde71053dd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d278a949fc01490d9162e4194242ff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-28 00:40:34,094] Trial 3 pruned. \n",
      "[I 2023-06-28 00:40:35,493] Trial 5 pruned. \n",
      "[I 2023-06-28 00:40:39,133] Trial 4 pruned. \n",
      "[I 2023-06-28 00:40:50,586] Trial 2 pruned. \n",
      "[I 2023-06-28 00:41:02,869] Trial 0 finished with value: 0.6410358661189715 and parameters: {'n_estimators': 405, 'learning_rate': 0.009643984562230094, 'num_leaves': 158, 'max_depth': 55, 'min_child_samples': 7, 'min_child_weight': 124, 'subsample': 0.17567177463120887, 'colsample_bytree': 0.8079955728992779, 'reg_alpha': 0.0029323371798063184, 'reg_lambda': 0.3095981889431533}. Best is trial 0 with value: 0.6410358661189715.\n",
      "[I 2023-06-28 00:41:05,977] Trial 9 pruned. \n",
      "[I 2023-06-28 00:41:12,111] Trial 6 pruned. \n",
      "[I 2023-06-28 00:41:16,092] Trial 1 pruned. \n",
      "[I 2023-06-28 00:41:17,576] Trial 8 pruned. \n",
      "[I 2023-06-28 00:41:23,208] Trial 13 pruned. \n",
      "[I 2023-06-28 00:41:31,970] Trial 7 pruned. \n",
      "[I 2023-06-28 00:41:40,765] Trial 11 pruned. \n",
      "[I 2023-06-28 00:41:43,937] Trial 14 pruned. \n",
      "[I 2023-06-28 00:41:46,358] Trial 10 pruned. \n",
      "[I 2023-06-28 00:42:09,847] Trial 12 finished with value: 0.6422514868691923 and parameters: {'n_estimators': 686, 'learning_rate': 0.006513293024805877, 'num_leaves': 167, 'max_depth': 91, 'min_child_samples': 15, 'min_child_weight': 218, 'subsample': 0.1822471885279545, 'colsample_bytree': 0.294663040383314, 'reg_alpha': 0.29072039881968964, 'reg_lambda': 0.42332449949022166}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:42:11,533] Trial 15 pruned. \n",
      "[I 2023-06-28 00:42:49,368] Trial 21 pruned. \n",
      "[I 2023-06-28 00:43:00,348] Trial 24 pruned. \n",
      "[I 2023-06-28 00:43:16,248] Trial 23 pruned. \n",
      "[I 2023-06-28 00:43:31,256] Trial 17 finished with value: 0.6415678295162618 and parameters: {'n_estimators': 975, 'learning_rate': 0.0037290473743267602, 'num_leaves': 83, 'max_depth': 68, 'min_child_samples': 69, 'min_child_weight': 139, 'subsample': 0.10110953690766794, 'colsample_bytree': 0.44584278358926743, 'reg_alpha': 0.005810162783341554, 'reg_lambda': 0.5724113187677883}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:43:32,808] Trial 16 finished with value: 0.6402683741673401 and parameters: {'n_estimators': 263, 'learning_rate': 0.013866416094188679, 'num_leaves': 96, 'max_depth': 65, 'min_child_samples': 24, 'min_child_weight': 24, 'subsample': 0.28665708840108073, 'colsample_bytree': 0.1674777167002791, 'reg_alpha': 0.006987096672639828, 'reg_lambda': 0.0012285290084091743}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:43:34,702] Trial 20 finished with value: 0.6414631372473432 and parameters: {'n_estimators': 917, 'learning_rate': 0.00503295503169669, 'num_leaves': 93, 'max_depth': 71, 'min_child_samples': 251, 'min_child_weight': 147, 'subsample': 0.10153784697135837, 'colsample_bytree': 0.3881905231493581, 'reg_alpha': 0.0025489370338230627, 'reg_lambda': 0.9697353062367585}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:43:37,374] Trial 18 finished with value: 0.6413872859393182 and parameters: {'n_estimators': 976, 'learning_rate': 0.003347715458175833, 'num_leaves': 106, 'max_depth': 70, 'min_child_samples': 3, 'min_child_weight': 145, 'subsample': 0.10301447247815758, 'colsample_bytree': 0.4453876821985236, 'reg_alpha': 0.004522109955561845, 'reg_lambda': 0.9427048199218862}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:43:39,130] Trial 25 pruned. \n",
      "[I 2023-06-28 00:43:47,612] Trial 19 finished with value: 0.6416711860273642 and parameters: {'n_estimators': 986, 'learning_rate': 0.0036283066729281064, 'num_leaves': 91, 'max_depth': 70, 'min_child_samples': 96, 'min_child_weight': 143, 'subsample': 0.11098865180362628, 'colsample_bytree': 0.41512891018487935, 'reg_alpha': 0.0032654109881151716, 'reg_lambda': 0.7755535520624774}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:44:05,563] Trial 22 pruned. \n",
      "[I 2023-06-28 00:44:06,125] Trial 26 pruned. \n",
      "[I 2023-06-28 00:44:12,389] Trial 27 pruned. \n",
      "[I 2023-06-28 00:44:19,008] Trial 32 pruned. \n",
      "[I 2023-06-28 00:44:34,231] Trial 33 pruned. \n",
      "[I 2023-06-28 00:44:39,451] Trial 34 pruned. \n",
      "[I 2023-06-28 00:44:44,559] Trial 28 pruned. \n",
      "[I 2023-06-28 00:44:50,234] Trial 31 pruned. \n",
      "[I 2023-06-28 00:45:08,070] Trial 30 pruned. \n",
      "[I 2023-06-28 00:45:13,046] Trial 35 pruned. \n",
      "[I 2023-06-28 00:45:15,481] Trial 29 pruned. \n",
      "[I 2023-06-28 00:45:16,141] Trial 36 pruned. \n",
      "[I 2023-06-28 00:45:26,957] Trial 37 pruned. \n",
      "[I 2023-06-28 00:45:50,728] Trial 40 pruned. \n",
      "[I 2023-06-28 00:46:05,970] Trial 41 pruned. \n",
      "[I 2023-06-28 00:46:08,605] Trial 43 pruned. \n",
      "[I 2023-06-28 00:46:12,684] Trial 42 pruned. \n",
      "[I 2023-06-28 00:46:16,036] Trial 44 pruned. \n",
      "[I 2023-06-28 00:46:19,857] Trial 38 finished with value: 0.641562782306751 and parameters: {'n_estimators': 895, 'learning_rate': 0.005306439869121035, 'num_leaves': 86, 'max_depth': 59, 'min_child_samples': 84, 'min_child_weight': 173, 'subsample': 0.12294882082013962, 'colsample_bytree': 0.35501705028285585, 'reg_alpha': 0.002979113533053082, 'reg_lambda': 0.46508238819338305}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:46:22,761] Trial 39 finished with value: 0.6417377130505226 and parameters: {'n_estimators': 909, 'learning_rate': 0.004922433080680044, 'num_leaves': 86, 'max_depth': 59, 'min_child_samples': 188, 'min_child_weight': 181, 'subsample': 0.16558751984335576, 'colsample_bytree': 0.36348265475303, 'reg_alpha': 0.002510464288279289, 'reg_lambda': 0.43120739051874096}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:46:25,385] Trial 45 pruned. \n",
      "[I 2023-06-28 00:46:46,521] Trial 46 pruned. \n",
      "[I 2023-06-28 00:46:53,978] Trial 53 pruned. \n",
      "[I 2023-06-28 00:47:12,962] Trial 47 pruned. \n",
      "[I 2023-06-28 00:47:35,465] Trial 54 pruned. \n",
      "[I 2023-06-28 00:47:36,225] Trial 48 pruned. \n",
      "[I 2023-06-28 00:47:40,156] Trial 49 pruned. \n",
      "[I 2023-06-28 00:47:45,964] Trial 50 pruned. \n",
      "[I 2023-06-28 00:47:51,924] Trial 55 pruned. \n",
      "[I 2023-06-28 00:48:02,396] Trial 51 finished with value: 0.6417474214164387 and parameters: {'n_estimators': 956, 'learning_rate': 0.004793510829021551, 'num_leaves': 126, 'max_depth': 42, 'min_child_samples': 37, 'min_child_weight': 201, 'subsample': 0.11029859723969299, 'colsample_bytree': 0.42661198098873615, 'reg_alpha': 0.004239653639499772, 'reg_lambda': 0.6663666161667026}. Best is trial 12 with value: 0.6422514868691923.\n",
      "[I 2023-06-28 00:48:06,007] Trial 52 finished with value: 0.6424653092466924 and parameters: {'n_estimators': 998, 'learning_rate': 0.004565896907186115, 'num_leaves': 119, 'max_depth': 42, 'min_child_samples': 139, 'min_child_weight': 200, 'subsample': 0.11498053779651443, 'colsample_bytree': 0.24049548351554417, 'reg_alpha': 0.0013920533392223111, 'reg_lambda': 0.6212494114464403}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:48:20,837] Trial 56 pruned. \n",
      "[I 2023-06-28 00:48:33,332] Trial 57 pruned. \n",
      "[I 2023-06-28 00:48:37,168] Trial 60 pruned. \n",
      "[I 2023-06-28 00:48:49,326] Trial 61 pruned. \n",
      "[I 2023-06-28 00:49:00,667] Trial 58 pruned. \n",
      "[I 2023-06-28 00:49:05,484] Trial 62 pruned. \n",
      "[I 2023-06-28 00:49:09,688] Trial 63 pruned. \n",
      "[I 2023-06-28 00:49:17,128] Trial 59 pruned. \n",
      "[I 2023-06-28 00:49:21,664] Trial 64 pruned. \n",
      "[I 2023-06-28 00:49:58,615] Trial 65 pruned. \n",
      "[I 2023-06-28 00:50:12,519] Trial 66 pruned. \n",
      "[I 2023-06-28 00:50:18,210] Trial 67 pruned. \n",
      "[I 2023-06-28 00:50:41,440] Trial 69 finished with value: 0.6417218967999968 and parameters: {'n_estimators': 955, 'learning_rate': 0.0038586809553902176, 'num_leaves': 106, 'max_depth': 26, 'min_child_samples': 17, 'min_child_weight': 206, 'subsample': 0.11987294634804141, 'colsample_bytree': 0.4001895800498107, 'reg_alpha': 0.0114883832833475, 'reg_lambda': 0.1857229417762014}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:50:42,487] Trial 68 finished with value: 0.6419949812926189 and parameters: {'n_estimators': 951, 'learning_rate': 0.004056201486747144, 'num_leaves': 105, 'max_depth': 26, 'min_child_samples': 76, 'min_child_weight': 190, 'subsample': 0.11982191329448671, 'colsample_bytree': 0.39098024451192875, 'reg_alpha': 0.0005340865345827651, 'reg_lambda': 0.3237014293564245}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:50:42,934] Trial 75 pruned. \n",
      "[I 2023-06-28 00:50:46,983] Trial 70 finished with value: 0.6418050439327517 and parameters: {'n_estimators': 958, 'learning_rate': 0.004046175724540012, 'num_leaves': 106, 'max_depth': 25, 'min_child_samples': 16, 'min_child_weight': 203, 'subsample': 0.11943690503024008, 'colsample_bytree': 0.4000020565484781, 'reg_alpha': 0.0007769425963748479, 'reg_lambda': 0.16766684297452492}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:50:48,623] Trial 71 pruned. \n",
      "[I 2023-06-28 00:50:53,112] Trial 72 finished with value: 0.6419027271416923 and parameters: {'n_estimators': 855, 'learning_rate': 0.004011387694610818, 'num_leaves': 104, 'max_depth': 62, 'min_child_samples': 12, 'min_child_weight': 189, 'subsample': 0.11969455158124225, 'colsample_bytree': 0.38958875178147534, 'reg_alpha': 0.011356816803573243, 'reg_lambda': 0.2982567158876368}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:51:00,553] Trial 76 pruned. \n",
      "[I 2023-06-28 00:51:07,046] Trial 73 pruned. \n",
      "[I 2023-06-28 00:51:35,964] Trial 77 pruned. \n",
      "[I 2023-06-28 00:51:55,043] Trial 74 finished with value: 0.6419428538278314 and parameters: {'n_estimators': 932, 'learning_rate': 0.004268495713410235, 'num_leaves': 98, 'max_depth': 62, 'min_child_samples': 14, 'min_child_weight': 190, 'subsample': 0.12099344141216768, 'colsample_bytree': 0.40229588507840675, 'reg_alpha': 0.005841923129087019, 'reg_lambda': 0.3155110887818602}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:52:06,652] Trial 82 pruned. \n",
      "[I 2023-06-28 00:52:35,417] Trial 78 finished with value: 0.6421050431429063 and parameters: {'n_estimators': 970, 'learning_rate': 0.004120896617218438, 'num_leaves': 76, 'max_depth': 23, 'min_child_samples': 47, 'min_child_weight': 189, 'subsample': 0.10915752099617418, 'colsample_bytree': 0.4000083824132679, 'reg_alpha': 0.027871249065902964, 'reg_lambda': 0.26628930518858845}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:52:36,130] Trial 80 finished with value: 0.6419473180950539 and parameters: {'n_estimators': 927, 'learning_rate': 0.004413363409661048, 'num_leaves': 126, 'max_depth': 26, 'min_child_samples': 45, 'min_child_weight': 189, 'subsample': 0.10764653333564184, 'colsample_bytree': 0.3895662284688228, 'reg_alpha': 0.0002307559837249593, 'reg_lambda': 0.08908436581904446}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:52:37,540] Trial 79 finished with value: 0.6418668508553932 and parameters: {'n_estimators': 925, 'learning_rate': 0.0039061003314025985, 'num_leaves': 129, 'max_depth': 25, 'min_child_samples': 12, 'min_child_weight': 190, 'subsample': 0.10820806659487008, 'colsample_bytree': 0.4108771526849113, 'reg_alpha': 0.03156127168096364, 'reg_lambda': 0.28541799134246676}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:52:41,019] Trial 86 pruned. \n",
      "[I 2023-06-28 00:52:41,700] Trial 84 pruned. \n",
      "[I 2023-06-28 00:52:42,761] Trial 81 finished with value: 0.6418770415977872 and parameters: {'n_estimators': 932, 'learning_rate': 0.004269164071726727, 'num_leaves': 75, 'max_depth': 24, 'min_child_samples': 21, 'min_child_weight': 187, 'subsample': 0.10650052245958325, 'colsample_bytree': 0.3960821328229671, 'reg_alpha': 0.011387899919419625, 'reg_lambda': 0.10335742111434686}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:52:54,594] Trial 83 finished with value: 0.641704495915533 and parameters: {'n_estimators': 924, 'learning_rate': 0.003468982593619079, 'num_leaves': 127, 'max_depth': 23, 'min_child_samples': 25, 'min_child_weight': 188, 'subsample': 0.10829114507604955, 'colsample_bytree': 0.4015699622462889, 'reg_alpha': 0.00023284811590151085, 'reg_lambda': 0.089198401608958}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:53:18,200] Trial 87 pruned. \n",
      "[I 2023-06-28 00:53:20,235] Trial 85 pruned. \n",
      "[I 2023-06-28 00:53:20,466] Trial 90 pruned. \n",
      "[I 2023-06-28 00:53:50,720] Trial 93 pruned. \n",
      "[I 2023-06-28 00:53:58,196] Trial 94 pruned. \n",
      "[I 2023-06-28 00:54:04,596] Trial 88 finished with value: 0.6415759733784288 and parameters: {'n_estimators': 883, 'learning_rate': 0.0033405920652169684, 'num_leaves': 180, 'max_depth': 13, 'min_child_samples': 26, 'min_child_weight': 192, 'subsample': 0.10738327564035308, 'colsample_bytree': 0.31606696608486134, 'reg_alpha': 0.030789680213734464, 'reg_lambda': 0.2445245243183084}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:54:06,799] Trial 89 finished with value: 0.6414876325000047 and parameters: {'n_estimators': 884, 'learning_rate': 0.0030309136896756765, 'num_leaves': 179, 'max_depth': 13, 'min_child_samples': 10, 'min_child_weight': 191, 'subsample': 0.10819979756091858, 'colsample_bytree': 0.3102364719218524, 'reg_alpha': 0.025443065292328548, 'reg_lambda': 0.13782198759402303}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:54:14,335] Trial 92 pruned. \n",
      "[I 2023-06-28 00:54:14,863] Trial 95 pruned. \n",
      "[I 2023-06-28 00:54:19,121] Trial 91 finished with value: 0.6413521082895596 and parameters: {'n_estimators': 879, 'learning_rate': 0.003382543804874183, 'num_leaves': 253, 'max_depth': 13, 'min_child_samples': 9, 'min_child_weight': 166, 'subsample': 0.1343062184167856, 'colsample_bytree': 0.35737618666533916, 'reg_alpha': 0.00033626999958771776, 'reg_lambda': 0.10409404387394398}. Best is trial 52 with value: 0.6424653092466924.\n",
      "[I 2023-06-28 00:54:31,432] Trial 97 pruned. \n",
      "[I 2023-06-28 00:54:34,004] Trial 98 pruned. \n",
      "[I 2023-06-28 00:54:34,386] Trial 96 pruned. \n",
      "[I 2023-06-28 00:54:37,974] Trial 99 pruned. \n"
     ]
    }
   ],
   "source": [
    "# sampler = optuna.samplers.TPESampler(seed=42)\n",
    "# pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=2, min_early_stopping_rate=0)\n",
    "# study = optuna.create_study(pruner=pruner,sampler=sampler,direction='maximize')\n",
    "# study.optimize(objective, n_trials=100,n_jobs=-1,show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 998,\n",
       " 'learning_rate': 0.004565896907186115,\n",
       " 'num_leaves': 119,\n",
       " 'max_depth': 42,\n",
       " 'min_child_samples': 139,\n",
       " 'min_child_weight': 200,\n",
       " 'subsample': 0.11498053779651443,\n",
       " 'colsample_bytree': 0.24049548351554417,\n",
       " 'reg_alpha': 0.0013920533392223111,\n",
       " 'reg_lambda': 0.6212494114464403}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the hyperparameter space for lgbm\n",
    "# from optuna.samplers import TPESampler\n",
    "# import optuna\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from optuna import Trial, visualization\n",
    "# from optuna.pruners import SuccessiveHalvingPruner\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# def objective(trial: Trial):\n",
    "#     params={\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "#         'max_leaves': trial.suggest_int('max_leaves', 10, 200),\n",
    "#         'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 1e3),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#         'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 1e3),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 1e3),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 10, 200),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 0, 20),\n",
    "#         'random_state': 42,\n",
    "#         'n_jobs': -1,\n",
    "#     }\n",
    "#     skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "#     scores=[]\n",
    "#     i=0\n",
    "#     for train_index, test_index in skf.split(X, y):\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#         model=LGBMClassifier(**params)\n",
    "#         model.fit(X_train,y_train)\n",
    "#         y_pred=model.predict_proba(X_test)[:,1]\n",
    "#         trial.report(roc_auc_score(y_test,y_pred), i)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "#         scores.append(roc_auc_score(y_test,y_pred))\n",
    "#         i+=1\n",
    "#     return np.mean(scores)\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler(seed=42)\n",
    "# pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=2, min_early_stopping_rate=0)\n",
    "# study = optuna.create_study(pruner=pruner,sampler=sampler,direction='maximize')\n",
    "# study.optimize(objective, n_trials=100,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study.optimize(objective, n_trials=100,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # Define the hyperparameter space\n",
    "    # params = {\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "    #     'max_leaves': trial.suggest_int('max_leaves', 10, 200),\n",
    "    #     'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 1e3),\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e0),\n",
    "    #     'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    #     'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "    #     'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    #     'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 1e3),\n",
    "    #     'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 1e3),\n",
    "    # }\n",
    "    \n",
    "    # model = XGBClassifier(**params,loss_function=auc_loss_func)\n",
    "    \n",
    "    # skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    # scores=[]\n",
    "    # i=0\n",
    "    # for train_index, test_index in skf.split(X, y):\n",
    "    #     X_train, X_test = X[train_index], X[test_index]\n",
    "    #     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #     model.fit(X_train,y_train)\n",
    "    #     y_pred=model.predict_proba(X_test)[:,1]\n",
    "    #     trial.report(roc_auc_score(y_test,y_pred), step=i)\n",
    "    #     scores.append(roc_auc_score(y_test,y_pred))\n",
    "    #     if trial.should_prune():\n",
    "    #         raise optuna.TrialPruned()\n",
    "    #     i+=1\n",
    "    # return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from optuna.pruners import SuccessiveHalvingPruner\n",
    "# # tune the weights of the voting classifier\n",
    "# def objective(trial: optuna.Trial):\n",
    "#     w1 = trial.suggest_float(\"w1\", 0.0, 1.0)\n",
    "#     w2 = trial.suggest_float(\"w2\", 0.0, 1.0)\n",
    "#     w3 = trial.suggest_float(\"w3\", 0.0, 1.0)\n",
    "#     w4 = trial.suggest_float(\"w4\", 0.0, 1.0)\n",
    "#     w5 = trial.suggest_float(\"w5\", 0.0, 1.0)\n",
    "#     weights=[w1,w2,w3,w4,w5]\n",
    "#     skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "#     scores=[]\n",
    "#     i=0\n",
    "#     for train_index, test_index in skf.split(X, y):\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#         vc=VotingClassifier(estimators=estimators,n_jobs=-1,voting='soft',weights=weights)\n",
    "#         vc.fit(X_train,y_train)\n",
    "#         y_pred=vc.predict_proba(X_test)[:,1]\n",
    "#         scores.append(roc_auc_score(y_test,y_pred))\n",
    "#         i+=1\n",
    "        \n",
    "#     return np.mean(scores)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "# sampler = optuna.samplers.TPESampler(seed=42)\n",
    "# pruner = SuccessiveHalvingPruner(min_resource=1, reduction_factor=2, min_early_stopping_rate=0)\n",
    "# study = optuna.create_study(pruner=pruner,sampler=sampler,direction='maximize')\n",
    "# study.optimize(objective, n_trials=100,n_jobs=-1,show_progress_bar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id=test['id']\n",
    "test_data=test.drop(['id'],axis=1)\n",
    "#test_data=test.drop(['id','Product ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "# test_data,_=preprocess(test_data,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=vc_l1.predict_proba(test_data)[:,1]\n",
    "preds2=vc_l2.predict_proba(test_data)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame({'id':test_id,'EC1':preds1,'EC2':preds2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649703118426022"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['EC1'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.15 / client 1.5.13)\n",
      "Successfully submitted to Explore Multi-Label Classification with an Enzyme Substrate Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/432k [00:00<?, ?B/s]\n",
      "  2%|▏         | 8.00k/432k [00:00<00:38, 11.3kB/s]\n",
      " 22%|██▏       | 96.0k/432k [00:00<00:02, 151kB/s] \n",
      " 33%|███▎      | 144k/432k [00:00<00:01, 200kB/s] \n",
      " 50%|████▉     | 216k/432k [00:01<00:00, 298kB/s]\n",
      " 65%|██████▍   | 280k/432k [00:01<00:00, 362kB/s]\n",
      " 80%|███████▉  | 344k/432k [00:01<00:00, 427kB/s]\n",
      "100%|██████████| 432k/432k [00:02<00:00, 178kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c playground-series-s3e18 -f sub.csv -m \"lgbm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
